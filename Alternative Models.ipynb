{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlens\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "from matplotlib.pyplot import show\n",
    "\n",
    "from mlens.preprocessing import EnsembleTransformer\n",
    "from mlens.model_selection import Evaluator\n",
    "from mlens.metrics import make_scorer\n",
    "from mlens.ensemble import SuperLearner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fake_real_df_clean = fake_real_df[['title','text','label']]\n",
    "fake_real_df = pd.read_csv('./fake_or_real_news.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(fake_real_df_clean, fake_real_df_clean[\"label\"]):\n",
    "    strat_train_set = fake_real_df_clean.loc[train_index]\n",
    "    strat_test_set = fake_real_df_clean.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "strat_fake_or_real_train = strat_train_set.copy()\n",
    "strat_fake_or_real_test  = strat_test_set.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = strat_fake_or_real_train.copy().drop('label', 1)\n",
    "y_train = strat_fake_or_real_train.copy()['label']\n",
    "X_test  = strat_fake_or_real_test.copy().drop('label', 1)\n",
    "y_test  = strat_fake_or_real_test.copy()['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "\n",
    "def preprocessing(text):\n",
    "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    stop = stopwords.words('english')\n",
    "    tokens = [token for token in tokens if token not in stop]\n",
    "    tokens = [word for word in tokens if len(word) >= 3]\n",
    "    tokens = [word.lower() for word in tokens]\n",
    "    lcStem = LancasterStemmer()\n",
    "    tokens = [lcStem.stem(word) for word in tokens]\n",
    "    preprocessed_text = ' '.join(tokens)\n",
    "    return preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_text_list  = list(X_train['text'])\n",
    "X_train_title_list = list(X_train['title'])\n",
    "X_test_text_list   = list(X_test['text'])\n",
    "X_test_title_list  = list(X_test['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_text_clean = [preprocessing(text) for text in X_train_text_list]\n",
    "X_train_title_clean = [preprocessing(text) for text in X_train_title_list]\n",
    "X_test_text_clean = [preprocessing(text) for text in X_test_text_list]\n",
    "X_test_title_clean = [preprocessing(text) for text in X_test_title_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_binary = [x=='REAL' for x in list(y_train)]\n",
    "y_test_binary = [x=='REAL' for x in list(y_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "The code above is all cleaning.\n",
    "I separated the two features Text and title. \n",
    "You can join them into a df\n",
    "if you want to use multiple features analysis.\n",
    "Below is the actual machine learning that I have done\n",
    "so far.\n",
    "'''\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(min_df=2, ngram_range=(1,2), stop_words='english', strip_accents='unicode',norm=u'l2')\n",
    "\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train_text_clean, y_train_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "rfc = RandomForestClassifier() #.fit(X_train_tfidf, y_train_binary)\n",
    "mnb = MultinomialNB()\n",
    "abc = AdaBoostClassifier()\n",
    "lac = LarsCV()\n",
    "\n",
    "base_learners = [('rfc', rfc),\n",
    "                 ('mnb', mnb),\n",
    "                 ('abc', abc),\n",
    "                ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  rfc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/metrics/regression.py:164: DeprecationWarning: numpy boolean subtract, the `-` operator, is deprecated, use the bitwise_xor, the `^` operator, or the logical_xor function instead.\n",
      "  output_errors = np.average(np.abs(y_pred - y_true),\n",
      "/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/metrics/regression.py:164: DeprecationWarning: numpy boolean subtract, the `-` operator, is deprecated, use the bitwise_xor, the `^` operator, or the logical_xor function instead.\n",
      "  output_errors = np.average(np.abs(y_pred - y_true),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rfc mean absolute error: 0.004932912391475927\n",
      "Processing:  mnb\n",
      "mnb mean absolute error: 0.06610102604577743\n",
      "Processing:  abc\n",
      "abc mean absolute error: 0.09609313338595106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/metrics/regression.py:164: DeprecationWarning: numpy boolean subtract, the `-` operator, is deprecated, use the bitwise_xor, the `^` operator, or the logical_xor function instead.\n",
      "  output_errors = np.average(np.abs(y_pred - y_true),\n"
     ]
    }
   ],
   "source": [
    "#type(X_train_tfidf.shape[0])\n",
    "#len(base_learners)\n",
    "P = np.zeros((X_train_tfidf.shape[0], len(base_learners)))\n",
    "P = pd.DataFrame(P, columns=[e for e, _ in base_learners])\n",
    "\n",
    "for est_name, est in base_learners:\n",
    "    print('Processing: ', est_name)\n",
    "    est.fit(X_train_tfidf, y_train_binary)\n",
    "    p = est.predict(X_train_tfidf)\n",
    "    P.loc[:, est_name] = p\n",
    "    print(\"{0} mean absolute error: {1}\".format(est_name, mean_absolute_error(y_train_binary, P[est_name])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.5067087609\n",
      "93.3898973954\n",
      "90.3906866614\n"
     ]
    }
   ],
   "source": [
    "P['Truth'] = y_train_binary\n",
    "for est_name, est in base_learners:\n",
    "    print(P[P[est_name] == P['Truth']][est_name].count()/len(P)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlcAAAIZCAYAAACLaRqYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f755e5de278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mlens.visualization import corrmat\n",
    "ax = corrmat(P.corr())\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dicts = {\n",
    "    'rfc': \n",
    "        {'n_estimators': randint(5, 40),\n",
    "         'max_features': ['sqrt', 'log2', None],\n",
    "         'n_jobs': [-1]\n",
    "        },\n",
    "    'abc':\n",
    "        {'n_estimators': randint(25, 50, 100),\n",
    "         'learning_rate': uniform(0.1, 10),\n",
    "        },\n",
    "    'mnb':\n",
    "        {'alpha': [0.026895783878784774],\n",
    "         'class_prior': [None],\n",
    "         'fit_prior': [False]\n",
    "        }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "\n",
    "evl = Evaluator(scorer, \n",
    "                cv=2,\n",
    "                random_state=42,\n",
    "                verbose=5\n",
    "               )\n",
    "\n",
    "\n",
    "meta_learners = [('rfc', rfc)]\n",
    "\n",
    "in_layer = EnsembleTransformer()\n",
    "in_layer.add('stack', base_learners)\n",
    "preprocess = [in_layer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SuperLearner(array_check=2, backend='threading', folds=2,\n",
       "       layers=LayerContainer(backend='threading',\n",
       "        layers=OrderedDict([('layer-1', Layer(cls='stack', cls_kwargs=None,\n",
       "   estimators=[('rfc', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            ...n_exception=True, scorer=None, verbose=5))]),\n",
       "        n_jobs=-1, raise_on_exception=True, verbose=5),\n",
       "       n_jobs=-1, raise_on_exception=True, random_state=None, scorer=None,\n",
       "       shuffle=False, verbose=5)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ens = SuperLearner(verbose=5,\n",
    "                   backend=\"threading\")\n",
    "ens.add(base_learners)\n",
    "ens.add_meta(meta_learners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing layers (2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting layer-1\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    0.2s remaining:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   9 | elapsed:    1.2s remaining:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    1.9s remaining:    0.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit complete | 00:00:17\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   17.6s finished\n",
      "layer-1 Done | 00:00:17\n",
      "\n",
      "Fitting layer-2\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "layer-2 Done | 00:00:00\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SuperLearner(array_check=2, backend='threading', folds=2,\n",
       "       layers=LayerContainer(backend='threading',\n",
       "        layers=OrderedDict([('layer-1', Layer(cls='stack', cls_kwargs=None,\n",
       "   estimators=[('rfc', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            ...n_exception=True, scorer=None, verbose=5))]),\n",
       "        n_jobs=-1, raise_on_exception=True, verbose=5),\n",
       "       n_jobs=-1, raise_on_exception=True, random_state=None, scorer=None,\n",
       "       shuffle=False, verbose=5)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ens.fit(X_train_tfidf, y_train_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_tfidf = vectorizer.fit_transform(X_test_text_clean, y_test_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing layers (2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting layer-1\n"
     ]
    },
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x7f75a5c8c0c0, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/anthonyle/anaconda3/envs/deep_learning/lib...ges/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/anthon.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7f75a5c8c0c0, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/anthonyle/anaconda3/envs/deep_learning/lib...ges/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/anthon.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n     17 \n     18 \n     19 \n     20 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'ens_pred = ens.predict(X_test_tfidf)\\nprint(\"Ense...at(mean_absolute_error(y_test_binary, ens_pred)))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 6, 25, 9, 36, 42, 416722, tzinfo=datetime.timezone.utc), 'msg_id': '98861FABD69640DF982C5221FE60A189', 'msg_type': 'execute_request', 'session': '55AD9960AF514B44A33856CD0CDB88E6', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '98861FABD69640DF982C5221FE60A189', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'55AD9960AF514B44A33856CD0CDB88E6']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'ens_pred = ens.predict(X_test_tfidf)\\nprint(\"Ense...at(mean_absolute_error(y_test_binary, ens_pred)))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 6, 25, 9, 36, 42, 416722, tzinfo=datetime.timezone.utc), 'msg_id': '98861FABD69640DF982C5221FE60A189', 'msg_type': 'execute_request', 'session': '55AD9960AF514B44A33856CD0CDB88E6', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '98861FABD69640DF982C5221FE60A189', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'55AD9960AF514B44A33856CD0CDB88E6'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'ens_pred = ens.predict(X_test_tfidf)\\nprint(\"Ense...at(mean_absolute_error(y_test_binary, ens_pred)))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 6, 25, 9, 36, 42, 416722, tzinfo=datetime.timezone.utc), 'msg_id': '98861FABD69640DF982C5221FE60A189', 'msg_type': 'execute_request', 'session': '55AD9960AF514B44A33856CD0CDB88E6', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '98861FABD69640DF982C5221FE60A189', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='ens_pred = ens.predict(X_test_tfidf)\\nprint(\"Ense...at(mean_absolute_error(y_test_binary, ens_pred)))', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'ens_pred = ens.predict(X_test_tfidf)\\nprint(\"Ense...at(mean_absolute_error(y_test_binary, ens_pred)))'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('ens_pred = ens.predict(X_test_tfidf)\\nprint(\"Ense...at(mean_absolute_error(y_test_binary, ens_pred)))',), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('ens_pred = ens.predict(X_test_tfidf)\\nprint(\"Ense...at(mean_absolute_error(y_test_binary, ens_pred)))',)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='ens_pred = ens.predict(X_test_tfidf)\\nprint(\"Ense...at(mean_absolute_error(y_test_binary, ens_pred)))', store_history=True, silent=False, shell_futures=True)\n   2693                 self.displayhook.exec_result = result\n   2694 \n   2695                 # Execute the user code\n   2696                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2697                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2698                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2699                 \n   2700                 self.last_execution_succeeded = not has_raised\n   2701 \n   2702                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-112-4d700f445c49>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7f755be816a0, executi..._before_exec=None error_in_exec=None result=None>)\n   2797 \n   2798         try:\n   2799             for i, node in enumerate(to_run_exec):\n   2800                 mod = ast.Module([node])\n   2801                 code = compiler(mod, cell_name, \"exec\")\n-> 2802                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f7567666a50, file \"<ipython-input-112-4d700f445c49>\", line 1>\n        result = <ExecutionResult object at 7f755be816a0, executi..._before_exec=None error_in_exec=None result=None>\n   2803                     return True\n   2804 \n   2805             for i, node in enumerate(to_run_interactive):\n   2806                 mod = ast.Interactive([node])\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f7567666a50, file \"<ipython-input-112-4d700f445c49>\", line 1>, result=<ExecutionResult object at 7f755be816a0, executi..._before_exec=None error_in_exec=None result=None>)\n   2857         outflag = True  # happens in more places, so it's easier as default\n   2858         try:\n   2859             try:\n   2860                 self.hooks.pre_run_code_hook()\n   2861                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2862                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f7567666a50, file \"<ipython-input-112-4d700f445c49>\", line 1>\n        self.user_global_ns = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'EnsembleTransformer': <class 'mlens.preprocessing.ensemble_transformer.EnsembleTransformer'>, 'Evaluator': <class 'mlens.model_selection.model_selection.Evaluator'>, 'In': ['', \"import pandas as pd\\nfake_real_df = pd.read_csv('./fake_or_real_news.csv')\", \"fake_real_df_clean = fake_real_df[['title','text','label']]\", 'from sklearn.model_selection import StratifiedSh...rat_test_set = fake_real_df_clean.loc[test_index]', 'strat_fake_or_real_train = strat_train_set.copy()\\nstrat_fake_or_real_test  = strat_test_set.copy()', \"X_train = strat_fake_or_real_train.copy().drop('...y_test  = strat_fake_or_real_test.copy()['label']\", \"import nltk\\nfrom nltk.corpus import stopwords\\nfr...t = ' '.join(tokens)\\n    return preprocessed_text\", \"X_train_text_list  = list(X_train['text'])\\nX_tra...ext'])\\nX_test_title_list  = list(X_test['title'])\", 'X_train_text_clean = [preprocessing(text) for te...reprocessing(text) for text in X_test_title_list]', 'nltk.download()', \"import pandas as pd\\nfake_real_df = pd.read_csv('./fake_or_real_news.csv')\", \"fake_real_df_clean = fake_real_df[['title','text','label']]\", 'from sklearn.model_selection import StratifiedSh...rat_test_set = fake_real_df_clean.loc[test_index]', 'strat_fake_or_real_train = strat_train_set.copy()\\nstrat_fake_or_real_test  = strat_test_set.copy()', \"X_train = strat_fake_or_real_train.copy().drop('...y_test  = strat_fake_or_real_test.copy()['label']\", \"import nltk\\nfrom nltk.corpus import stopwords\\nfr...t = ' '.join(tokens)\\n    return preprocessed_text\", \"X_train_text_list  = list(X_train['text'])\\nX_tra...ext'])\\nX_test_title_list  = list(X_test['title'])\", 'X_train_text_clean = [preprocessing(text) for te...reprocessing(text) for text in X_test_title_list]', \"y_train_binary = [x=='REAL' for x in list(y_trai...y_test_binary = [x=='REAL' for x in list(y_test)]\", \"'''\\nThe code above is all cleaning.\\nI separated ...fit_transform(X_train_text_clean, y_train_binary)\", ...], 'LancasterStemmer': <class 'nltk.stem.lancaster.LancasterStemmer'>, 'LarsCV': <class 'sklearn.linear_model.least_angle.LarsCV'>, 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'Out': {9: True, 21: array([ 0.82955665,  0.82741617,  0.82329714,  0.81342547,  0.83119447]), 22: '\\nIt is now up to you to use the data as you wish...ll going to work on improving the current model.\\n', 29: <5068x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, 30: <1x286760 sparse matrix of type '<class 'numpy.f... stored elements in Compressed Sparse Row format>, 31: (5068, 286760), 32: 5068, 36: <class 'int'>, 37: 4, 38: <class 'int'>, ...}, 'P':         rfc    mnb    abc  Truth\n0      True   T...lse  False  False  False\n\n[5068 rows x 4 columns], 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, ...}\n        self.user_ns = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'EnsembleTransformer': <class 'mlens.preprocessing.ensemble_transformer.EnsembleTransformer'>, 'Evaluator': <class 'mlens.model_selection.model_selection.Evaluator'>, 'In': ['', \"import pandas as pd\\nfake_real_df = pd.read_csv('./fake_or_real_news.csv')\", \"fake_real_df_clean = fake_real_df[['title','text','label']]\", 'from sklearn.model_selection import StratifiedSh...rat_test_set = fake_real_df_clean.loc[test_index]', 'strat_fake_or_real_train = strat_train_set.copy()\\nstrat_fake_or_real_test  = strat_test_set.copy()', \"X_train = strat_fake_or_real_train.copy().drop('...y_test  = strat_fake_or_real_test.copy()['label']\", \"import nltk\\nfrom nltk.corpus import stopwords\\nfr...t = ' '.join(tokens)\\n    return preprocessed_text\", \"X_train_text_list  = list(X_train['text'])\\nX_tra...ext'])\\nX_test_title_list  = list(X_test['title'])\", 'X_train_text_clean = [preprocessing(text) for te...reprocessing(text) for text in X_test_title_list]', 'nltk.download()', \"import pandas as pd\\nfake_real_df = pd.read_csv('./fake_or_real_news.csv')\", \"fake_real_df_clean = fake_real_df[['title','text','label']]\", 'from sklearn.model_selection import StratifiedSh...rat_test_set = fake_real_df_clean.loc[test_index]', 'strat_fake_or_real_train = strat_train_set.copy()\\nstrat_fake_or_real_test  = strat_test_set.copy()', \"X_train = strat_fake_or_real_train.copy().drop('...y_test  = strat_fake_or_real_test.copy()['label']\", \"import nltk\\nfrom nltk.corpus import stopwords\\nfr...t = ' '.join(tokens)\\n    return preprocessed_text\", \"X_train_text_list  = list(X_train['text'])\\nX_tra...ext'])\\nX_test_title_list  = list(X_test['title'])\", 'X_train_text_clean = [preprocessing(text) for te...reprocessing(text) for text in X_test_title_list]', \"y_train_binary = [x=='REAL' for x in list(y_trai...y_test_binary = [x=='REAL' for x in list(y_test)]\", \"'''\\nThe code above is all cleaning.\\nI separated ...fit_transform(X_train_text_clean, y_train_binary)\", ...], 'LancasterStemmer': <class 'nltk.stem.lancaster.LancasterStemmer'>, 'LarsCV': <class 'sklearn.linear_model.least_angle.LarsCV'>, 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'Out': {9: True, 21: array([ 0.82955665,  0.82741617,  0.82329714,  0.81342547,  0.83119447]), 22: '\\nIt is now up to you to use the data as you wish...ll going to work on improving the current model.\\n', 29: <5068x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, 30: <1x286760 sparse matrix of type '<class 'numpy.f... stored elements in Compressed Sparse Row format>, 31: (5068, 286760), 32: 5068, 36: <class 'int'>, 37: 4, 38: <class 'int'>, ...}, 'P':         rfc    mnb    abc  Truth\n0      True   T...lse  False  False  False\n\n[5068 rows x 4 columns], 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, ...}\n   2863             finally:\n   2864                 # Reset our crash handler in place\n   2865                 sys.excepthook = old_excepthook\n   2866         except SystemExit as e:\n\n...........................................................................\n/mnt/Linux-Extra/home-extra/Anthony.Le/Projects/fake_news/<ipython-input-112-4d700f445c49> in <module>()\n----> 1 \n      2 \n      3 \n      4 \n      5 \n      6 ens_pred = ens.predict(X_test_tfidf)\n      7 print(\"Ensemble mean absolute error: {0}\".format(mean_absolute_error(y_test_binary, ens_pred)))\n      8 \n      9 \n     10 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/ensemble/base.py in predict(self=SuperLearner(array_check=2, backend='threading',...ne, scorer=None,\n       shuffle=False, verbose=5), X=<1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>)\n    739         if self.shuffle:\n    740             r = check_random_state(self.random_state)\n    741             idx = r.permutation(X.shape[0])\n    742             X = X[idx]\n    743 \n--> 744         y = self.layers.predict(X)\n        y = undefined\n        self.layers.predict = <bound method LayerContainer.predict of LayerCon...  n_jobs=-1, raise_on_exception=True, verbose=5)>\n        X = <1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>\n    745 \n    746         if y.shape[1] == 1:\n    747             # The meta estimator is treated as a layer and thus a prediction\n    748             # matrix with shape [n_samples, 1] is created. Ravel before return\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/ensemble/base.py in predict(self=LayerContainer(backend='threading',\n        laye...   n_jobs=-1, raise_on_exception=True, verbose=5), X=<1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>, *args=(), **kwargs={})\n    262         Returns\n    263         -------\n    264         X_pred : array-like of shape = [n_samples, n_fitted_estimators]\n    265             predictions from final layer.\n    266         \"\"\"\n--> 267         return self._predict(X, 'predict', *args, **kwargs)\n        self._predict = <bound method LayerContainer._predict of LayerCo...  n_jobs=-1, raise_on_exception=True, verbose=5)>\n        X = <1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>\n        args = ()\n        kwargs = {}\n    268 \n    269     def transform(self, X=None, *args, **kwargs):\n    270         \"\"\"Generic method for reproducing predictions of the ``fit`` call.\n    271 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/ensemble/base.py in _predict(self=LayerContainer(backend='threading',\n        laye...   n_jobs=-1, raise_on_exception=True, verbose=5), X=<1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>, job='predict', *args=(), **kwargs={})\n    315         processor = ParallelProcessing(self)\n    316         processor.initialize(job, X, *args, **kwargs)\n    317 \n    318         # Predict with ensemble\n    319         try:\n--> 320             processor.process()\n        processor.process = <bound method ParallelProcessing.process of <mlens.parallel.manager.ParallelProcessing object>>\n    321 \n    322             preds = processor.get_preds()\n    323 \n    324             if self.verbose:\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/parallel/manager.py in process(self=<mlens.parallel.manager.ParallelProcessing object>)\n    213                       mmap_mode='w+',\n    214                       verbose=self.layers.verbose,\n    215                       backend=self.layers.backend) as parallel:\n    216 \n    217             for n, lyr in enumerate(self.layers.layers.values()):\n--> 218                 self._partial_process(n, lyr, parallel)\n        self._partial_process = <bound method ParallelProcessing._partial_proces...lens.parallel.manager.ParallelProcessing object>>\n        n = 0\n        lyr = Layer(cls='stack', cls_kwargs=None,\n   estimator... raise_on_exception=True, scorer=None, verbose=5)\n        parallel = Parallel(n_jobs=-1)\n    219 \n    220         self.__fitted__ = 1\n    221 \n    222     def get_preds(self, n=-1, dtype=np.float, order='C'):\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/parallel/manager.py in _partial_process(self=<mlens.parallel.manager.ParallelProcessing object>, n=0, lyr=Layer(cls='stack', cls_kwargs=None,\n   estimator... raise_on_exception=True, scorer=None, verbose=5), parallel=Parallel(n_jobs=-1))\n    303         if 'X' in fargs:\n    304             kwargs['X'] = self.job.P[n]\n    305         if 'P' in fargs:\n    306             kwargs['P'] = self.job.P[n + 1]\n    307 \n--> 308         f(**kwargs)\n        f = <bound method BaseEstimator.predict of <mlens.parallel.stack.Stacker object>>\n        kwargs = {'P': memmap([[ 0.,  0.,  0.],\n       [ 0.,  0.,  0.],...\n       [ 0.,  0.,  0.],\n       [ 0.,  0.,  0.]]), 'X': <1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>, 'parallel': Parallel(n_jobs=-1)}\n    309 \n    310 \n    311 ###############################################################################\n    312 class ParallelEvaluation(object):\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/parallel/estimation.py in predict(self=<mlens.parallel.stack.Stacker object>, X=<1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>, P=memmap([[ 0.,  0.,  0.],\n       [ 0.,  0.,  0.],...\n       [ 0.,  0.,  0.],\n       [ 0.,  0.,  0.]]), parallel=Parallel(n_jobs=-1))\n    224                                       xtest=X,\n    225                                       pred=P,\n    226                                       col=col,\n    227                                       name=self.name,\n    228                                       attr=pred_method)\n--> 229                  for case, (inst_name, est, (_, col)) in ests)\n        ests = [(None, ('rfc', RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), (None, 0))), (None, ('mnb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), (None, 1))), (None, ('abc', AdaBoostClassifier(algorithm='SAMME.R', base_est...ing_rate=1.0, n_estimators=50, random_state=None), (None, 2)))]\n    230 \n    231         if self.verbose:\n    232             print_time(t0, '%s Done' % self.name, file=printout)\n    233 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseEstimator.predict.<locals>.<genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Sun Jun 25 02:36:42 2017\nPID: 16426Python 3.6.1: /home/anthonyle/anaconda3/envs/deep_learning/bin/python\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/externals/joblib/parallel.py in __call__(self=<mlens.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function predict_est>, (), {'attr': 'predict', 'case': None, 'col': 0, 'est': RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), 'inst_name': 'rfc', 'name': 'layer-1', 'pred': memmap([[ 0.,  0.,  0.],\n       [ 0.,  0.,  0.],...\n       [ 0.,  0.,  0.],\n       [ 0.,  0.,  0.]]), 'tr_list': [], 'xtest': <1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function predict_est>\n        args = ()\n        kwargs = {'attr': 'predict', 'case': None, 'col': 0, 'est': RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), 'inst_name': 'rfc', 'name': 'layer-1', 'pred': memmap([[ 0.,  0.,  0.],\n       [ 0.,  0.,  0.],...\n       [ 0.,  0.,  0.],\n       [ 0.,  0.,  0.]]), 'tr_list': [], 'xtest': <1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/parallel/estimation.py in predict_est(case=None, tr_list=[], inst_name='rfc', est=RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), xtest=<1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>, pred=memmap([[ 0.,  0.,  0.],\n       [ 0.,  0.,  0.],...\n       [ 0.,  0.,  0.],\n       [ 0.,  0.,  0.]]), col=0, name='layer-1', attr='predict')\n    402 \n    403     # Predict into memmap\n    404     # Here, we coerce errors on failed predictions - all predictors that\n    405     # survive into the estimators_ attribute of a layer should be able to\n    406     # predict, otherwise the subsequent layer will get corrupt input.\n--> 407     p = getattr(est, attr)(xtest)\n        p = undefined\n        est = RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False)\n        attr = 'predict'\n        xtest = <1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>\n    408 \n    409     if len(p.shape) == 1:\n    410         pred[:, col] = p\n    411     else:\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/ensemble/forest.py in predict(self=RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), X=<1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>)\n    529         Returns\n    530         -------\n    531         y : array of shape = [n_samples] or [n_samples, n_outputs]\n    532             The predicted classes.\n    533         \"\"\"\n--> 534         proba = self.predict_proba(X)\n        proba = undefined\n        self.predict_proba = <bound method ForestClassifier.predict_proba of ...e=None,\n            verbose=0, warm_start=False)>\n        X = <1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>\n    535 \n    536         if self.n_outputs_ == 1:\n    537             return self.classes_.take(np.argmax(proba, axis=1), axis=0)\n    538 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/ensemble/forest.py in predict_proba(self=RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), X=<1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>)\n    568             such arrays if n_outputs > 1.\n    569             The class probabilities of the input samples. The order of the\n    570             classes corresponds to that in the attribute `classes_`.\n    571         \"\"\"\n    572         # Check data\n--> 573         X = self._validate_X_predict(X)\n        X = <1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>\n        self._validate_X_predict = <bound method BaseForest._validate_X_predict of ...e=None,\n            verbose=0, warm_start=False)>\n    574 \n    575         # Assign chunk of trees to jobs\n    576         n_jobs, _, _ = _partition_estimators(self.n_estimators, self.n_jobs)\n    577 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/ensemble/forest.py in _validate_X_predict(self=RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), X=<1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>)\n    350         \"\"\"Validate X whenever one tries to predict, apply, predict_proba\"\"\"\n    351         if self.estimators_ is None or len(self.estimators_) == 0:\n    352             raise NotFittedError(\"Estimator not fitted, \"\n    353                                  \"call `fit` before exploiting the model.\")\n    354 \n--> 355         return self.estimators_[0]._validate_X_predict(X, check_input=True)\n        self.estimators_._validate_X_predict = undefined\n        X = <1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>\n    356 \n    357     @property\n    358     def feature_importances_(self):\n    359         \"\"\"Return the feature importances (the higher, the more important the\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/tree/tree.py in _validate_X_predict(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1441231714, splitter='best'), X=<1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>, check_input=True)\n    360         if self.tree_ is None:\n    361             raise NotFittedError(\"Estimator not fitted, \"\n    362                                  \"call `fit` before exploiting the model.\")\n    363 \n    364         if check_input:\n--> 365             X = check_array(X, dtype=DTYPE, accept_sparse=\"csr\")\n        X = <1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>\n    366             if issparse(X) and (X.indices.dtype != np.intc or\n    367                                 X.indptr.dtype != np.intc):\n    368                 raise ValueError(\"No support for np.int64 index based \"\n    369                                  \"sparse matrices\")\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array=<1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>, accept_sparse=['csr'], dtype=<class 'numpy.float32'>, order=None, copy=False, force_all_finite=True, ensure_2d=True, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)\n    375         estimator_name = \"Estimator\"\n    376     context = \" by %s\" % estimator_name if estimator is not None else \"\"\n    377 \n    378     if sp.issparse(array):\n    379         array = _ensure_sparse_format(array, accept_sparse, dtype, copy,\n--> 380                                       force_all_finite)\n        force_all_finite = True\n    381     else:\n    382         array = np.array(array, dtype=dtype, order=order, copy=copy)\n    383 \n    384         if ensure_2d:\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/utils/validation.py in _ensure_sparse_format(spmatrix=<1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>, accept_sparse=['csr'], dtype=<class 'numpy.float32'>, copy=False, force_all_finite=True)\n    253         spmatrix = spmatrix.asformat(accept_sparse[0])\n    254         changed_format = True\n    255 \n    256     if dtype != spmatrix.dtype:\n    257         # convert dtype\n--> 258         spmatrix = spmatrix.astype(dtype)\n        spmatrix = <1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>\n        spmatrix.astype = <bound method _data_matrix.astype of <1267x62200...stored elements in Compressed Sparse Row format>>\n        dtype = <class 'numpy.float32'>\n    259     elif copy and not changed_format:\n    260         # force copy\n    261         spmatrix = spmatrix.copy()\n    262 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/scipy/sparse/data.py in astype(self=<1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>, t=<class 'numpy.float32'>)\n     63             return self\n     64         else:\n     65             return NotImplemented\n     66 \n     67     def astype(self, t):\n---> 68         return self._with_data(self._deduped_data().astype(t))\n        self._with_data = <bound method _cs_matrix._with_data of <1267x622...stored elements in Compressed Sparse Row format>>\n        self._deduped_data.astype = undefined\n        t = <class 'numpy.float32'>\n     69 \n     70     astype.__doc__ = spmatrix.astype.__doc__\n     71 \n     72     def conj(self):\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/scipy/sparse/data.py in _deduped_data(self=<1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>)\n     29         self.data.dtype = newtype\n     30     dtype = property(fget=_get_dtype, fset=_set_dtype)\n     31 \n     32     def _deduped_data(self):\n     33         if hasattr(self, 'sum_duplicates'):\n---> 34             self.sum_duplicates()\n        self.sum_duplicates = <bound method _cs_matrix.sum_duplicates of <1267...stored elements in Compressed Sparse Row format>>\n     35         return self.data\n     36 \n     37     def __abs__(self):\n     38         return self._with_data(abs(self._deduped_data()))\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/scipy/sparse/compressed.py in sum_duplicates(self=<1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>)\n   1011 \n   1012         The is an *in place* operation\n   1013         \"\"\"\n   1014         if self.has_canonical_format:\n   1015             return\n-> 1016         self.sort_indices()\n        self.sort_indices = <bound method _cs_matrix.sort_indices of <1267x6...stored elements in Compressed Sparse Row format>>\n   1017 \n   1018         M, N = self._swap(self.shape)\n   1019         _sparsetools.csr_sum_duplicates(M, N, self.indptr, self.indices,\n   1020                                         self.data)\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/scipy/sparse/compressed.py in sort_indices(self=<1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>)\n   1057         \"\"\"Sort the indices of this matrix *in place*\n   1058         \"\"\"\n   1059 \n   1060         if not self.has_sorted_indices:\n   1061             _sparsetools.csr_sort_indices(len(self.indptr) - 1, self.indptr,\n-> 1062                                           self.indices, self.data)\n        self.indices = memmap([40112, 31916,  7520, ..., 33149, 16533, 28279], dtype=int32)\n        self.data = memmap([ 0.01903084,  0.0253219 ,  0.04890401, ...,  0.04318216,\n        0.04005177,  0.04318216])\n   1063             self.has_sorted_indices = True\n   1064 \n   1065     def prune(self):\n   1066         \"\"\"Remove empty space after all non-zero elements.\n\nValueError: UPDATEIFCOPY base is read-only\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/parallel/estimation.py\u001b[0m in \u001b[0;36mpredict_est\u001b[0;34m(case, tr_list, inst_name, est, xtest, pred, col, name, attr)\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;31m# predict, otherwise the subsequent layer will get corrupt input.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    533\u001b[0m         \"\"\"\n\u001b[0;32m--> 534\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m             if issparse(X) and (X.indices.dtype != np.intc or\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    379\u001b[0m         array = _ensure_sparse_format(array, accept_sparse, dtype, copy,\n\u001b[0;32m--> 380\u001b[0;31m                                       force_all_finite)\n\u001b[0m\u001b[1;32m    381\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_ensure_sparse_format\u001b[0;34m(spmatrix, accept_sparse, dtype, copy, force_all_finite)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;31m# convert dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0mspmatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspmatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchanged_format\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/scipy/sparse/data.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deduped_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/scipy/sparse/data.py\u001b[0m in \u001b[0;36m_deduped_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sum_duplicates'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36msum_duplicates\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1015\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36msort_indices\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m             _sparsetools.csr_sort_indices(len(self.indptr) - 1, self.indptr,\n\u001b[0;32m-> 1062\u001b[0;31m                                           self.indices, self.data)\n\u001b[0m\u001b[1;32m   1063\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_sorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: UPDATEIFCOPY base is read-only",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    681\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m'timeout'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgetfullargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mworker\u001b[0;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat_exc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_tb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTransportableException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nValueError                                         Sun Jun 25 02:36:42 2017\nPID: 16426Python 3.6.1: /home/anthonyle/anaconda3/envs/deep_learning/bin/python\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/externals/joblib/parallel.py in __call__(self=<mlens.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function predict_est>, (), {'attr': 'predict', 'case': None, 'col': 0, 'est': RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), 'inst_name': 'rfc', 'name': 'layer-1', 'pred': memmap([[ 0.,  0.,  0.],\n       [ 0.,  0.,  0.],...\n       [ 0.,  0.,  0.],\n       [ 0.,  0.,  0.]]), 'tr_list': [], 'xtest': <1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function predict_est>\n        args = ()\n        kwargs = {'attr': 'predict', 'case': None, 'col': 0, 'est': RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), 'inst_name': 'rfc', 'name': 'layer-1', 'pred': memmap([[ 0.,  0.,  0.],\n       [ 0.,  0.,  0.],...\n       [ 0.,  0.,  0.],\n       [ 0.,  0.,  0.]]), 'tr_list': [], 'xtest': <1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/parallel/estimation.py in predict_est(case=None, tr_list=[], inst_name='rfc', est=RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), xtest=<1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>, pred=memmap([[ 0.,  0.,  0.],\n       [ 0.,  0.,  0.],...\n       [ 0.,  0.,  0.],\n       [ 0.,  0.,  0.]]), col=0, name='layer-1', attr='predict')\n    402 \n    403     # Predict into memmap\n    404     # Here, we coerce errors on failed predictions - all predictors that\n    405     # survive into the estimators_ attribute of a layer should be able to\n    406     # predict, otherwise the subsequent layer will get corrupt input.\n--> 407     p = getattr(est, attr)(xtest)\n        p = undefined\n        est = RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False)\n        attr = 'predict'\n        xtest = <1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>\n    408 \n    409     if len(p.shape) == 1:\n    410         pred[:, col] = p\n    411     else:\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/ensemble/forest.py in predict(self=RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), X=<1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>)\n    529         Returns\n    530         -------\n    531         y : array of shape = [n_samples] or [n_samples, n_outputs]\n    532             The predicted classes.\n    533         \"\"\"\n--> 534         proba = self.predict_proba(X)\n        proba = undefined\n        self.predict_proba = <bound method ForestClassifier.predict_proba of ...e=None,\n            verbose=0, warm_start=False)>\n        X = <1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>\n    535 \n    536         if self.n_outputs_ == 1:\n    537             return self.classes_.take(np.argmax(proba, axis=1), axis=0)\n    538 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/ensemble/forest.py in predict_proba(self=RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), X=<1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>)\n    568             such arrays if n_outputs > 1.\n    569             The class probabilities of the input samples. The order of the\n    570             classes corresponds to that in the attribute `classes_`.\n    571         \"\"\"\n    572         # Check data\n--> 573         X = self._validate_X_predict(X)\n        X = <1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>\n        self._validate_X_predict = <bound method BaseForest._validate_X_predict of ...e=None,\n            verbose=0, warm_start=False)>\n    574 \n    575         # Assign chunk of trees to jobs\n    576         n_jobs, _, _ = _partition_estimators(self.n_estimators, self.n_jobs)\n    577 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/ensemble/forest.py in _validate_X_predict(self=RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), X=<1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>)\n    350         \"\"\"Validate X whenever one tries to predict, apply, predict_proba\"\"\"\n    351         if self.estimators_ is None or len(self.estimators_) == 0:\n    352             raise NotFittedError(\"Estimator not fitted, \"\n    353                                  \"call `fit` before exploiting the model.\")\n    354 \n--> 355         return self.estimators_[0]._validate_X_predict(X, check_input=True)\n        self.estimators_._validate_X_predict = undefined\n        X = <1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>\n    356 \n    357     @property\n    358     def feature_importances_(self):\n    359         \"\"\"Return the feature importances (the higher, the more important the\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/tree/tree.py in _validate_X_predict(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1441231714, splitter='best'), X=<1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>, check_input=True)\n    360         if self.tree_ is None:\n    361             raise NotFittedError(\"Estimator not fitted, \"\n    362                                  \"call `fit` before exploiting the model.\")\n    363 \n    364         if check_input:\n--> 365             X = check_array(X, dtype=DTYPE, accept_sparse=\"csr\")\n        X = <1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>\n    366             if issparse(X) and (X.indices.dtype != np.intc or\n    367                                 X.indptr.dtype != np.intc):\n    368                 raise ValueError(\"No support for np.int64 index based \"\n    369                                  \"sparse matrices\")\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array=<1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>, accept_sparse=['csr'], dtype=<class 'numpy.float32'>, order=None, copy=False, force_all_finite=True, ensure_2d=True, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)\n    375         estimator_name = \"Estimator\"\n    376     context = \" by %s\" % estimator_name if estimator is not None else \"\"\n    377 \n    378     if sp.issparse(array):\n    379         array = _ensure_sparse_format(array, accept_sparse, dtype, copy,\n--> 380                                       force_all_finite)\n        force_all_finite = True\n    381     else:\n    382         array = np.array(array, dtype=dtype, order=order, copy=copy)\n    383 \n    384         if ensure_2d:\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/utils/validation.py in _ensure_sparse_format(spmatrix=<1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>, accept_sparse=['csr'], dtype=<class 'numpy.float32'>, copy=False, force_all_finite=True)\n    253         spmatrix = spmatrix.asformat(accept_sparse[0])\n    254         changed_format = True\n    255 \n    256     if dtype != spmatrix.dtype:\n    257         # convert dtype\n--> 258         spmatrix = spmatrix.astype(dtype)\n        spmatrix = <1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>\n        spmatrix.astype = <bound method _data_matrix.astype of <1267x62200...stored elements in Compressed Sparse Row format>>\n        dtype = <class 'numpy.float32'>\n    259     elif copy and not changed_format:\n    260         # force copy\n    261         spmatrix = spmatrix.copy()\n    262 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/scipy/sparse/data.py in astype(self=<1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>, t=<class 'numpy.float32'>)\n     63             return self\n     64         else:\n     65             return NotImplemented\n     66 \n     67     def astype(self, t):\n---> 68         return self._with_data(self._deduped_data().astype(t))\n        self._with_data = <bound method _cs_matrix._with_data of <1267x622...stored elements in Compressed Sparse Row format>>\n        self._deduped_data.astype = undefined\n        t = <class 'numpy.float32'>\n     69 \n     70     astype.__doc__ = spmatrix.astype.__doc__\n     71 \n     72     def conj(self):\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/scipy/sparse/data.py in _deduped_data(self=<1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>)\n     29         self.data.dtype = newtype\n     30     dtype = property(fget=_get_dtype, fset=_set_dtype)\n     31 \n     32     def _deduped_data(self):\n     33         if hasattr(self, 'sum_duplicates'):\n---> 34             self.sum_duplicates()\n        self.sum_duplicates = <bound method _cs_matrix.sum_duplicates of <1267...stored elements in Compressed Sparse Row format>>\n     35         return self.data\n     36 \n     37     def __abs__(self):\n     38         return self._with_data(abs(self._deduped_data()))\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/scipy/sparse/compressed.py in sum_duplicates(self=<1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>)\n   1011 \n   1012         The is an *in place* operation\n   1013         \"\"\"\n   1014         if self.has_canonical_format:\n   1015             return\n-> 1016         self.sort_indices()\n        self.sort_indices = <bound method _cs_matrix.sort_indices of <1267x6...stored elements in Compressed Sparse Row format>>\n   1017 \n   1018         M, N = self._swap(self.shape)\n   1019         _sparsetools.csr_sum_duplicates(M, N, self.indptr, self.indices,\n   1020                                         self.data)\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/scipy/sparse/compressed.py in sort_indices(self=<1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>)\n   1057         \"\"\"Sort the indices of this matrix *in place*\n   1058         \"\"\"\n   1059 \n   1060         if not self.has_sorted_indices:\n   1061             _sparsetools.csr_sort_indices(len(self.indptr) - 1, self.indptr,\n-> 1062                                           self.indices, self.data)\n        self.indices = memmap([40112, 31916,  7520, ..., 33149, 16533, 28279], dtype=int32)\n        self.data = memmap([ 0.01903084,  0.0253219 ,  0.04890401, ...,  0.04318216,\n        0.04005177,  0.04318216])\n   1063             self.has_sorted_indices = True\n   1064 \n   1065     def prune(self):\n   1066         \"\"\"Remove empty space after all non-zero elements.\n\nValueError: UPDATEIFCOPY base is read-only\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-4d700f445c49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mens_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_tfidf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Ensemble mean absolute error: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_binary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mens_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/ensemble/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    742\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/ensemble/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    265\u001b[0m             \u001b[0mpredictions\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfinal\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \"\"\"\n\u001b[0;32m--> 267\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'predict'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/ensemble/base.py\u001b[0m in \u001b[0;36m_predict\u001b[0;34m(self, X, job, *args, **kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;31m# Predict with ensemble\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m             \u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_preds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/parallel/manager.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlyr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_partial_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlyr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparallel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__fitted__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/parallel/manager.py\u001b[0m in \u001b[0;36m_partial_process\u001b[0;34m(self, n, lyr, parallel)\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'P'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m         \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/parallel/estimation.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, P, parallel)\u001b[0m\n\u001b[1;32m    227\u001b[0m                                       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m                                       attr=pred_method)\n\u001b[0;32m--> 229\u001b[0;31m                  for case, (inst_name, est, (_, col)) in ests)\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    766\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x7f75a5c8c0c0, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/anthonyle/anaconda3/envs/deep_learning/lib...ges/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/anthon.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7f75a5c8c0c0, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/anthonyle/anaconda3/envs/deep_learning/lib...ges/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/anthon.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n     17 \n     18 \n     19 \n     20 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'ens_pred = ens.predict(X_test_tfidf)\\nprint(\"Ense...at(mean_absolute_error(y_test_binary, ens_pred)))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 6, 25, 9, 36, 42, 416722, tzinfo=datetime.timezone.utc), 'msg_id': '98861FABD69640DF982C5221FE60A189', 'msg_type': 'execute_request', 'session': '55AD9960AF514B44A33856CD0CDB88E6', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '98861FABD69640DF982C5221FE60A189', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'55AD9960AF514B44A33856CD0CDB88E6']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'ens_pred = ens.predict(X_test_tfidf)\\nprint(\"Ense...at(mean_absolute_error(y_test_binary, ens_pred)))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 6, 25, 9, 36, 42, 416722, tzinfo=datetime.timezone.utc), 'msg_id': '98861FABD69640DF982C5221FE60A189', 'msg_type': 'execute_request', 'session': '55AD9960AF514B44A33856CD0CDB88E6', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '98861FABD69640DF982C5221FE60A189', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'55AD9960AF514B44A33856CD0CDB88E6'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'ens_pred = ens.predict(X_test_tfidf)\\nprint(\"Ense...at(mean_absolute_error(y_test_binary, ens_pred)))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 6, 25, 9, 36, 42, 416722, tzinfo=datetime.timezone.utc), 'msg_id': '98861FABD69640DF982C5221FE60A189', 'msg_type': 'execute_request', 'session': '55AD9960AF514B44A33856CD0CDB88E6', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '98861FABD69640DF982C5221FE60A189', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='ens_pred = ens.predict(X_test_tfidf)\\nprint(\"Ense...at(mean_absolute_error(y_test_binary, ens_pred)))', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'ens_pred = ens.predict(X_test_tfidf)\\nprint(\"Ense...at(mean_absolute_error(y_test_binary, ens_pred)))'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('ens_pred = ens.predict(X_test_tfidf)\\nprint(\"Ense...at(mean_absolute_error(y_test_binary, ens_pred)))',), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('ens_pred = ens.predict(X_test_tfidf)\\nprint(\"Ense...at(mean_absolute_error(y_test_binary, ens_pred)))',)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='ens_pred = ens.predict(X_test_tfidf)\\nprint(\"Ense...at(mean_absolute_error(y_test_binary, ens_pred)))', store_history=True, silent=False, shell_futures=True)\n   2693                 self.displayhook.exec_result = result\n   2694 \n   2695                 # Execute the user code\n   2696                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2697                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2698                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2699                 \n   2700                 self.last_execution_succeeded = not has_raised\n   2701 \n   2702                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-112-4d700f445c49>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7f755be816a0, executi..._before_exec=None error_in_exec=None result=None>)\n   2797 \n   2798         try:\n   2799             for i, node in enumerate(to_run_exec):\n   2800                 mod = ast.Module([node])\n   2801                 code = compiler(mod, cell_name, \"exec\")\n-> 2802                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f7567666a50, file \"<ipython-input-112-4d700f445c49>\", line 1>\n        result = <ExecutionResult object at 7f755be816a0, executi..._before_exec=None error_in_exec=None result=None>\n   2803                     return True\n   2804 \n   2805             for i, node in enumerate(to_run_interactive):\n   2806                 mod = ast.Interactive([node])\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f7567666a50, file \"<ipython-input-112-4d700f445c49>\", line 1>, result=<ExecutionResult object at 7f755be816a0, executi..._before_exec=None error_in_exec=None result=None>)\n   2857         outflag = True  # happens in more places, so it's easier as default\n   2858         try:\n   2859             try:\n   2860                 self.hooks.pre_run_code_hook()\n   2861                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2862                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f7567666a50, file \"<ipython-input-112-4d700f445c49>\", line 1>\n        self.user_global_ns = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'EnsembleTransformer': <class 'mlens.preprocessing.ensemble_transformer.EnsembleTransformer'>, 'Evaluator': <class 'mlens.model_selection.model_selection.Evaluator'>, 'In': ['', \"import pandas as pd\\nfake_real_df = pd.read_csv('./fake_or_real_news.csv')\", \"fake_real_df_clean = fake_real_df[['title','text','label']]\", 'from sklearn.model_selection import StratifiedSh...rat_test_set = fake_real_df_clean.loc[test_index]', 'strat_fake_or_real_train = strat_train_set.copy()\\nstrat_fake_or_real_test  = strat_test_set.copy()', \"X_train = strat_fake_or_real_train.copy().drop('...y_test  = strat_fake_or_real_test.copy()['label']\", \"import nltk\\nfrom nltk.corpus import stopwords\\nfr...t = ' '.join(tokens)\\n    return preprocessed_text\", \"X_train_text_list  = list(X_train['text'])\\nX_tra...ext'])\\nX_test_title_list  = list(X_test['title'])\", 'X_train_text_clean = [preprocessing(text) for te...reprocessing(text) for text in X_test_title_list]', 'nltk.download()', \"import pandas as pd\\nfake_real_df = pd.read_csv('./fake_or_real_news.csv')\", \"fake_real_df_clean = fake_real_df[['title','text','label']]\", 'from sklearn.model_selection import StratifiedSh...rat_test_set = fake_real_df_clean.loc[test_index]', 'strat_fake_or_real_train = strat_train_set.copy()\\nstrat_fake_or_real_test  = strat_test_set.copy()', \"X_train = strat_fake_or_real_train.copy().drop('...y_test  = strat_fake_or_real_test.copy()['label']\", \"import nltk\\nfrom nltk.corpus import stopwords\\nfr...t = ' '.join(tokens)\\n    return preprocessed_text\", \"X_train_text_list  = list(X_train['text'])\\nX_tra...ext'])\\nX_test_title_list  = list(X_test['title'])\", 'X_train_text_clean = [preprocessing(text) for te...reprocessing(text) for text in X_test_title_list]', \"y_train_binary = [x=='REAL' for x in list(y_trai...y_test_binary = [x=='REAL' for x in list(y_test)]\", \"'''\\nThe code above is all cleaning.\\nI separated ...fit_transform(X_train_text_clean, y_train_binary)\", ...], 'LancasterStemmer': <class 'nltk.stem.lancaster.LancasterStemmer'>, 'LarsCV': <class 'sklearn.linear_model.least_angle.LarsCV'>, 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'Out': {9: True, 21: array([ 0.82955665,  0.82741617,  0.82329714,  0.81342547,  0.83119447]), 22: '\\nIt is now up to you to use the data as you wish...ll going to work on improving the current model.\\n', 29: <5068x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, 30: <1x286760 sparse matrix of type '<class 'numpy.f... stored elements in Compressed Sparse Row format>, 31: (5068, 286760), 32: 5068, 36: <class 'int'>, 37: 4, 38: <class 'int'>, ...}, 'P':         rfc    mnb    abc  Truth\n0      True   T...lse  False  False  False\n\n[5068 rows x 4 columns], 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, ...}\n        self.user_ns = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'EnsembleTransformer': <class 'mlens.preprocessing.ensemble_transformer.EnsembleTransformer'>, 'Evaluator': <class 'mlens.model_selection.model_selection.Evaluator'>, 'In': ['', \"import pandas as pd\\nfake_real_df = pd.read_csv('./fake_or_real_news.csv')\", \"fake_real_df_clean = fake_real_df[['title','text','label']]\", 'from sklearn.model_selection import StratifiedSh...rat_test_set = fake_real_df_clean.loc[test_index]', 'strat_fake_or_real_train = strat_train_set.copy()\\nstrat_fake_or_real_test  = strat_test_set.copy()', \"X_train = strat_fake_or_real_train.copy().drop('...y_test  = strat_fake_or_real_test.copy()['label']\", \"import nltk\\nfrom nltk.corpus import stopwords\\nfr...t = ' '.join(tokens)\\n    return preprocessed_text\", \"X_train_text_list  = list(X_train['text'])\\nX_tra...ext'])\\nX_test_title_list  = list(X_test['title'])\", 'X_train_text_clean = [preprocessing(text) for te...reprocessing(text) for text in X_test_title_list]', 'nltk.download()', \"import pandas as pd\\nfake_real_df = pd.read_csv('./fake_or_real_news.csv')\", \"fake_real_df_clean = fake_real_df[['title','text','label']]\", 'from sklearn.model_selection import StratifiedSh...rat_test_set = fake_real_df_clean.loc[test_index]', 'strat_fake_or_real_train = strat_train_set.copy()\\nstrat_fake_or_real_test  = strat_test_set.copy()', \"X_train = strat_fake_or_real_train.copy().drop('...y_test  = strat_fake_or_real_test.copy()['label']\", \"import nltk\\nfrom nltk.corpus import stopwords\\nfr...t = ' '.join(tokens)\\n    return preprocessed_text\", \"X_train_text_list  = list(X_train['text'])\\nX_tra...ext'])\\nX_test_title_list  = list(X_test['title'])\", 'X_train_text_clean = [preprocessing(text) for te...reprocessing(text) for text in X_test_title_list]', \"y_train_binary = [x=='REAL' for x in list(y_trai...y_test_binary = [x=='REAL' for x in list(y_test)]\", \"'''\\nThe code above is all cleaning.\\nI separated ...fit_transform(X_train_text_clean, y_train_binary)\", ...], 'LancasterStemmer': <class 'nltk.stem.lancaster.LancasterStemmer'>, 'LarsCV': <class 'sklearn.linear_model.least_angle.LarsCV'>, 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'Out': {9: True, 21: array([ 0.82955665,  0.82741617,  0.82329714,  0.81342547,  0.83119447]), 22: '\\nIt is now up to you to use the data as you wish...ll going to work on improving the current model.\\n', 29: <5068x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, 30: <1x286760 sparse matrix of type '<class 'numpy.f... stored elements in Compressed Sparse Row format>, 31: (5068, 286760), 32: 5068, 36: <class 'int'>, 37: 4, 38: <class 'int'>, ...}, 'P':         rfc    mnb    abc  Truth\n0      True   T...lse  False  False  False\n\n[5068 rows x 4 columns], 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, ...}\n   2863             finally:\n   2864                 # Reset our crash handler in place\n   2865                 sys.excepthook = old_excepthook\n   2866         except SystemExit as e:\n\n...........................................................................\n/mnt/Linux-Extra/home-extra/Anthony.Le/Projects/fake_news/<ipython-input-112-4d700f445c49> in <module>()\n----> 1 \n      2 \n      3 \n      4 \n      5 \n      6 ens_pred = ens.predict(X_test_tfidf)\n      7 print(\"Ensemble mean absolute error: {0}\".format(mean_absolute_error(y_test_binary, ens_pred)))\n      8 \n      9 \n     10 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/ensemble/base.py in predict(self=SuperLearner(array_check=2, backend='threading',...ne, scorer=None,\n       shuffle=False, verbose=5), X=<1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>)\n    739         if self.shuffle:\n    740             r = check_random_state(self.random_state)\n    741             idx = r.permutation(X.shape[0])\n    742             X = X[idx]\n    743 \n--> 744         y = self.layers.predict(X)\n        y = undefined\n        self.layers.predict = <bound method LayerContainer.predict of LayerCon...  n_jobs=-1, raise_on_exception=True, verbose=5)>\n        X = <1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>\n    745 \n    746         if y.shape[1] == 1:\n    747             # The meta estimator is treated as a layer and thus a prediction\n    748             # matrix with shape [n_samples, 1] is created. Ravel before return\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/ensemble/base.py in predict(self=LayerContainer(backend='threading',\n        laye...   n_jobs=-1, raise_on_exception=True, verbose=5), X=<1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>, *args=(), **kwargs={})\n    262         Returns\n    263         -------\n    264         X_pred : array-like of shape = [n_samples, n_fitted_estimators]\n    265             predictions from final layer.\n    266         \"\"\"\n--> 267         return self._predict(X, 'predict', *args, **kwargs)\n        self._predict = <bound method LayerContainer._predict of LayerCo...  n_jobs=-1, raise_on_exception=True, verbose=5)>\n        X = <1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>\n        args = ()\n        kwargs = {}\n    268 \n    269     def transform(self, X=None, *args, **kwargs):\n    270         \"\"\"Generic method for reproducing predictions of the ``fit`` call.\n    271 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/ensemble/base.py in _predict(self=LayerContainer(backend='threading',\n        laye...   n_jobs=-1, raise_on_exception=True, verbose=5), X=<1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>, job='predict', *args=(), **kwargs={})\n    315         processor = ParallelProcessing(self)\n    316         processor.initialize(job, X, *args, **kwargs)\n    317 \n    318         # Predict with ensemble\n    319         try:\n--> 320             processor.process()\n        processor.process = <bound method ParallelProcessing.process of <mlens.parallel.manager.ParallelProcessing object>>\n    321 \n    322             preds = processor.get_preds()\n    323 \n    324             if self.verbose:\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/parallel/manager.py in process(self=<mlens.parallel.manager.ParallelProcessing object>)\n    213                       mmap_mode='w+',\n    214                       verbose=self.layers.verbose,\n    215                       backend=self.layers.backend) as parallel:\n    216 \n    217             for n, lyr in enumerate(self.layers.layers.values()):\n--> 218                 self._partial_process(n, lyr, parallel)\n        self._partial_process = <bound method ParallelProcessing._partial_proces...lens.parallel.manager.ParallelProcessing object>>\n        n = 0\n        lyr = Layer(cls='stack', cls_kwargs=None,\n   estimator... raise_on_exception=True, scorer=None, verbose=5)\n        parallel = Parallel(n_jobs=-1)\n    219 \n    220         self.__fitted__ = 1\n    221 \n    222     def get_preds(self, n=-1, dtype=np.float, order='C'):\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/parallel/manager.py in _partial_process(self=<mlens.parallel.manager.ParallelProcessing object>, n=0, lyr=Layer(cls='stack', cls_kwargs=None,\n   estimator... raise_on_exception=True, scorer=None, verbose=5), parallel=Parallel(n_jobs=-1))\n    303         if 'X' in fargs:\n    304             kwargs['X'] = self.job.P[n]\n    305         if 'P' in fargs:\n    306             kwargs['P'] = self.job.P[n + 1]\n    307 \n--> 308         f(**kwargs)\n        f = <bound method BaseEstimator.predict of <mlens.parallel.stack.Stacker object>>\n        kwargs = {'P': memmap([[ 0.,  0.,  0.],\n       [ 0.,  0.,  0.],...\n       [ 0.,  0.,  0.],\n       [ 0.,  0.,  0.]]), 'X': <1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>, 'parallel': Parallel(n_jobs=-1)}\n    309 \n    310 \n    311 ###############################################################################\n    312 class ParallelEvaluation(object):\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/parallel/estimation.py in predict(self=<mlens.parallel.stack.Stacker object>, X=<1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>, P=memmap([[ 0.,  0.,  0.],\n       [ 0.,  0.,  0.],...\n       [ 0.,  0.,  0.],\n       [ 0.,  0.,  0.]]), parallel=Parallel(n_jobs=-1))\n    224                                       xtest=X,\n    225                                       pred=P,\n    226                                       col=col,\n    227                                       name=self.name,\n    228                                       attr=pred_method)\n--> 229                  for case, (inst_name, est, (_, col)) in ests)\n        ests = [(None, ('rfc', RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), (None, 0))), (None, ('mnb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), (None, 1))), (None, ('abc', AdaBoostClassifier(algorithm='SAMME.R', base_est...ing_rate=1.0, n_estimators=50, random_state=None), (None, 2)))]\n    230 \n    231         if self.verbose:\n    232             print_time(t0, '%s Done' % self.name, file=printout)\n    233 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseEstimator.predict.<locals>.<genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Sun Jun 25 02:36:42 2017\nPID: 16426Python 3.6.1: /home/anthonyle/anaconda3/envs/deep_learning/bin/python\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/externals/joblib/parallel.py in __call__(self=<mlens.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function predict_est>, (), {'attr': 'predict', 'case': None, 'col': 0, 'est': RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), 'inst_name': 'rfc', 'name': 'layer-1', 'pred': memmap([[ 0.,  0.,  0.],\n       [ 0.,  0.,  0.],...\n       [ 0.,  0.,  0.],\n       [ 0.,  0.,  0.]]), 'tr_list': [], 'xtest': <1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function predict_est>\n        args = ()\n        kwargs = {'attr': 'predict', 'case': None, 'col': 0, 'est': RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), 'inst_name': 'rfc', 'name': 'layer-1', 'pred': memmap([[ 0.,  0.,  0.],\n       [ 0.,  0.,  0.],...\n       [ 0.,  0.,  0.],\n       [ 0.,  0.,  0.]]), 'tr_list': [], 'xtest': <1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/parallel/estimation.py in predict_est(case=None, tr_list=[], inst_name='rfc', est=RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), xtest=<1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>, pred=memmap([[ 0.,  0.,  0.],\n       [ 0.,  0.,  0.],...\n       [ 0.,  0.,  0.],\n       [ 0.,  0.,  0.]]), col=0, name='layer-1', attr='predict')\n    402 \n    403     # Predict into memmap\n    404     # Here, we coerce errors on failed predictions - all predictors that\n    405     # survive into the estimators_ attribute of a layer should be able to\n    406     # predict, otherwise the subsequent layer will get corrupt input.\n--> 407     p = getattr(est, attr)(xtest)\n        p = undefined\n        est = RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False)\n        attr = 'predict'\n        xtest = <1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>\n    408 \n    409     if len(p.shape) == 1:\n    410         pred[:, col] = p\n    411     else:\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/ensemble/forest.py in predict(self=RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), X=<1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>)\n    529         Returns\n    530         -------\n    531         y : array of shape = [n_samples] or [n_samples, n_outputs]\n    532             The predicted classes.\n    533         \"\"\"\n--> 534         proba = self.predict_proba(X)\n        proba = undefined\n        self.predict_proba = <bound method ForestClassifier.predict_proba of ...e=None,\n            verbose=0, warm_start=False)>\n        X = <1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>\n    535 \n    536         if self.n_outputs_ == 1:\n    537             return self.classes_.take(np.argmax(proba, axis=1), axis=0)\n    538 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/ensemble/forest.py in predict_proba(self=RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), X=<1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>)\n    568             such arrays if n_outputs > 1.\n    569             The class probabilities of the input samples. The order of the\n    570             classes corresponds to that in the attribute `classes_`.\n    571         \"\"\"\n    572         # Check data\n--> 573         X = self._validate_X_predict(X)\n        X = <1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>\n        self._validate_X_predict = <bound method BaseForest._validate_X_predict of ...e=None,\n            verbose=0, warm_start=False)>\n    574 \n    575         # Assign chunk of trees to jobs\n    576         n_jobs, _, _ = _partition_estimators(self.n_estimators, self.n_jobs)\n    577 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/ensemble/forest.py in _validate_X_predict(self=RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), X=<1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>)\n    350         \"\"\"Validate X whenever one tries to predict, apply, predict_proba\"\"\"\n    351         if self.estimators_ is None or len(self.estimators_) == 0:\n    352             raise NotFittedError(\"Estimator not fitted, \"\n    353                                  \"call `fit` before exploiting the model.\")\n    354 \n--> 355         return self.estimators_[0]._validate_X_predict(X, check_input=True)\n        self.estimators_._validate_X_predict = undefined\n        X = <1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>\n    356 \n    357     @property\n    358     def feature_importances_(self):\n    359         \"\"\"Return the feature importances (the higher, the more important the\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/tree/tree.py in _validate_X_predict(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1441231714, splitter='best'), X=<1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>, check_input=True)\n    360         if self.tree_ is None:\n    361             raise NotFittedError(\"Estimator not fitted, \"\n    362                                  \"call `fit` before exploiting the model.\")\n    363 \n    364         if check_input:\n--> 365             X = check_array(X, dtype=DTYPE, accept_sparse=\"csr\")\n        X = <1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>\n    366             if issparse(X) and (X.indices.dtype != np.intc or\n    367                                 X.indptr.dtype != np.intc):\n    368                 raise ValueError(\"No support for np.int64 index based \"\n    369                                  \"sparse matrices\")\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array=<1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>, accept_sparse=['csr'], dtype=<class 'numpy.float32'>, order=None, copy=False, force_all_finite=True, ensure_2d=True, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)\n    375         estimator_name = \"Estimator\"\n    376     context = \" by %s\" % estimator_name if estimator is not None else \"\"\n    377 \n    378     if sp.issparse(array):\n    379         array = _ensure_sparse_format(array, accept_sparse, dtype, copy,\n--> 380                                       force_all_finite)\n        force_all_finite = True\n    381     else:\n    382         array = np.array(array, dtype=dtype, order=order, copy=copy)\n    383 \n    384         if ensure_2d:\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/utils/validation.py in _ensure_sparse_format(spmatrix=<1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>, accept_sparse=['csr'], dtype=<class 'numpy.float32'>, copy=False, force_all_finite=True)\n    253         spmatrix = spmatrix.asformat(accept_sparse[0])\n    254         changed_format = True\n    255 \n    256     if dtype != spmatrix.dtype:\n    257         # convert dtype\n--> 258         spmatrix = spmatrix.astype(dtype)\n        spmatrix = <1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>\n        spmatrix.astype = <bound method _data_matrix.astype of <1267x62200...stored elements in Compressed Sparse Row format>>\n        dtype = <class 'numpy.float32'>\n    259     elif copy and not changed_format:\n    260         # force copy\n    261         spmatrix = spmatrix.copy()\n    262 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/scipy/sparse/data.py in astype(self=<1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>, t=<class 'numpy.float32'>)\n     63             return self\n     64         else:\n     65             return NotImplemented\n     66 \n     67     def astype(self, t):\n---> 68         return self._with_data(self._deduped_data().astype(t))\n        self._with_data = <bound method _cs_matrix._with_data of <1267x622...stored elements in Compressed Sparse Row format>>\n        self._deduped_data.astype = undefined\n        t = <class 'numpy.float32'>\n     69 \n     70     astype.__doc__ = spmatrix.astype.__doc__\n     71 \n     72     def conj(self):\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/scipy/sparse/data.py in _deduped_data(self=<1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>)\n     29         self.data.dtype = newtype\n     30     dtype = property(fget=_get_dtype, fset=_set_dtype)\n     31 \n     32     def _deduped_data(self):\n     33         if hasattr(self, 'sum_duplicates'):\n---> 34             self.sum_duplicates()\n        self.sum_duplicates = <bound method _cs_matrix.sum_duplicates of <1267...stored elements in Compressed Sparse Row format>>\n     35         return self.data\n     36 \n     37     def __abs__(self):\n     38         return self._with_data(abs(self._deduped_data()))\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/scipy/sparse/compressed.py in sum_duplicates(self=<1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>)\n   1011 \n   1012         The is an *in place* operation\n   1013         \"\"\"\n   1014         if self.has_canonical_format:\n   1015             return\n-> 1016         self.sort_indices()\n        self.sort_indices = <bound method _cs_matrix.sort_indices of <1267x6...stored elements in Compressed Sparse Row format>>\n   1017 \n   1018         M, N = self._swap(self.shape)\n   1019         _sparsetools.csr_sum_duplicates(M, N, self.indptr, self.indices,\n   1020                                         self.data)\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/scipy/sparse/compressed.py in sort_indices(self=<1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>)\n   1057         \"\"\"Sort the indices of this matrix *in place*\n   1058         \"\"\"\n   1059 \n   1060         if not self.has_sorted_indices:\n   1061             _sparsetools.csr_sort_indices(len(self.indptr) - 1, self.indptr,\n-> 1062                                           self.indices, self.data)\n        self.indices = memmap([40112, 31916,  7520, ..., 33149, 16533, 28279], dtype=int32)\n        self.data = memmap([ 0.01903084,  0.0253219 ,  0.04890401, ...,  0.04318216,\n        0.04005177,  0.04318216])\n   1063             self.has_sorted_indices = True\n   1064 \n   1065     def prune(self):\n   1066         \"\"\"Remove empty space after all non-zero elements.\n\nValueError: UPDATEIFCOPY base is read-only\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "ens_pred = ens.predict(X_test_tfidf)\n",
    "print(\"Ensemble mean absolute error: {0}\".format(mean_absolute_error(y_test_binary, ens_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing layers (2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting layer-1\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    0.2s remaining:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   9 | elapsed:    0.9s remaining:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    1.7s remaining:    0.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit complete | 00:00:19\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   19.1s finished\n",
      "layer-1 Done | 00:00:19\n",
      "\n",
      "Fitting layer-2\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "layer-2 Done | 00:00:00\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing layers (2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting layer-1\n"
     ]
    },
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x7f75a5c8c0c0, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/anthonyle/anaconda3/envs/deep_learning/lib...ges/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/anthon.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7f75a5c8c0c0, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/anthonyle/anaconda3/envs/deep_learning/lib...ges/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/anthon.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n     17 \n     18 \n     19 \n     20 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'from sklearn.model_selection import cross_val_sc..._tfidf, y_train_binary, cv=5, scoring=\"accuracy\")', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 6, 25, 9, 30, 44, 209328, tzinfo=datetime.timezone.utc), 'msg_id': '94F9EAB6938145C09C5F4C0A42C6ABC9', 'msg_type': 'execute_request', 'session': '55AD9960AF514B44A33856CD0CDB88E6', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '94F9EAB6938145C09C5F4C0A42C6ABC9', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'55AD9960AF514B44A33856CD0CDB88E6']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'from sklearn.model_selection import cross_val_sc..._tfidf, y_train_binary, cv=5, scoring=\"accuracy\")', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 6, 25, 9, 30, 44, 209328, tzinfo=datetime.timezone.utc), 'msg_id': '94F9EAB6938145C09C5F4C0A42C6ABC9', 'msg_type': 'execute_request', 'session': '55AD9960AF514B44A33856CD0CDB88E6', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '94F9EAB6938145C09C5F4C0A42C6ABC9', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'55AD9960AF514B44A33856CD0CDB88E6'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'from sklearn.model_selection import cross_val_sc..._tfidf, y_train_binary, cv=5, scoring=\"accuracy\")', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 6, 25, 9, 30, 44, 209328, tzinfo=datetime.timezone.utc), 'msg_id': '94F9EAB6938145C09C5F4C0A42C6ABC9', 'msg_type': 'execute_request', 'session': '55AD9960AF514B44A33856CD0CDB88E6', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '94F9EAB6938145C09C5F4C0A42C6ABC9', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='from sklearn.model_selection import cross_val_sc..._tfidf, y_train_binary, cv=5, scoring=\"accuracy\")', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'from sklearn.model_selection import cross_val_sc..._tfidf, y_train_binary, cv=5, scoring=\"accuracy\")'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('from sklearn.model_selection import cross_val_sc..._tfidf, y_train_binary, cv=5, scoring=\"accuracy\")',), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('from sklearn.model_selection import cross_val_sc..._tfidf, y_train_binary, cv=5, scoring=\"accuracy\")',)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='from sklearn.model_selection import cross_val_sc..._tfidf, y_train_binary, cv=5, scoring=\"accuracy\")', store_history=True, silent=False, shell_futures=True)\n   2693                 self.displayhook.exec_result = result\n   2694 \n   2695                 # Execute the user code\n   2696                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2697                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2698                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2699                 \n   2700                 self.last_execution_succeeded = not has_raised\n   2701 \n   2702                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.ImportFrom object>, <_ast.Expr object>], cell_name='<ipython-input-106-3a7f44104b84>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7f755940dcc0, executi..._before_exec=None error_in_exec=None result=None>)\n   2803                     return True\n   2804 \n   2805             for i, node in enumerate(to_run_interactive):\n   2806                 mod = ast.Interactive([node])\n   2807                 code = compiler(mod, cell_name, \"single\")\n-> 2808                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f7566b519c0, file \"<ipython-input-106-3a7f44104b84>\", line 2>\n        result = <ExecutionResult object at 7f755940dcc0, executi..._before_exec=None error_in_exec=None result=None>\n   2809                     return True\n   2810 \n   2811             # Flush softspace\n   2812             if softspace(sys.stdout, 0):\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f7566b519c0, file \"<ipython-input-106-3a7f44104b84>\", line 2>, result=<ExecutionResult object at 7f755940dcc0, executi..._before_exec=None error_in_exec=None result=None>)\n   2857         outflag = True  # happens in more places, so it's easier as default\n   2858         try:\n   2859             try:\n   2860                 self.hooks.pre_run_code_hook()\n   2861                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2862                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f7566b519c0, file \"<ipython-input-106-3a7f44104b84>\", line 2>\n        self.user_global_ns = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'EnsembleTransformer': <class 'mlens.preprocessing.ensemble_transformer.EnsembleTransformer'>, 'Evaluator': <class 'mlens.model_selection.model_selection.Evaluator'>, 'In': ['', \"import pandas as pd\\nfake_real_df = pd.read_csv('./fake_or_real_news.csv')\", \"fake_real_df_clean = fake_real_df[['title','text','label']]\", 'from sklearn.model_selection import StratifiedSh...rat_test_set = fake_real_df_clean.loc[test_index]', 'strat_fake_or_real_train = strat_train_set.copy()\\nstrat_fake_or_real_test  = strat_test_set.copy()', \"X_train = strat_fake_or_real_train.copy().drop('...y_test  = strat_fake_or_real_test.copy()['label']\", \"import nltk\\nfrom nltk.corpus import stopwords\\nfr...t = ' '.join(tokens)\\n    return preprocessed_text\", \"X_train_text_list  = list(X_train['text'])\\nX_tra...ext'])\\nX_test_title_list  = list(X_test['title'])\", 'X_train_text_clean = [preprocessing(text) for te...reprocessing(text) for text in X_test_title_list]', 'nltk.download()', \"import pandas as pd\\nfake_real_df = pd.read_csv('./fake_or_real_news.csv')\", \"fake_real_df_clean = fake_real_df[['title','text','label']]\", 'from sklearn.model_selection import StratifiedSh...rat_test_set = fake_real_df_clean.loc[test_index]', 'strat_fake_or_real_train = strat_train_set.copy()\\nstrat_fake_or_real_test  = strat_test_set.copy()', \"X_train = strat_fake_or_real_train.copy().drop('...y_test  = strat_fake_or_real_test.copy()['label']\", \"import nltk\\nfrom nltk.corpus import stopwords\\nfr...t = ' '.join(tokens)\\n    return preprocessed_text\", \"X_train_text_list  = list(X_train['text'])\\nX_tra...ext'])\\nX_test_title_list  = list(X_test['title'])\", 'X_train_text_clean = [preprocessing(text) for te...reprocessing(text) for text in X_test_title_list]', \"y_train_binary = [x=='REAL' for x in list(y_trai...y_test_binary = [x=='REAL' for x in list(y_test)]\", \"'''\\nThe code above is all cleaning.\\nI separated ...fit_transform(X_train_text_clean, y_train_binary)\", ...], 'LancasterStemmer': <class 'nltk.stem.lancaster.LancasterStemmer'>, 'LarsCV': <class 'sklearn.linear_model.least_angle.LarsCV'>, 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'Out': {9: True, 21: array([ 0.82955665,  0.82741617,  0.82329714,  0.81342547,  0.83119447]), 22: '\\nIt is now up to you to use the data as you wish...ll going to work on improving the current model.\\n', 29: <5068x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, 30: <1x286760 sparse matrix of type '<class 'numpy.f... stored elements in Compressed Sparse Row format>, 31: (5068, 286760), 32: 5068, 36: <class 'int'>, 37: 4, 38: <class 'int'>, ...}, 'P':         rfc    mnb    abc  Truth\n0      True   T...lse  False  False  False\n\n[5068 rows x 4 columns], 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, ...}\n        self.user_ns = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'EnsembleTransformer': <class 'mlens.preprocessing.ensemble_transformer.EnsembleTransformer'>, 'Evaluator': <class 'mlens.model_selection.model_selection.Evaluator'>, 'In': ['', \"import pandas as pd\\nfake_real_df = pd.read_csv('./fake_or_real_news.csv')\", \"fake_real_df_clean = fake_real_df[['title','text','label']]\", 'from sklearn.model_selection import StratifiedSh...rat_test_set = fake_real_df_clean.loc[test_index]', 'strat_fake_or_real_train = strat_train_set.copy()\\nstrat_fake_or_real_test  = strat_test_set.copy()', \"X_train = strat_fake_or_real_train.copy().drop('...y_test  = strat_fake_or_real_test.copy()['label']\", \"import nltk\\nfrom nltk.corpus import stopwords\\nfr...t = ' '.join(tokens)\\n    return preprocessed_text\", \"X_train_text_list  = list(X_train['text'])\\nX_tra...ext'])\\nX_test_title_list  = list(X_test['title'])\", 'X_train_text_clean = [preprocessing(text) for te...reprocessing(text) for text in X_test_title_list]', 'nltk.download()', \"import pandas as pd\\nfake_real_df = pd.read_csv('./fake_or_real_news.csv')\", \"fake_real_df_clean = fake_real_df[['title','text','label']]\", 'from sklearn.model_selection import StratifiedSh...rat_test_set = fake_real_df_clean.loc[test_index]', 'strat_fake_or_real_train = strat_train_set.copy()\\nstrat_fake_or_real_test  = strat_test_set.copy()', \"X_train = strat_fake_or_real_train.copy().drop('...y_test  = strat_fake_or_real_test.copy()['label']\", \"import nltk\\nfrom nltk.corpus import stopwords\\nfr...t = ' '.join(tokens)\\n    return preprocessed_text\", \"X_train_text_list  = list(X_train['text'])\\nX_tra...ext'])\\nX_test_title_list  = list(X_test['title'])\", 'X_train_text_clean = [preprocessing(text) for te...reprocessing(text) for text in X_test_title_list]', \"y_train_binary = [x=='REAL' for x in list(y_trai...y_test_binary = [x=='REAL' for x in list(y_test)]\", \"'''\\nThe code above is all cleaning.\\nI separated ...fit_transform(X_train_text_clean, y_train_binary)\", ...], 'LancasterStemmer': <class 'nltk.stem.lancaster.LancasterStemmer'>, 'LarsCV': <class 'sklearn.linear_model.least_angle.LarsCV'>, 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'Out': {9: True, 21: array([ 0.82955665,  0.82741617,  0.82329714,  0.81342547,  0.83119447]), 22: '\\nIt is now up to you to use the data as you wish...ll going to work on improving the current model.\\n', 29: <5068x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, 30: <1x286760 sparse matrix of type '<class 'numpy.f... stored elements in Compressed Sparse Row format>, 31: (5068, 286760), 32: 5068, 36: <class 'int'>, 37: 4, 38: <class 'int'>, ...}, 'P':         rfc    mnb    abc  Truth\n0      True   T...lse  False  False  False\n\n[5068 rows x 4 columns], 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, ...}\n   2863             finally:\n   2864                 # Reset our crash handler in place\n   2865                 sys.excepthook = old_excepthook\n   2866         except SystemExit as e:\n\n...........................................................................\n/mnt/Linux-Extra/home-extra/Anthony.Le/Projects/fake_news/<ipython-input-106-3a7f44104b84> in <module>()\n      1 \n----> 2 \n      3 \n      4 \n      5 from sklearn.model_selection import cross_val_score\n      6 cross_val_score(ens, X_train_tfidf, y_train_binary, cv=5, scoring=\"accuracy\")\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in cross_val_score(estimator=SuperLearner(array_check=2, backend='threading',...ne, scorer=None,\n       shuffle=False, verbose=5), X=<5068x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, y=[True, False, False, False, False, False, False, False, True, True, True, False, True, False, True, False, True, True, False, False, ...], groups=None, scoring='accuracy', cv=KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs')\n    135     parallel = Parallel(n_jobs=n_jobs, verbose=verbose,\n    136                         pre_dispatch=pre_dispatch)\n    137     scores = parallel(delayed(_fit_and_score)(clone(estimator), X, y, scorer,\n    138                                               train, test, verbose, None,\n    139                                               fit_params)\n--> 140                       for train, test in cv_iter)\n        cv_iter = [(array([1014, 1015, 1016, ..., 5065, 5066, 5067]), array([   0,    1,    2, ..., 1011, 1012, 1013])), (array([   0,    1,    2, ..., 5065, 5066, 5067]), array([1014, 1015, 1016, ..., 2025, 2026, 2027])), (array([   0,    1,    2, ..., 5065, 5066, 5067]), array([2028, 2029, 2030, ..., 3039, 3040, 3041])), (array([   0,    1,    2, ..., 5065, 5066, 5067]), array([3042, 3043, 3044, ..., 4052, 4053, 4054])), (array([   0,    1,    2, ..., 4052, 4053, 4054]), array([4055, 4056, 4057, ..., 5065, 5066, 5067]))]\n    141     return np.array(scores)[:, 0]\n    142 \n    143 \n    144 def _fit_and_score(estimator, X, y, scorer, train, test, verbose,\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object cross_val_score.<locals>.<genexpr>>)\n    753         self.n_completed_tasks = 0\n    754         try:\n    755             # Only set self._iterating to True if at least a batch\n    756             # was dispatched. In particular this covers the edge\n    757             # case of Parallel used with an exhausted iterator.\n--> 758             while self.dispatch_one_batch(iterator):\n        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>\n        iterator = <generator object cross_val_score.<locals>.<genexpr>>\n    759                 self._iterating = True\n    760             else:\n    761                 self._iterating = False\n    762 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object cross_val_score.<locals>.<genexpr>>)\n    603             tasks = BatchedCalls(itertools.islice(iterator, batch_size))\n    604             if len(tasks) == 0:\n    605                 # No more tasks available in the iterator: tell caller to stop.\n    606                 return False\n    607             else:\n--> 608                 self._dispatch(tasks)\n        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>\n        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    609                 return True\n    610 \n    611     def _print(self, msg, msg_args):\n    612         \"\"\"Display the message on stout or stderr depending on verbosity\"\"\"\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    566         self.n_dispatched_tasks += len(batch)\n    567         self.n_dispatched_batches += 1\n    568 \n    569         dispatch_timestamp = time.time()\n    570         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)\n--> 571         job = self._backend.apply_async(batch, callback=cb)\n        job = undefined\n        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>\n    572         self._jobs.append(job)\n    573 \n    574     def dispatch_next(self):\n    575         \"\"\"Dispatch more data for parallel processing\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)\n    104             raise ValueError('n_jobs == 0 in Parallel has no meaning')\n    105         return 1\n    106 \n    107     def apply_async(self, func, callback=None):\n    108         \"\"\"Schedule a func to be run\"\"\"\n--> 109         result = ImmediateResult(func)\n        result = undefined\n        func = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    110         if callback:\n    111             callback(result)\n    112         return result\n    113 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    321 \n    322 class ImmediateResult(object):\n    323     def __init__(self, batch):\n    324         # Don't delay the application, to avoid keeping the input\n    325         # arguments in memory\n--> 326         self.results = batch()\n        self.results = undefined\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    327 \n    328     def get(self):\n    329         return self.results\n    330 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (SuperLearner(array_check=2, backend='threading',...ne, scorer=None,\n       shuffle=False, verbose=5), <5068x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, [True, False, False, False, False, False, False, False, True, True, True, False, True, False, True, False, True, True, False, False, ...], make_scorer(accuracy_score), array([1014, 1015, 1016, ..., 5065, 5066, 5067]), array([   0,    1,    2, ..., 1011, 1012, 1013]), 0, None, None), {})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (SuperLearner(array_check=2, backend='threading',...ne, scorer=None,\n       shuffle=False, verbose=5), <5068x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, [True, False, False, False, False, False, False, False, True, True, True, False, True, False, True, False, True, True, False, False, ...], make_scorer(accuracy_score), array([1014, 1015, 1016, ..., 5065, 5066, 5067]), array([   0,    1,    2, ..., 1011, 1012, 1013]), 0, None, None)\n        kwargs = {}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=SuperLearner(array_check=2, backend='threading',...ne, scorer=None,\n       shuffle=False, verbose=5), X=<5068x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, y=[True, False, False, False, False, False, False, False, True, True, True, False, True, False, True, False, True, True, False, False, ...], scorer=make_scorer(accuracy_score), train=array([1014, 1015, 1016, ..., 5065, 5066, 5067]), test=array([   0,    1,    2, ..., 1011, 1012, 1013]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=False, error_score='raise')\n    255                              \" numeric value. (Hint: if using 'raise', please\"\n    256                              \" make sure that it has been spelled correctly.)\")\n    257 \n    258     else:\n    259         fit_time = time.time() - start_time\n--> 260         test_score = _score(estimator, X_test, y_test, scorer)\n        test_score = undefined\n        estimator = SuperLearner(array_check=2, backend='threading',...ne, scorer=None,\n       shuffle=False, verbose=5)\n        X_test = <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>\n        y_test = [True, False, False, False, False, False, False, False, True, True, True, False, True, False, True, False, True, True, False, False, ...]\n        scorer = make_scorer(accuracy_score)\n    261         score_time = time.time() - start_time - fit_time\n    262         if return_train_score:\n    263             train_score = _score(estimator, X_train, y_train, scorer)\n    264 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _score(estimator=SuperLearner(array_check=2, backend='threading',...ne, scorer=None,\n       shuffle=False, verbose=5), X_test=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, y_test=[True, False, False, False, False, False, False, False, True, True, True, False, True, False, True, False, True, True, False, False, ...], scorer=make_scorer(accuracy_score))\n    283 def _score(estimator, X_test, y_test, scorer):\n    284     \"\"\"Compute the score of an estimator on a given test set.\"\"\"\n    285     if y_test is None:\n    286         score = scorer(estimator, X_test)\n    287     else:\n--> 288         score = scorer(estimator, X_test, y_test)\n        score = undefined\n        scorer = make_scorer(accuracy_score)\n        estimator = SuperLearner(array_check=2, backend='threading',...ne, scorer=None,\n       shuffle=False, verbose=5)\n        X_test = <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>\n        y_test = [True, False, False, False, False, False, False, False, True, True, True, False, True, False, True, False, True, True, False, False, ...]\n    289     if hasattr(score, 'item'):\n    290         try:\n    291             # e.g. unwrap memmapped scalars\n    292             score = score.item()\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/metrics/scorer.py in __call__(self=make_scorer(accuracy_score), estimator=SuperLearner(array_check=2, backend='threading',...ne, scorer=None,\n       shuffle=False, verbose=5), X=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, y_true=[True, False, False, False, False, False, False, False, True, True, True, False, True, False, True, False, True, True, False, False, ...], sample_weight=None)\n     86         score : float\n     87             Score function applied to prediction of estimator on X.\n     88         \"\"\"\n     89         super(_PredictScorer, self).__call__(estimator, X, y_true,\n     90                                              sample_weight=sample_weight)\n---> 91         y_pred = estimator.predict(X)\n        y_pred = undefined\n        estimator.predict = <bound method BaseEnsemble.predict of SuperLearn...e, scorer=None,\n       shuffle=False, verbose=5)>\n        X = <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>\n     92         if sample_weight is not None:\n     93             return self._sign * self._score_func(y_true, y_pred,\n     94                                                  sample_weight=sample_weight,\n     95                                                  **self._kwargs)\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/ensemble/base.py in predict(self=SuperLearner(array_check=2, backend='threading',...ne, scorer=None,\n       shuffle=False, verbose=5), X=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>)\n    739         if self.shuffle:\n    740             r = check_random_state(self.random_state)\n    741             idx = r.permutation(X.shape[0])\n    742             X = X[idx]\n    743 \n--> 744         y = self.layers.predict(X)\n        y = undefined\n        self.layers.predict = <bound method LayerContainer.predict of LayerCon...  n_jobs=-1, raise_on_exception=True, verbose=5)>\n        X = <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>\n    745 \n    746         if y.shape[1] == 1:\n    747             # The meta estimator is treated as a layer and thus a prediction\n    748             # matrix with shape [n_samples, 1] is created. Ravel before return\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/ensemble/base.py in predict(self=LayerContainer(backend='threading',\n        laye...   n_jobs=-1, raise_on_exception=True, verbose=5), X=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, *args=(), **kwargs={})\n    262         Returns\n    263         -------\n    264         X_pred : array-like of shape = [n_samples, n_fitted_estimators]\n    265             predictions from final layer.\n    266         \"\"\"\n--> 267         return self._predict(X, 'predict', *args, **kwargs)\n        self._predict = <bound method LayerContainer._predict of LayerCo...  n_jobs=-1, raise_on_exception=True, verbose=5)>\n        X = <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>\n        args = ()\n        kwargs = {}\n    268 \n    269     def transform(self, X=None, *args, **kwargs):\n    270         \"\"\"Generic method for reproducing predictions of the ``fit`` call.\n    271 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/ensemble/base.py in _predict(self=LayerContainer(backend='threading',\n        laye...   n_jobs=-1, raise_on_exception=True, verbose=5), X=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, job='predict', *args=(), **kwargs={})\n    315         processor = ParallelProcessing(self)\n    316         processor.initialize(job, X, *args, **kwargs)\n    317 \n    318         # Predict with ensemble\n    319         try:\n--> 320             processor.process()\n        processor.process = <bound method ParallelProcessing.process of <mlens.parallel.manager.ParallelProcessing object>>\n    321 \n    322             preds = processor.get_preds()\n    323 \n    324             if self.verbose:\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/parallel/manager.py in process(self=<mlens.parallel.manager.ParallelProcessing object>)\n    213                       mmap_mode='w+',\n    214                       verbose=self.layers.verbose,\n    215                       backend=self.layers.backend) as parallel:\n    216 \n    217             for n, lyr in enumerate(self.layers.layers.values()):\n--> 218                 self._partial_process(n, lyr, parallel)\n        self._partial_process = <bound method ParallelProcessing._partial_proces...lens.parallel.manager.ParallelProcessing object>>\n        n = 0\n        lyr = Layer(cls='stack', cls_kwargs=None,\n   estimator... raise_on_exception=True, scorer=None, verbose=5)\n        parallel = Parallel(n_jobs=-1)\n    219 \n    220         self.__fitted__ = 1\n    221 \n    222     def get_preds(self, n=-1, dtype=np.float, order='C'):\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/parallel/manager.py in _partial_process(self=<mlens.parallel.manager.ParallelProcessing object>, n=0, lyr=Layer(cls='stack', cls_kwargs=None,\n   estimator... raise_on_exception=True, scorer=None, verbose=5), parallel=Parallel(n_jobs=-1))\n    303         if 'X' in fargs:\n    304             kwargs['X'] = self.job.P[n]\n    305         if 'P' in fargs:\n    306             kwargs['P'] = self.job.P[n + 1]\n    307 \n--> 308         f(**kwargs)\n        f = <bound method BaseEstimator.predict of <mlens.parallel.stack.Stacker object>>\n        kwargs = {'P': memmap([[ 0.,  1.,  0.],\n       [ 0.,  0.,  0.],...\n       [ 0.,  1.,  0.],\n       [ 0.,  1.,  0.]]), 'X': <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, 'parallel': Parallel(n_jobs=-1)}\n    309 \n    310 \n    311 ###############################################################################\n    312 class ParallelEvaluation(object):\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/parallel/estimation.py in predict(self=<mlens.parallel.stack.Stacker object>, X=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, P=memmap([[ 0.,  1.,  0.],\n       [ 0.,  0.,  0.],...\n       [ 0.,  1.,  0.],\n       [ 0.,  1.,  0.]]), parallel=Parallel(n_jobs=-1))\n    224                                       xtest=X,\n    225                                       pred=P,\n    226                                       col=col,\n    227                                       name=self.name,\n    228                                       attr=pred_method)\n--> 229                  for case, (inst_name, est, (_, col)) in ests)\n        ests = [(None, ('rfc', RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), (None, 0))), (None, ('mnb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), (None, 1))), (None, ('abc', AdaBoostClassifier(algorithm='SAMME.R', base_est...ing_rate=1.0, n_estimators=50, random_state=None), (None, 2)))]\n    230 \n    231         if self.verbose:\n    232             print_time(t0, '%s Done' % self.name, file=printout)\n    233 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseEstimator.predict.<locals>.<genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Sun Jun 25 02:31:03 2017\nPID: 16426Python 3.6.1: /home/anthonyle/anaconda3/envs/deep_learning/bin/python\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/externals/joblib/parallel.py in __call__(self=<mlens.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function predict_est>, (), {'attr': 'predict', 'case': None, 'col': 0, 'est': RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), 'inst_name': 'rfc', 'name': 'layer-1', 'pred': memmap([[ 0.,  1.,  0.],\n       [ 0.,  0.,  0.],...\n       [ 0.,  1.,  0.],\n       [ 0.,  1.,  0.]]), 'tr_list': [], 'xtest': <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function predict_est>\n        args = ()\n        kwargs = {'attr': 'predict', 'case': None, 'col': 0, 'est': RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), 'inst_name': 'rfc', 'name': 'layer-1', 'pred': memmap([[ 0.,  1.,  0.],\n       [ 0.,  0.,  0.],...\n       [ 0.,  1.,  0.],\n       [ 0.,  1.,  0.]]), 'tr_list': [], 'xtest': <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/parallel/estimation.py in predict_est(case=None, tr_list=[], inst_name='rfc', est=RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), xtest=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, pred=memmap([[ 0.,  1.,  0.],\n       [ 0.,  0.,  0.],...\n       [ 0.,  1.,  0.],\n       [ 0.,  1.,  0.]]), col=0, name='layer-1', attr='predict')\n    402 \n    403     # Predict into memmap\n    404     # Here, we coerce errors on failed predictions - all predictors that\n    405     # survive into the estimators_ attribute of a layer should be able to\n    406     # predict, otherwise the subsequent layer will get corrupt input.\n--> 407     p = getattr(est, attr)(xtest)\n        p = undefined\n        est = RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False)\n        attr = 'predict'\n        xtest = <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>\n    408 \n    409     if len(p.shape) == 1:\n    410         pred[:, col] = p\n    411     else:\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/ensemble/forest.py in predict(self=RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), X=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>)\n    529         Returns\n    530         -------\n    531         y : array of shape = [n_samples] or [n_samples, n_outputs]\n    532             The predicted classes.\n    533         \"\"\"\n--> 534         proba = self.predict_proba(X)\n        proba = undefined\n        self.predict_proba = <bound method ForestClassifier.predict_proba of ...e=None,\n            verbose=0, warm_start=False)>\n        X = <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>\n    535 \n    536         if self.n_outputs_ == 1:\n    537             return self.classes_.take(np.argmax(proba, axis=1), axis=0)\n    538 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/ensemble/forest.py in predict_proba(self=RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), X=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>)\n    568             such arrays if n_outputs > 1.\n    569             The class probabilities of the input samples. The order of the\n    570             classes corresponds to that in the attribute `classes_`.\n    571         \"\"\"\n    572         # Check data\n--> 573         X = self._validate_X_predict(X)\n        X = <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>\n        self._validate_X_predict = <bound method BaseForest._validate_X_predict of ...e=None,\n            verbose=0, warm_start=False)>\n    574 \n    575         # Assign chunk of trees to jobs\n    576         n_jobs, _, _ = _partition_estimators(self.n_estimators, self.n_jobs)\n    577 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/ensemble/forest.py in _validate_X_predict(self=RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), X=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>)\n    350         \"\"\"Validate X whenever one tries to predict, apply, predict_proba\"\"\"\n    351         if self.estimators_ is None or len(self.estimators_) == 0:\n    352             raise NotFittedError(\"Estimator not fitted, \"\n    353                                  \"call `fit` before exploiting the model.\")\n    354 \n--> 355         return self.estimators_[0]._validate_X_predict(X, check_input=True)\n        self.estimators_._validate_X_predict = undefined\n        X = <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>\n    356 \n    357     @property\n    358     def feature_importances_(self):\n    359         \"\"\"Return the feature importances (the higher, the more important the\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/tree/tree.py in _validate_X_predict(self=DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=537424915, splitter='best'), X=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, check_input=True)\n    360         if self.tree_ is None:\n    361             raise NotFittedError(\"Estimator not fitted, \"\n    362                                  \"call `fit` before exploiting the model.\")\n    363 \n    364         if check_input:\n--> 365             X = check_array(X, dtype=DTYPE, accept_sparse=\"csr\")\n        X = <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>\n    366             if issparse(X) and (X.indices.dtype != np.intc or\n    367                                 X.indptr.dtype != np.intc):\n    368                 raise ValueError(\"No support for np.int64 index based \"\n    369                                  \"sparse matrices\")\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, accept_sparse=['csr'], dtype=<class 'numpy.float32'>, order=None, copy=False, force_all_finite=True, ensure_2d=True, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)\n    375         estimator_name = \"Estimator\"\n    376     context = \" by %s\" % estimator_name if estimator is not None else \"\"\n    377 \n    378     if sp.issparse(array):\n    379         array = _ensure_sparse_format(array, accept_sparse, dtype, copy,\n--> 380                                       force_all_finite)\n        force_all_finite = True\n    381     else:\n    382         array = np.array(array, dtype=dtype, order=order, copy=copy)\n    383 \n    384         if ensure_2d:\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/utils/validation.py in _ensure_sparse_format(spmatrix=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, accept_sparse=['csr'], dtype=<class 'numpy.float32'>, copy=False, force_all_finite=True)\n    253         spmatrix = spmatrix.asformat(accept_sparse[0])\n    254         changed_format = True\n    255 \n    256     if dtype != spmatrix.dtype:\n    257         # convert dtype\n--> 258         spmatrix = spmatrix.astype(dtype)\n        spmatrix = <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>\n        spmatrix.astype = <bound method _data_matrix.astype of <1014x28676...stored elements in Compressed Sparse Row format>>\n        dtype = <class 'numpy.float32'>\n    259     elif copy and not changed_format:\n    260         # force copy\n    261         spmatrix = spmatrix.copy()\n    262 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/scipy/sparse/data.py in astype(self=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, t=<class 'numpy.float32'>)\n     63             return self\n     64         else:\n     65             return NotImplemented\n     66 \n     67     def astype(self, t):\n---> 68         return self._with_data(self._deduped_data().astype(t))\n        self._with_data = <bound method _cs_matrix._with_data of <1014x286...stored elements in Compressed Sparse Row format>>\n        self._deduped_data.astype = undefined\n        t = <class 'numpy.float32'>\n     69 \n     70     astype.__doc__ = spmatrix.astype.__doc__\n     71 \n     72     def conj(self):\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/scipy/sparse/data.py in _deduped_data(self=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>)\n     29         self.data.dtype = newtype\n     30     dtype = property(fget=_get_dtype, fset=_set_dtype)\n     31 \n     32     def _deduped_data(self):\n     33         if hasattr(self, 'sum_duplicates'):\n---> 34             self.sum_duplicates()\n        self.sum_duplicates = <bound method _cs_matrix.sum_duplicates of <1014...stored elements in Compressed Sparse Row format>>\n     35         return self.data\n     36 \n     37     def __abs__(self):\n     38         return self._with_data(abs(self._deduped_data()))\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/scipy/sparse/compressed.py in sum_duplicates(self=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>)\n   1011 \n   1012         The is an *in place* operation\n   1013         \"\"\"\n   1014         if self.has_canonical_format:\n   1015             return\n-> 1016         self.sort_indices()\n        self.sort_indices = <bound method _cs_matrix.sort_indices of <1014x2...stored elements in Compressed Sparse Row format>>\n   1017 \n   1018         M, N = self._swap(self.shape)\n   1019         _sparsetools.csr_sum_duplicates(M, N, self.indptr, self.indices,\n   1020                                         self.data)\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/scipy/sparse/compressed.py in sort_indices(self=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>)\n   1057         \"\"\"Sort the indices of this matrix *in place*\n   1058         \"\"\"\n   1059 \n   1060         if not self.has_sorted_indices:\n   1061             _sparsetools.csr_sort_indices(len(self.indptr) - 1, self.indptr,\n-> 1062                                           self.indices, self.data)\n        self.indices = memmap([285386, 285009, 284390, ...,   1862,   1712,   1709], dtype=int32)\n        self.data = memmap([ 0.04089954,  0.01047909,  0.05310395, ...,  0.03177006,\n        0.02322263,  0.01355832])\n   1063             self.has_sorted_indices = True\n   1064 \n   1065     def prune(self):\n   1066         \"\"\"Remove empty space after all non-zero elements.\n\nValueError: UPDATEIFCOPY base is read-only\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/parallel/estimation.py\u001b[0m in \u001b[0;36mpredict_est\u001b[0;34m(case, tr_list, inst_name, est, xtest, pred, col, name, attr)\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;31m# predict, otherwise the subsequent layer will get corrupt input.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    533\u001b[0m         \"\"\"\n\u001b[0;32m--> 534\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m             if issparse(X) and (X.indices.dtype != np.intc or\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    379\u001b[0m         array = _ensure_sparse_format(array, accept_sparse, dtype, copy,\n\u001b[0;32m--> 380\u001b[0;31m                                       force_all_finite)\n\u001b[0m\u001b[1;32m    381\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_ensure_sparse_format\u001b[0;34m(spmatrix, accept_sparse, dtype, copy, force_all_finite)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;31m# convert dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0mspmatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspmatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchanged_format\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/scipy/sparse/data.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deduped_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/scipy/sparse/data.py\u001b[0m in \u001b[0;36m_deduped_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sum_duplicates'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36msum_duplicates\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1015\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36msort_indices\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m             _sparsetools.csr_sort_indices(len(self.indptr) - 1, self.indptr,\n\u001b[0;32m-> 1062\u001b[0;31m                                           self.indices, self.data)\n\u001b[0m\u001b[1;32m   1063\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_sorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: UPDATEIFCOPY base is read-only",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    681\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m'timeout'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgetfullargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mworker\u001b[0;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat_exc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_tb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTransportableException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nValueError                                         Sun Jun 25 02:31:03 2017\nPID: 16426Python 3.6.1: /home/anthonyle/anaconda3/envs/deep_learning/bin/python\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/externals/joblib/parallel.py in __call__(self=<mlens.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function predict_est>, (), {'attr': 'predict', 'case': None, 'col': 0, 'est': RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), 'inst_name': 'rfc', 'name': 'layer-1', 'pred': memmap([[ 0.,  1.,  0.],\n       [ 0.,  0.,  0.],...\n       [ 0.,  1.,  0.],\n       [ 0.,  1.,  0.]]), 'tr_list': [], 'xtest': <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function predict_est>\n        args = ()\n        kwargs = {'attr': 'predict', 'case': None, 'col': 0, 'est': RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), 'inst_name': 'rfc', 'name': 'layer-1', 'pred': memmap([[ 0.,  1.,  0.],\n       [ 0.,  0.,  0.],...\n       [ 0.,  1.,  0.],\n       [ 0.,  1.,  0.]]), 'tr_list': [], 'xtest': <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/parallel/estimation.py in predict_est(case=None, tr_list=[], inst_name='rfc', est=RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), xtest=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, pred=memmap([[ 0.,  1.,  0.],\n       [ 0.,  0.,  0.],...\n       [ 0.,  1.,  0.],\n       [ 0.,  1.,  0.]]), col=0, name='layer-1', attr='predict')\n    402 \n    403     # Predict into memmap\n    404     # Here, we coerce errors on failed predictions - all predictors that\n    405     # survive into the estimators_ attribute of a layer should be able to\n    406     # predict, otherwise the subsequent layer will get corrupt input.\n--> 407     p = getattr(est, attr)(xtest)\n        p = undefined\n        est = RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False)\n        attr = 'predict'\n        xtest = <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>\n    408 \n    409     if len(p.shape) == 1:\n    410         pred[:, col] = p\n    411     else:\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/ensemble/forest.py in predict(self=RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), X=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>)\n    529         Returns\n    530         -------\n    531         y : array of shape = [n_samples] or [n_samples, n_outputs]\n    532             The predicted classes.\n    533         \"\"\"\n--> 534         proba = self.predict_proba(X)\n        proba = undefined\n        self.predict_proba = <bound method ForestClassifier.predict_proba of ...e=None,\n            verbose=0, warm_start=False)>\n        X = <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>\n    535 \n    536         if self.n_outputs_ == 1:\n    537             return self.classes_.take(np.argmax(proba, axis=1), axis=0)\n    538 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/ensemble/forest.py in predict_proba(self=RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), X=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>)\n    568             such arrays if n_outputs > 1.\n    569             The class probabilities of the input samples. The order of the\n    570             classes corresponds to that in the attribute `classes_`.\n    571         \"\"\"\n    572         # Check data\n--> 573         X = self._validate_X_predict(X)\n        X = <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>\n        self._validate_X_predict = <bound method BaseForest._validate_X_predict of ...e=None,\n            verbose=0, warm_start=False)>\n    574 \n    575         # Assign chunk of trees to jobs\n    576         n_jobs, _, _ = _partition_estimators(self.n_estimators, self.n_jobs)\n    577 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/ensemble/forest.py in _validate_X_predict(self=RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), X=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>)\n    350         \"\"\"Validate X whenever one tries to predict, apply, predict_proba\"\"\"\n    351         if self.estimators_ is None or len(self.estimators_) == 0:\n    352             raise NotFittedError(\"Estimator not fitted, \"\n    353                                  \"call `fit` before exploiting the model.\")\n    354 \n--> 355         return self.estimators_[0]._validate_X_predict(X, check_input=True)\n        self.estimators_._validate_X_predict = undefined\n        X = <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>\n    356 \n    357     @property\n    358     def feature_importances_(self):\n    359         \"\"\"Return the feature importances (the higher, the more important the\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/tree/tree.py in _validate_X_predict(self=DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=537424915, splitter='best'), X=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, check_input=True)\n    360         if self.tree_ is None:\n    361             raise NotFittedError(\"Estimator not fitted, \"\n    362                                  \"call `fit` before exploiting the model.\")\n    363 \n    364         if check_input:\n--> 365             X = check_array(X, dtype=DTYPE, accept_sparse=\"csr\")\n        X = <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>\n    366             if issparse(X) and (X.indices.dtype != np.intc or\n    367                                 X.indptr.dtype != np.intc):\n    368                 raise ValueError(\"No support for np.int64 index based \"\n    369                                  \"sparse matrices\")\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, accept_sparse=['csr'], dtype=<class 'numpy.float32'>, order=None, copy=False, force_all_finite=True, ensure_2d=True, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)\n    375         estimator_name = \"Estimator\"\n    376     context = \" by %s\" % estimator_name if estimator is not None else \"\"\n    377 \n    378     if sp.issparse(array):\n    379         array = _ensure_sparse_format(array, accept_sparse, dtype, copy,\n--> 380                                       force_all_finite)\n        force_all_finite = True\n    381     else:\n    382         array = np.array(array, dtype=dtype, order=order, copy=copy)\n    383 \n    384         if ensure_2d:\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/utils/validation.py in _ensure_sparse_format(spmatrix=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, accept_sparse=['csr'], dtype=<class 'numpy.float32'>, copy=False, force_all_finite=True)\n    253         spmatrix = spmatrix.asformat(accept_sparse[0])\n    254         changed_format = True\n    255 \n    256     if dtype != spmatrix.dtype:\n    257         # convert dtype\n--> 258         spmatrix = spmatrix.astype(dtype)\n        spmatrix = <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>\n        spmatrix.astype = <bound method _data_matrix.astype of <1014x28676...stored elements in Compressed Sparse Row format>>\n        dtype = <class 'numpy.float32'>\n    259     elif copy and not changed_format:\n    260         # force copy\n    261         spmatrix = spmatrix.copy()\n    262 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/scipy/sparse/data.py in astype(self=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, t=<class 'numpy.float32'>)\n     63             return self\n     64         else:\n     65             return NotImplemented\n     66 \n     67     def astype(self, t):\n---> 68         return self._with_data(self._deduped_data().astype(t))\n        self._with_data = <bound method _cs_matrix._with_data of <1014x286...stored elements in Compressed Sparse Row format>>\n        self._deduped_data.astype = undefined\n        t = <class 'numpy.float32'>\n     69 \n     70     astype.__doc__ = spmatrix.astype.__doc__\n     71 \n     72     def conj(self):\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/scipy/sparse/data.py in _deduped_data(self=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>)\n     29         self.data.dtype = newtype\n     30     dtype = property(fget=_get_dtype, fset=_set_dtype)\n     31 \n     32     def _deduped_data(self):\n     33         if hasattr(self, 'sum_duplicates'):\n---> 34             self.sum_duplicates()\n        self.sum_duplicates = <bound method _cs_matrix.sum_duplicates of <1014...stored elements in Compressed Sparse Row format>>\n     35         return self.data\n     36 \n     37     def __abs__(self):\n     38         return self._with_data(abs(self._deduped_data()))\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/scipy/sparse/compressed.py in sum_duplicates(self=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>)\n   1011 \n   1012         The is an *in place* operation\n   1013         \"\"\"\n   1014         if self.has_canonical_format:\n   1015             return\n-> 1016         self.sort_indices()\n        self.sort_indices = <bound method _cs_matrix.sort_indices of <1014x2...stored elements in Compressed Sparse Row format>>\n   1017 \n   1018         M, N = self._swap(self.shape)\n   1019         _sparsetools.csr_sum_duplicates(M, N, self.indptr, self.indices,\n   1020                                         self.data)\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/scipy/sparse/compressed.py in sort_indices(self=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>)\n   1057         \"\"\"Sort the indices of this matrix *in place*\n   1058         \"\"\"\n   1059 \n   1060         if not self.has_sorted_indices:\n   1061             _sparsetools.csr_sort_indices(len(self.indptr) - 1, self.indptr,\n-> 1062                                           self.indices, self.data)\n        self.indices = memmap([285386, 285009, 284390, ...,   1862,   1712,   1709], dtype=int32)\n        self.data = memmap([ 0.04089954,  0.01047909,  0.05310395, ...,  0.03177006,\n        0.02322263,  0.01355832])\n   1063             self.has_sorted_indices = True\n   1064 \n   1065     def prune(self):\n   1066         \"\"\"Remove empty space after all non-zero elements.\n\nValueError: UPDATEIFCOPY base is read-only\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-3a7f44104b84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_tfidf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_binary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m    138\u001b[0m                                               \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                                               fit_params)\n\u001b[0;32m--> 140\u001b[0;31m                       for train, test in cv_iter)\n\u001b[0m\u001b[1;32m    141\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    606\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0mfit_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0mtest_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m         \u001b[0mscore_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfit_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_score\u001b[0;34m(estimator, X_test, y_test, scorer)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'item'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/metrics/scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[1;32m     89\u001b[0m         super(_PredictScorer, self).__call__(estimator, X, y_true,\n\u001b[1;32m     90\u001b[0m                                              sample_weight=sample_weight)\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             return self._sign * self._score_func(y_true, y_pred,\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/ensemble/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    742\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/ensemble/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    265\u001b[0m             \u001b[0mpredictions\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfinal\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \"\"\"\n\u001b[0;32m--> 267\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'predict'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/ensemble/base.py\u001b[0m in \u001b[0;36m_predict\u001b[0;34m(self, X, job, *args, **kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;31m# Predict with ensemble\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m             \u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_preds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/parallel/manager.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlyr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_partial_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlyr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparallel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__fitted__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/parallel/manager.py\u001b[0m in \u001b[0;36m_partial_process\u001b[0;34m(self, n, lyr, parallel)\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'P'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m         \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/parallel/estimation.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, P, parallel)\u001b[0m\n\u001b[1;32m    227\u001b[0m                                       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m                                       attr=pred_method)\n\u001b[0;32m--> 229\u001b[0;31m                  for case, (inst_name, est, (_, col)) in ests)\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    766\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x7f75a5c8c0c0, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/anthonyle/anaconda3/envs/deep_learning/lib...ges/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/anthon.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7f75a5c8c0c0, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/anthonyle/anaconda3/envs/deep_learning/lib...ges/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/anthon.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n     17 \n     18 \n     19 \n     20 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'from sklearn.model_selection import cross_val_sc..._tfidf, y_train_binary, cv=5, scoring=\"accuracy\")', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 6, 25, 9, 30, 44, 209328, tzinfo=datetime.timezone.utc), 'msg_id': '94F9EAB6938145C09C5F4C0A42C6ABC9', 'msg_type': 'execute_request', 'session': '55AD9960AF514B44A33856CD0CDB88E6', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '94F9EAB6938145C09C5F4C0A42C6ABC9', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'55AD9960AF514B44A33856CD0CDB88E6']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'from sklearn.model_selection import cross_val_sc..._tfidf, y_train_binary, cv=5, scoring=\"accuracy\")', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 6, 25, 9, 30, 44, 209328, tzinfo=datetime.timezone.utc), 'msg_id': '94F9EAB6938145C09C5F4C0A42C6ABC9', 'msg_type': 'execute_request', 'session': '55AD9960AF514B44A33856CD0CDB88E6', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '94F9EAB6938145C09C5F4C0A42C6ABC9', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'55AD9960AF514B44A33856CD0CDB88E6'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'from sklearn.model_selection import cross_val_sc..._tfidf, y_train_binary, cv=5, scoring=\"accuracy\")', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 6, 25, 9, 30, 44, 209328, tzinfo=datetime.timezone.utc), 'msg_id': '94F9EAB6938145C09C5F4C0A42C6ABC9', 'msg_type': 'execute_request', 'session': '55AD9960AF514B44A33856CD0CDB88E6', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '94F9EAB6938145C09C5F4C0A42C6ABC9', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='from sklearn.model_selection import cross_val_sc..._tfidf, y_train_binary, cv=5, scoring=\"accuracy\")', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'from sklearn.model_selection import cross_val_sc..._tfidf, y_train_binary, cv=5, scoring=\"accuracy\")'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('from sklearn.model_selection import cross_val_sc..._tfidf, y_train_binary, cv=5, scoring=\"accuracy\")',), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('from sklearn.model_selection import cross_val_sc..._tfidf, y_train_binary, cv=5, scoring=\"accuracy\")',)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='from sklearn.model_selection import cross_val_sc..._tfidf, y_train_binary, cv=5, scoring=\"accuracy\")', store_history=True, silent=False, shell_futures=True)\n   2693                 self.displayhook.exec_result = result\n   2694 \n   2695                 # Execute the user code\n   2696                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2697                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2698                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2699                 \n   2700                 self.last_execution_succeeded = not has_raised\n   2701 \n   2702                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.ImportFrom object>, <_ast.Expr object>], cell_name='<ipython-input-106-3a7f44104b84>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7f755940dcc0, executi..._before_exec=None error_in_exec=None result=None>)\n   2803                     return True\n   2804 \n   2805             for i, node in enumerate(to_run_interactive):\n   2806                 mod = ast.Interactive([node])\n   2807                 code = compiler(mod, cell_name, \"single\")\n-> 2808                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f7566b519c0, file \"<ipython-input-106-3a7f44104b84>\", line 2>\n        result = <ExecutionResult object at 7f755940dcc0, executi..._before_exec=None error_in_exec=None result=None>\n   2809                     return True\n   2810 \n   2811             # Flush softspace\n   2812             if softspace(sys.stdout, 0):\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f7566b519c0, file \"<ipython-input-106-3a7f44104b84>\", line 2>, result=<ExecutionResult object at 7f755940dcc0, executi..._before_exec=None error_in_exec=None result=None>)\n   2857         outflag = True  # happens in more places, so it's easier as default\n   2858         try:\n   2859             try:\n   2860                 self.hooks.pre_run_code_hook()\n   2861                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2862                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f7566b519c0, file \"<ipython-input-106-3a7f44104b84>\", line 2>\n        self.user_global_ns = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'EnsembleTransformer': <class 'mlens.preprocessing.ensemble_transformer.EnsembleTransformer'>, 'Evaluator': <class 'mlens.model_selection.model_selection.Evaluator'>, 'In': ['', \"import pandas as pd\\nfake_real_df = pd.read_csv('./fake_or_real_news.csv')\", \"fake_real_df_clean = fake_real_df[['title','text','label']]\", 'from sklearn.model_selection import StratifiedSh...rat_test_set = fake_real_df_clean.loc[test_index]', 'strat_fake_or_real_train = strat_train_set.copy()\\nstrat_fake_or_real_test  = strat_test_set.copy()', \"X_train = strat_fake_or_real_train.copy().drop('...y_test  = strat_fake_or_real_test.copy()['label']\", \"import nltk\\nfrom nltk.corpus import stopwords\\nfr...t = ' '.join(tokens)\\n    return preprocessed_text\", \"X_train_text_list  = list(X_train['text'])\\nX_tra...ext'])\\nX_test_title_list  = list(X_test['title'])\", 'X_train_text_clean = [preprocessing(text) for te...reprocessing(text) for text in X_test_title_list]', 'nltk.download()', \"import pandas as pd\\nfake_real_df = pd.read_csv('./fake_or_real_news.csv')\", \"fake_real_df_clean = fake_real_df[['title','text','label']]\", 'from sklearn.model_selection import StratifiedSh...rat_test_set = fake_real_df_clean.loc[test_index]', 'strat_fake_or_real_train = strat_train_set.copy()\\nstrat_fake_or_real_test  = strat_test_set.copy()', \"X_train = strat_fake_or_real_train.copy().drop('...y_test  = strat_fake_or_real_test.copy()['label']\", \"import nltk\\nfrom nltk.corpus import stopwords\\nfr...t = ' '.join(tokens)\\n    return preprocessed_text\", \"X_train_text_list  = list(X_train['text'])\\nX_tra...ext'])\\nX_test_title_list  = list(X_test['title'])\", 'X_train_text_clean = [preprocessing(text) for te...reprocessing(text) for text in X_test_title_list]', \"y_train_binary = [x=='REAL' for x in list(y_trai...y_test_binary = [x=='REAL' for x in list(y_test)]\", \"'''\\nThe code above is all cleaning.\\nI separated ...fit_transform(X_train_text_clean, y_train_binary)\", ...], 'LancasterStemmer': <class 'nltk.stem.lancaster.LancasterStemmer'>, 'LarsCV': <class 'sklearn.linear_model.least_angle.LarsCV'>, 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'Out': {9: True, 21: array([ 0.82955665,  0.82741617,  0.82329714,  0.81342547,  0.83119447]), 22: '\\nIt is now up to you to use the data as you wish...ll going to work on improving the current model.\\n', 29: <5068x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, 30: <1x286760 sparse matrix of type '<class 'numpy.f... stored elements in Compressed Sparse Row format>, 31: (5068, 286760), 32: 5068, 36: <class 'int'>, 37: 4, 38: <class 'int'>, ...}, 'P':         rfc    mnb    abc  Truth\n0      True   T...lse  False  False  False\n\n[5068 rows x 4 columns], 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, ...}\n        self.user_ns = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'EnsembleTransformer': <class 'mlens.preprocessing.ensemble_transformer.EnsembleTransformer'>, 'Evaluator': <class 'mlens.model_selection.model_selection.Evaluator'>, 'In': ['', \"import pandas as pd\\nfake_real_df = pd.read_csv('./fake_or_real_news.csv')\", \"fake_real_df_clean = fake_real_df[['title','text','label']]\", 'from sklearn.model_selection import StratifiedSh...rat_test_set = fake_real_df_clean.loc[test_index]', 'strat_fake_or_real_train = strat_train_set.copy()\\nstrat_fake_or_real_test  = strat_test_set.copy()', \"X_train = strat_fake_or_real_train.copy().drop('...y_test  = strat_fake_or_real_test.copy()['label']\", \"import nltk\\nfrom nltk.corpus import stopwords\\nfr...t = ' '.join(tokens)\\n    return preprocessed_text\", \"X_train_text_list  = list(X_train['text'])\\nX_tra...ext'])\\nX_test_title_list  = list(X_test['title'])\", 'X_train_text_clean = [preprocessing(text) for te...reprocessing(text) for text in X_test_title_list]', 'nltk.download()', \"import pandas as pd\\nfake_real_df = pd.read_csv('./fake_or_real_news.csv')\", \"fake_real_df_clean = fake_real_df[['title','text','label']]\", 'from sklearn.model_selection import StratifiedSh...rat_test_set = fake_real_df_clean.loc[test_index]', 'strat_fake_or_real_train = strat_train_set.copy()\\nstrat_fake_or_real_test  = strat_test_set.copy()', \"X_train = strat_fake_or_real_train.copy().drop('...y_test  = strat_fake_or_real_test.copy()['label']\", \"import nltk\\nfrom nltk.corpus import stopwords\\nfr...t = ' '.join(tokens)\\n    return preprocessed_text\", \"X_train_text_list  = list(X_train['text'])\\nX_tra...ext'])\\nX_test_title_list  = list(X_test['title'])\", 'X_train_text_clean = [preprocessing(text) for te...reprocessing(text) for text in X_test_title_list]', \"y_train_binary = [x=='REAL' for x in list(y_trai...y_test_binary = [x=='REAL' for x in list(y_test)]\", \"'''\\nThe code above is all cleaning.\\nI separated ...fit_transform(X_train_text_clean, y_train_binary)\", ...], 'LancasterStemmer': <class 'nltk.stem.lancaster.LancasterStemmer'>, 'LarsCV': <class 'sklearn.linear_model.least_angle.LarsCV'>, 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'Out': {9: True, 21: array([ 0.82955665,  0.82741617,  0.82329714,  0.81342547,  0.83119447]), 22: '\\nIt is now up to you to use the data as you wish...ll going to work on improving the current model.\\n', 29: <5068x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, 30: <1x286760 sparse matrix of type '<class 'numpy.f... stored elements in Compressed Sparse Row format>, 31: (5068, 286760), 32: 5068, 36: <class 'int'>, 37: 4, 38: <class 'int'>, ...}, 'P':         rfc    mnb    abc  Truth\n0      True   T...lse  False  False  False\n\n[5068 rows x 4 columns], 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, ...}\n   2863             finally:\n   2864                 # Reset our crash handler in place\n   2865                 sys.excepthook = old_excepthook\n   2866         except SystemExit as e:\n\n...........................................................................\n/mnt/Linux-Extra/home-extra/Anthony.Le/Projects/fake_news/<ipython-input-106-3a7f44104b84> in <module>()\n      1 \n----> 2 \n      3 \n      4 \n      5 from sklearn.model_selection import cross_val_score\n      6 cross_val_score(ens, X_train_tfidf, y_train_binary, cv=5, scoring=\"accuracy\")\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in cross_val_score(estimator=SuperLearner(array_check=2, backend='threading',...ne, scorer=None,\n       shuffle=False, verbose=5), X=<5068x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, y=[True, False, False, False, False, False, False, False, True, True, True, False, True, False, True, False, True, True, False, False, ...], groups=None, scoring='accuracy', cv=KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs')\n    135     parallel = Parallel(n_jobs=n_jobs, verbose=verbose,\n    136                         pre_dispatch=pre_dispatch)\n    137     scores = parallel(delayed(_fit_and_score)(clone(estimator), X, y, scorer,\n    138                                               train, test, verbose, None,\n    139                                               fit_params)\n--> 140                       for train, test in cv_iter)\n        cv_iter = [(array([1014, 1015, 1016, ..., 5065, 5066, 5067]), array([   0,    1,    2, ..., 1011, 1012, 1013])), (array([   0,    1,    2, ..., 5065, 5066, 5067]), array([1014, 1015, 1016, ..., 2025, 2026, 2027])), (array([   0,    1,    2, ..., 5065, 5066, 5067]), array([2028, 2029, 2030, ..., 3039, 3040, 3041])), (array([   0,    1,    2, ..., 5065, 5066, 5067]), array([3042, 3043, 3044, ..., 4052, 4053, 4054])), (array([   0,    1,    2, ..., 4052, 4053, 4054]), array([4055, 4056, 4057, ..., 5065, 5066, 5067]))]\n    141     return np.array(scores)[:, 0]\n    142 \n    143 \n    144 def _fit_and_score(estimator, X, y, scorer, train, test, verbose,\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object cross_val_score.<locals>.<genexpr>>)\n    753         self.n_completed_tasks = 0\n    754         try:\n    755             # Only set self._iterating to True if at least a batch\n    756             # was dispatched. In particular this covers the edge\n    757             # case of Parallel used with an exhausted iterator.\n--> 758             while self.dispatch_one_batch(iterator):\n        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>\n        iterator = <generator object cross_val_score.<locals>.<genexpr>>\n    759                 self._iterating = True\n    760             else:\n    761                 self._iterating = False\n    762 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object cross_val_score.<locals>.<genexpr>>)\n    603             tasks = BatchedCalls(itertools.islice(iterator, batch_size))\n    604             if len(tasks) == 0:\n    605                 # No more tasks available in the iterator: tell caller to stop.\n    606                 return False\n    607             else:\n--> 608                 self._dispatch(tasks)\n        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>\n        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    609                 return True\n    610 \n    611     def _print(self, msg, msg_args):\n    612         \"\"\"Display the message on stout or stderr depending on verbosity\"\"\"\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    566         self.n_dispatched_tasks += len(batch)\n    567         self.n_dispatched_batches += 1\n    568 \n    569         dispatch_timestamp = time.time()\n    570         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)\n--> 571         job = self._backend.apply_async(batch, callback=cb)\n        job = undefined\n        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>\n    572         self._jobs.append(job)\n    573 \n    574     def dispatch_next(self):\n    575         \"\"\"Dispatch more data for parallel processing\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)\n    104             raise ValueError('n_jobs == 0 in Parallel has no meaning')\n    105         return 1\n    106 \n    107     def apply_async(self, func, callback=None):\n    108         \"\"\"Schedule a func to be run\"\"\"\n--> 109         result = ImmediateResult(func)\n        result = undefined\n        func = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    110         if callback:\n    111             callback(result)\n    112         return result\n    113 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    321 \n    322 class ImmediateResult(object):\n    323     def __init__(self, batch):\n    324         # Don't delay the application, to avoid keeping the input\n    325         # arguments in memory\n--> 326         self.results = batch()\n        self.results = undefined\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    327 \n    328     def get(self):\n    329         return self.results\n    330 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (SuperLearner(array_check=2, backend='threading',...ne, scorer=None,\n       shuffle=False, verbose=5), <5068x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, [True, False, False, False, False, False, False, False, True, True, True, False, True, False, True, False, True, True, False, False, ...], make_scorer(accuracy_score), array([1014, 1015, 1016, ..., 5065, 5066, 5067]), array([   0,    1,    2, ..., 1011, 1012, 1013]), 0, None, None), {})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (SuperLearner(array_check=2, backend='threading',...ne, scorer=None,\n       shuffle=False, verbose=5), <5068x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, [True, False, False, False, False, False, False, False, True, True, True, False, True, False, True, False, True, True, False, False, ...], make_scorer(accuracy_score), array([1014, 1015, 1016, ..., 5065, 5066, 5067]), array([   0,    1,    2, ..., 1011, 1012, 1013]), 0, None, None)\n        kwargs = {}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=SuperLearner(array_check=2, backend='threading',...ne, scorer=None,\n       shuffle=False, verbose=5), X=<5068x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, y=[True, False, False, False, False, False, False, False, True, True, True, False, True, False, True, False, True, True, False, False, ...], scorer=make_scorer(accuracy_score), train=array([1014, 1015, 1016, ..., 5065, 5066, 5067]), test=array([   0,    1,    2, ..., 1011, 1012, 1013]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=False, error_score='raise')\n    255                              \" numeric value. (Hint: if using 'raise', please\"\n    256                              \" make sure that it has been spelled correctly.)\")\n    257 \n    258     else:\n    259         fit_time = time.time() - start_time\n--> 260         test_score = _score(estimator, X_test, y_test, scorer)\n        test_score = undefined\n        estimator = SuperLearner(array_check=2, backend='threading',...ne, scorer=None,\n       shuffle=False, verbose=5)\n        X_test = <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>\n        y_test = [True, False, False, False, False, False, False, False, True, True, True, False, True, False, True, False, True, True, False, False, ...]\n        scorer = make_scorer(accuracy_score)\n    261         score_time = time.time() - start_time - fit_time\n    262         if return_train_score:\n    263             train_score = _score(estimator, X_train, y_train, scorer)\n    264 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _score(estimator=SuperLearner(array_check=2, backend='threading',...ne, scorer=None,\n       shuffle=False, verbose=5), X_test=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, y_test=[True, False, False, False, False, False, False, False, True, True, True, False, True, False, True, False, True, True, False, False, ...], scorer=make_scorer(accuracy_score))\n    283 def _score(estimator, X_test, y_test, scorer):\n    284     \"\"\"Compute the score of an estimator on a given test set.\"\"\"\n    285     if y_test is None:\n    286         score = scorer(estimator, X_test)\n    287     else:\n--> 288         score = scorer(estimator, X_test, y_test)\n        score = undefined\n        scorer = make_scorer(accuracy_score)\n        estimator = SuperLearner(array_check=2, backend='threading',...ne, scorer=None,\n       shuffle=False, verbose=5)\n        X_test = <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>\n        y_test = [True, False, False, False, False, False, False, False, True, True, True, False, True, False, True, False, True, True, False, False, ...]\n    289     if hasattr(score, 'item'):\n    290         try:\n    291             # e.g. unwrap memmapped scalars\n    292             score = score.item()\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/metrics/scorer.py in __call__(self=make_scorer(accuracy_score), estimator=SuperLearner(array_check=2, backend='threading',...ne, scorer=None,\n       shuffle=False, verbose=5), X=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, y_true=[True, False, False, False, False, False, False, False, True, True, True, False, True, False, True, False, True, True, False, False, ...], sample_weight=None)\n     86         score : float\n     87             Score function applied to prediction of estimator on X.\n     88         \"\"\"\n     89         super(_PredictScorer, self).__call__(estimator, X, y_true,\n     90                                              sample_weight=sample_weight)\n---> 91         y_pred = estimator.predict(X)\n        y_pred = undefined\n        estimator.predict = <bound method BaseEnsemble.predict of SuperLearn...e, scorer=None,\n       shuffle=False, verbose=5)>\n        X = <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>\n     92         if sample_weight is not None:\n     93             return self._sign * self._score_func(y_true, y_pred,\n     94                                                  sample_weight=sample_weight,\n     95                                                  **self._kwargs)\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/ensemble/base.py in predict(self=SuperLearner(array_check=2, backend='threading',...ne, scorer=None,\n       shuffle=False, verbose=5), X=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>)\n    739         if self.shuffle:\n    740             r = check_random_state(self.random_state)\n    741             idx = r.permutation(X.shape[0])\n    742             X = X[idx]\n    743 \n--> 744         y = self.layers.predict(X)\n        y = undefined\n        self.layers.predict = <bound method LayerContainer.predict of LayerCon...  n_jobs=-1, raise_on_exception=True, verbose=5)>\n        X = <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>\n    745 \n    746         if y.shape[1] == 1:\n    747             # The meta estimator is treated as a layer and thus a prediction\n    748             # matrix with shape [n_samples, 1] is created. Ravel before return\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/ensemble/base.py in predict(self=LayerContainer(backend='threading',\n        laye...   n_jobs=-1, raise_on_exception=True, verbose=5), X=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, *args=(), **kwargs={})\n    262         Returns\n    263         -------\n    264         X_pred : array-like of shape = [n_samples, n_fitted_estimators]\n    265             predictions from final layer.\n    266         \"\"\"\n--> 267         return self._predict(X, 'predict', *args, **kwargs)\n        self._predict = <bound method LayerContainer._predict of LayerCo...  n_jobs=-1, raise_on_exception=True, verbose=5)>\n        X = <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>\n        args = ()\n        kwargs = {}\n    268 \n    269     def transform(self, X=None, *args, **kwargs):\n    270         \"\"\"Generic method for reproducing predictions of the ``fit`` call.\n    271 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/ensemble/base.py in _predict(self=LayerContainer(backend='threading',\n        laye...   n_jobs=-1, raise_on_exception=True, verbose=5), X=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, job='predict', *args=(), **kwargs={})\n    315         processor = ParallelProcessing(self)\n    316         processor.initialize(job, X, *args, **kwargs)\n    317 \n    318         # Predict with ensemble\n    319         try:\n--> 320             processor.process()\n        processor.process = <bound method ParallelProcessing.process of <mlens.parallel.manager.ParallelProcessing object>>\n    321 \n    322             preds = processor.get_preds()\n    323 \n    324             if self.verbose:\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/parallel/manager.py in process(self=<mlens.parallel.manager.ParallelProcessing object>)\n    213                       mmap_mode='w+',\n    214                       verbose=self.layers.verbose,\n    215                       backend=self.layers.backend) as parallel:\n    216 \n    217             for n, lyr in enumerate(self.layers.layers.values()):\n--> 218                 self._partial_process(n, lyr, parallel)\n        self._partial_process = <bound method ParallelProcessing._partial_proces...lens.parallel.manager.ParallelProcessing object>>\n        n = 0\n        lyr = Layer(cls='stack', cls_kwargs=None,\n   estimator... raise_on_exception=True, scorer=None, verbose=5)\n        parallel = Parallel(n_jobs=-1)\n    219 \n    220         self.__fitted__ = 1\n    221 \n    222     def get_preds(self, n=-1, dtype=np.float, order='C'):\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/parallel/manager.py in _partial_process(self=<mlens.parallel.manager.ParallelProcessing object>, n=0, lyr=Layer(cls='stack', cls_kwargs=None,\n   estimator... raise_on_exception=True, scorer=None, verbose=5), parallel=Parallel(n_jobs=-1))\n    303         if 'X' in fargs:\n    304             kwargs['X'] = self.job.P[n]\n    305         if 'P' in fargs:\n    306             kwargs['P'] = self.job.P[n + 1]\n    307 \n--> 308         f(**kwargs)\n        f = <bound method BaseEstimator.predict of <mlens.parallel.stack.Stacker object>>\n        kwargs = {'P': memmap([[ 0.,  1.,  0.],\n       [ 0.,  0.,  0.],...\n       [ 0.,  1.,  0.],\n       [ 0.,  1.,  0.]]), 'X': <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, 'parallel': Parallel(n_jobs=-1)}\n    309 \n    310 \n    311 ###############################################################################\n    312 class ParallelEvaluation(object):\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/parallel/estimation.py in predict(self=<mlens.parallel.stack.Stacker object>, X=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, P=memmap([[ 0.,  1.,  0.],\n       [ 0.,  0.,  0.],...\n       [ 0.,  1.,  0.],\n       [ 0.,  1.,  0.]]), parallel=Parallel(n_jobs=-1))\n    224                                       xtest=X,\n    225                                       pred=P,\n    226                                       col=col,\n    227                                       name=self.name,\n    228                                       attr=pred_method)\n--> 229                  for case, (inst_name, est, (_, col)) in ests)\n        ests = [(None, ('rfc', RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), (None, 0))), (None, ('mnb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), (None, 1))), (None, ('abc', AdaBoostClassifier(algorithm='SAMME.R', base_est...ing_rate=1.0, n_estimators=50, random_state=None), (None, 2)))]\n    230 \n    231         if self.verbose:\n    232             print_time(t0, '%s Done' % self.name, file=printout)\n    233 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseEstimator.predict.<locals>.<genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Sun Jun 25 02:31:03 2017\nPID: 16426Python 3.6.1: /home/anthonyle/anaconda3/envs/deep_learning/bin/python\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/externals/joblib/parallel.py in __call__(self=<mlens.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function predict_est>, (), {'attr': 'predict', 'case': None, 'col': 0, 'est': RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), 'inst_name': 'rfc', 'name': 'layer-1', 'pred': memmap([[ 0.,  1.,  0.],\n       [ 0.,  0.,  0.],...\n       [ 0.,  1.,  0.],\n       [ 0.,  1.,  0.]]), 'tr_list': [], 'xtest': <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function predict_est>\n        args = ()\n        kwargs = {'attr': 'predict', 'case': None, 'col': 0, 'est': RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), 'inst_name': 'rfc', 'name': 'layer-1', 'pred': memmap([[ 0.,  1.,  0.],\n       [ 0.,  0.,  0.],...\n       [ 0.,  1.,  0.],\n       [ 0.,  1.,  0.]]), 'tr_list': [], 'xtest': <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/parallel/estimation.py in predict_est(case=None, tr_list=[], inst_name='rfc', est=RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), xtest=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, pred=memmap([[ 0.,  1.,  0.],\n       [ 0.,  0.,  0.],...\n       [ 0.,  1.,  0.],\n       [ 0.,  1.,  0.]]), col=0, name='layer-1', attr='predict')\n    402 \n    403     # Predict into memmap\n    404     # Here, we coerce errors on failed predictions - all predictors that\n    405     # survive into the estimators_ attribute of a layer should be able to\n    406     # predict, otherwise the subsequent layer will get corrupt input.\n--> 407     p = getattr(est, attr)(xtest)\n        p = undefined\n        est = RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False)\n        attr = 'predict'\n        xtest = <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>\n    408 \n    409     if len(p.shape) == 1:\n    410         pred[:, col] = p\n    411     else:\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/ensemble/forest.py in predict(self=RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), X=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>)\n    529         Returns\n    530         -------\n    531         y : array of shape = [n_samples] or [n_samples, n_outputs]\n    532             The predicted classes.\n    533         \"\"\"\n--> 534         proba = self.predict_proba(X)\n        proba = undefined\n        self.predict_proba = <bound method ForestClassifier.predict_proba of ...e=None,\n            verbose=0, warm_start=False)>\n        X = <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>\n    535 \n    536         if self.n_outputs_ == 1:\n    537             return self.classes_.take(np.argmax(proba, axis=1), axis=0)\n    538 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/ensemble/forest.py in predict_proba(self=RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), X=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>)\n    568             such arrays if n_outputs > 1.\n    569             The class probabilities of the input samples. The order of the\n    570             classes corresponds to that in the attribute `classes_`.\n    571         \"\"\"\n    572         # Check data\n--> 573         X = self._validate_X_predict(X)\n        X = <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>\n        self._validate_X_predict = <bound method BaseForest._validate_X_predict of ...e=None,\n            verbose=0, warm_start=False)>\n    574 \n    575         # Assign chunk of trees to jobs\n    576         n_jobs, _, _ = _partition_estimators(self.n_estimators, self.n_jobs)\n    577 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/ensemble/forest.py in _validate_X_predict(self=RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), X=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>)\n    350         \"\"\"Validate X whenever one tries to predict, apply, predict_proba\"\"\"\n    351         if self.estimators_ is None or len(self.estimators_) == 0:\n    352             raise NotFittedError(\"Estimator not fitted, \"\n    353                                  \"call `fit` before exploiting the model.\")\n    354 \n--> 355         return self.estimators_[0]._validate_X_predict(X, check_input=True)\n        self.estimators_._validate_X_predict = undefined\n        X = <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>\n    356 \n    357     @property\n    358     def feature_importances_(self):\n    359         \"\"\"Return the feature importances (the higher, the more important the\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/tree/tree.py in _validate_X_predict(self=DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=537424915, splitter='best'), X=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, check_input=True)\n    360         if self.tree_ is None:\n    361             raise NotFittedError(\"Estimator not fitted, \"\n    362                                  \"call `fit` before exploiting the model.\")\n    363 \n    364         if check_input:\n--> 365             X = check_array(X, dtype=DTYPE, accept_sparse=\"csr\")\n        X = <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>\n    366             if issparse(X) and (X.indices.dtype != np.intc or\n    367                                 X.indptr.dtype != np.intc):\n    368                 raise ValueError(\"No support for np.int64 index based \"\n    369                                  \"sparse matrices\")\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, accept_sparse=['csr'], dtype=<class 'numpy.float32'>, order=None, copy=False, force_all_finite=True, ensure_2d=True, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)\n    375         estimator_name = \"Estimator\"\n    376     context = \" by %s\" % estimator_name if estimator is not None else \"\"\n    377 \n    378     if sp.issparse(array):\n    379         array = _ensure_sparse_format(array, accept_sparse, dtype, copy,\n--> 380                                       force_all_finite)\n        force_all_finite = True\n    381     else:\n    382         array = np.array(array, dtype=dtype, order=order, copy=copy)\n    383 \n    384         if ensure_2d:\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/utils/validation.py in _ensure_sparse_format(spmatrix=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, accept_sparse=['csr'], dtype=<class 'numpy.float32'>, copy=False, force_all_finite=True)\n    253         spmatrix = spmatrix.asformat(accept_sparse[0])\n    254         changed_format = True\n    255 \n    256     if dtype != spmatrix.dtype:\n    257         # convert dtype\n--> 258         spmatrix = spmatrix.astype(dtype)\n        spmatrix = <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>\n        spmatrix.astype = <bound method _data_matrix.astype of <1014x28676...stored elements in Compressed Sparse Row format>>\n        dtype = <class 'numpy.float32'>\n    259     elif copy and not changed_format:\n    260         # force copy\n    261         spmatrix = spmatrix.copy()\n    262 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/scipy/sparse/data.py in astype(self=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, t=<class 'numpy.float32'>)\n     63             return self\n     64         else:\n     65             return NotImplemented\n     66 \n     67     def astype(self, t):\n---> 68         return self._with_data(self._deduped_data().astype(t))\n        self._with_data = <bound method _cs_matrix._with_data of <1014x286...stored elements in Compressed Sparse Row format>>\n        self._deduped_data.astype = undefined\n        t = <class 'numpy.float32'>\n     69 \n     70     astype.__doc__ = spmatrix.astype.__doc__\n     71 \n     72     def conj(self):\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/scipy/sparse/data.py in _deduped_data(self=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>)\n     29         self.data.dtype = newtype\n     30     dtype = property(fget=_get_dtype, fset=_set_dtype)\n     31 \n     32     def _deduped_data(self):\n     33         if hasattr(self, 'sum_duplicates'):\n---> 34             self.sum_duplicates()\n        self.sum_duplicates = <bound method _cs_matrix.sum_duplicates of <1014...stored elements in Compressed Sparse Row format>>\n     35         return self.data\n     36 \n     37     def __abs__(self):\n     38         return self._with_data(abs(self._deduped_data()))\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/scipy/sparse/compressed.py in sum_duplicates(self=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>)\n   1011 \n   1012         The is an *in place* operation\n   1013         \"\"\"\n   1014         if self.has_canonical_format:\n   1015             return\n-> 1016         self.sort_indices()\n        self.sort_indices = <bound method _cs_matrix.sort_indices of <1014x2...stored elements in Compressed Sparse Row format>>\n   1017 \n   1018         M, N = self._swap(self.shape)\n   1019         _sparsetools.csr_sum_duplicates(M, N, self.indptr, self.indices,\n   1020                                         self.data)\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/scipy/sparse/compressed.py in sort_indices(self=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>)\n   1057         \"\"\"Sort the indices of this matrix *in place*\n   1058         \"\"\"\n   1059 \n   1060         if not self.has_sorted_indices:\n   1061             _sparsetools.csr_sort_indices(len(self.indptr) - 1, self.indptr,\n-> 1062                                           self.indices, self.data)\n        self.indices = memmap([285386, 285009, 284390, ...,   1862,   1712,   1709], dtype=int32)\n        self.data = memmap([ 0.04089954,  0.01047909,  0.05310395, ...,  0.03177006,\n        0.02322263,  0.01355832])\n   1063             self.has_sorted_indices = True\n   1064 \n   1065     def prune(self):\n   1066         \"\"\"Remove empty space after all non-zero elements.\n\nValueError: UPDATEIFCOPY base is read-only\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(ens, X_train_tfidf, y_train_binary, cv=5, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is some error in this module. Given that it is rather late, I may just have to predict based on majority vote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/metrics/regression.py:164: DeprecationWarning: numpy boolean subtract, the `-` operator, is deprecated, use the bitwise_xor, the `^` operator, or the logical_xor function instead.\n",
      "  output_errors = np.average(np.abs(y_pred - y_true),\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.006314127861089187"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_train_binary, P['rfc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on uniform_gen in module scipy.stats._continuous_distns object:\n",
      "\n",
      "class uniform_gen(scipy.stats._distn_infrastructure.rv_continuous)\n",
      " |  A uniform continuous random variable.\n",
      " |  \n",
      " |  This distribution is constant between `loc` and ``loc + scale``.\n",
      " |  \n",
      " |  %(before_notes)s\n",
      " |  \n",
      " |  %(example)s\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      uniform_gen\n",
      " |      scipy.stats._distn_infrastructure.rv_continuous\n",
      " |      scipy.stats._distn_infrastructure.rv_generic\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods inherited from scipy.stats._distn_infrastructure.rv_continuous:\n",
      " |  \n",
      " |  __init__(self, momtype=1, a=None, b=None, xtol=1e-14, badvalue=None, name=None, longname=None, shapes=None, extradoc=None, seed=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  cdf(self, x, *args, **kwds)\n",
      " |      Cumulative distribution function of the given RV.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      x : array_like\n",
      " |          quantiles\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information)\n",
      " |      loc : array_like, optional\n",
      " |          location parameter (default=0)\n",
      " |      scale : array_like, optional\n",
      " |          scale parameter (default=1)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      cdf : ndarray\n",
      " |          Cumulative distribution function evaluated at `x`\n",
      " |  \n",
      " |  expect(self, func=None, args=(), loc=0, scale=1, lb=None, ub=None, conditional=False, **kwds)\n",
      " |      Calculate expected value of a function with respect to the\n",
      " |      distribution.\n",
      " |      \n",
      " |      The expected value of a function ``f(x)`` with respect to a\n",
      " |      distribution ``dist`` is defined as::\n",
      " |      \n",
      " |                  ubound\n",
      " |          E[x] = Integral(f(x) * dist.pdf(x))\n",
      " |                  lbound\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : callable, optional\n",
      " |          Function for which integral is calculated. Takes only one argument.\n",
      " |          The default is the identity mapping f(x) = x.\n",
      " |      args : tuple, optional\n",
      " |          Shape parameters of the distribution.\n",
      " |      loc : float, optional\n",
      " |          Location parameter (default=0).\n",
      " |      scale : float, optional\n",
      " |          Scale parameter (default=1).\n",
      " |      lb, ub : scalar, optional\n",
      " |          Lower and upper bound for integration. Default is set to the\n",
      " |          support of the distribution.\n",
      " |      conditional : bool, optional\n",
      " |          If True, the integral is corrected by the conditional probability\n",
      " |          of the integration interval.  The return value is the expectation\n",
      " |          of the function, conditional on being in the given interval.\n",
      " |          Default is False.\n",
      " |      \n",
      " |      Additional keyword arguments are passed to the integration routine.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      expect : float\n",
      " |          The calculated expected value.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The integration behavior of this function is inherited from\n",
      " |      `integrate.quad`.\n",
      " |  \n",
      " |  fit(self, data, *args, **kwds)\n",
      " |      Return MLEs for shape (if applicable), location, and scale\n",
      " |      parameters from data.\n",
      " |      \n",
      " |      MLE stands for Maximum Likelihood Estimate.  Starting estimates for\n",
      " |      the fit are given by input arguments; for any arguments not provided\n",
      " |      with starting estimates, ``self._fitstart(data)`` is called to generate\n",
      " |      such.\n",
      " |      \n",
      " |      One can hold some parameters fixed to specific values by passing in\n",
      " |      keyword arguments ``f0``, ``f1``, ..., ``fn`` (for shape parameters)\n",
      " |      and ``floc`` and ``fscale`` (for location and scale parameters,\n",
      " |      respectively).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : array_like\n",
      " |          Data to use in calculating the MLEs.\n",
      " |      args : floats, optional\n",
      " |          Starting value(s) for any shape-characterizing arguments (those not\n",
      " |          provided will be determined by a call to ``_fitstart(data)``).\n",
      " |          No default value.\n",
      " |      kwds : floats, optional\n",
      " |          Starting values for the location and scale parameters; no default.\n",
      " |          Special keyword arguments are recognized as holding certain\n",
      " |          parameters fixed:\n",
      " |      \n",
      " |          - f0...fn : hold respective shape parameters fixed.\n",
      " |            Alternatively, shape parameters to fix can be specified by name.\n",
      " |            For example, if ``self.shapes == \"a, b\"``, ``fa``and ``fix_a``\n",
      " |            are equivalent to ``f0``, and ``fb`` and ``fix_b`` are\n",
      " |            equivalent to ``f1``.\n",
      " |      \n",
      " |          - floc : hold location parameter fixed to specified value.\n",
      " |      \n",
      " |          - fscale : hold scale parameter fixed to specified value.\n",
      " |      \n",
      " |          - optimizer : The optimizer to use.  The optimizer must take ``func``,\n",
      " |            and starting position as the first two arguments,\n",
      " |            plus ``args`` (for extra arguments to pass to the\n",
      " |            function to be optimized) and ``disp=0`` to suppress\n",
      " |            output as keyword arguments.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      mle_tuple : tuple of floats\n",
      " |          MLEs for any shape parameters (if applicable), followed by those\n",
      " |          for location and scale. For most random variables, shape statistics\n",
      " |          will be returned, but there are exceptions (e.g. ``norm``).\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This fit is computed by maximizing a log-likelihood function, with\n",
      " |      penalty applied for samples outside of range of the distribution. The\n",
      " |      returned answer is not guaranteed to be the globally optimal MLE, it\n",
      " |      may only be locally optimal, or the optimization may fail altogether.\n",
      " |      \n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Generate some data to fit: draw random variates from the `beta`\n",
      " |      distribution\n",
      " |      \n",
      " |      >>> from scipy.stats import beta\n",
      " |      >>> a, b = 1., 2.\n",
      " |      >>> x = beta.rvs(a, b, size=1000)\n",
      " |      \n",
      " |      Now we can fit all four parameters (``a``, ``b``, ``loc`` and ``scale``):\n",
      " |      \n",
      " |      >>> a1, b1, loc1, scale1 = beta.fit(x)\n",
      " |      \n",
      " |      We can also use some prior knowledge about the dataset: let's keep\n",
      " |      ``loc`` and ``scale`` fixed:\n",
      " |      \n",
      " |      >>> a1, b1, loc1, scale1 = beta.fit(x, floc=0, fscale=1)\n",
      " |      >>> loc1, scale1\n",
      " |      (0, 1)\n",
      " |      \n",
      " |      We can also keep shape parameters fixed by using ``f``-keywords. To\n",
      " |      keep the zero-th shape parameter ``a`` equal 1, use ``f0=1`` or,\n",
      " |      equivalently, ``fa=1``:\n",
      " |      \n",
      " |      >>> a1, b1, loc1, scale1 = beta.fit(x, fa=1, floc=0, fscale=1)\n",
      " |      >>> a1\n",
      " |      1\n",
      " |      \n",
      " |      Not all distributions return estimates for the shape parameters.\n",
      " |      ``norm`` for example just returns estimates for location and scale:\n",
      " |      \n",
      " |      >>> from scipy.stats import norm\n",
      " |      >>> x = norm.rvs(a, b, size=1000, random_state=123)\n",
      " |      >>> loc1, scale1 = norm.fit(x)\n",
      " |      >>> loc1, scale1\n",
      " |      (0.92087172783841631, 2.0015750750324668)\n",
      " |  \n",
      " |  fit_loc_scale(self, data, *args)\n",
      " |      Estimate loc and scale parameters from data using 1st and 2nd moments.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : array_like\n",
      " |          Data to fit.\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Lhat : float\n",
      " |          Estimated location parameter for the data.\n",
      " |      Shat : float\n",
      " |          Estimated scale parameter for the data.\n",
      " |  \n",
      " |  isf(self, q, *args, **kwds)\n",
      " |      Inverse survival function (inverse of `sf`) at q of the given RV.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      q : array_like\n",
      " |          upper tail probability\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information)\n",
      " |      loc : array_like, optional\n",
      " |          location parameter (default=0)\n",
      " |      scale : array_like, optional\n",
      " |          scale parameter (default=1)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      x : ndarray or scalar\n",
      " |          Quantile corresponding to the upper tail probability q.\n",
      " |  \n",
      " |  logcdf(self, x, *args, **kwds)\n",
      " |      Log of the cumulative distribution function at x of the given RV.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      x : array_like\n",
      " |          quantiles\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information)\n",
      " |      loc : array_like, optional\n",
      " |          location parameter (default=0)\n",
      " |      scale : array_like, optional\n",
      " |          scale parameter (default=1)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      logcdf : array_like\n",
      " |          Log of the cumulative distribution function evaluated at x\n",
      " |  \n",
      " |  logpdf(self, x, *args, **kwds)\n",
      " |      Log of the probability density function at x of the given RV.\n",
      " |      \n",
      " |      This uses a more numerically accurate calculation if available.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      x : array_like\n",
      " |          quantiles\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information)\n",
      " |      loc : array_like, optional\n",
      " |          location parameter (default=0)\n",
      " |      scale : array_like, optional\n",
      " |          scale parameter (default=1)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      logpdf : array_like\n",
      " |          Log of the probability density function evaluated at x\n",
      " |  \n",
      " |  logsf(self, x, *args, **kwds)\n",
      " |      Log of the survival function of the given RV.\n",
      " |      \n",
      " |      Returns the log of the \"survival function,\" defined as (1 - `cdf`),\n",
      " |      evaluated at `x`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      x : array_like\n",
      " |          quantiles\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information)\n",
      " |      loc : array_like, optional\n",
      " |          location parameter (default=0)\n",
      " |      scale : array_like, optional\n",
      " |          scale parameter (default=1)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      logsf : ndarray\n",
      " |          Log of the survival function evaluated at `x`.\n",
      " |  \n",
      " |  nnlf(self, theta, x)\n",
      " |      Return negative loglikelihood function.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This is ``-sum(log pdf(x, theta), axis=0)`` where `theta` are the\n",
      " |      parameters (including loc and scale).\n",
      " |  \n",
      " |  pdf(self, x, *args, **kwds)\n",
      " |      Probability density function at x of the given RV.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      x : array_like\n",
      " |          quantiles\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information)\n",
      " |      loc : array_like, optional\n",
      " |          location parameter (default=0)\n",
      " |      scale : array_like, optional\n",
      " |          scale parameter (default=1)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      pdf : ndarray\n",
      " |          Probability density function evaluated at x\n",
      " |  \n",
      " |  ppf(self, q, *args, **kwds)\n",
      " |      Percent point function (inverse of `cdf`) at q of the given RV.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      q : array_like\n",
      " |          lower tail probability\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information)\n",
      " |      loc : array_like, optional\n",
      " |          location parameter (default=0)\n",
      " |      scale : array_like, optional\n",
      " |          scale parameter (default=1)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      x : array_like\n",
      " |          quantile corresponding to the lower tail probability q.\n",
      " |  \n",
      " |  sf(self, x, *args, **kwds)\n",
      " |      Survival function (1 - `cdf`) at x of the given RV.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      x : array_like\n",
      " |          quantiles\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information)\n",
      " |      loc : array_like, optional\n",
      " |          location parameter (default=0)\n",
      " |      scale : array_like, optional\n",
      " |          scale parameter (default=1)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      sf : array_like\n",
      " |          Survival function evaluated at x\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from scipy.stats._distn_infrastructure.rv_generic:\n",
      " |  \n",
      " |  __call__(self, *args, **kwds)\n",
      " |      Freeze the distribution for the given arguments.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution.  Should include all\n",
      " |          the non-optional arguments, may include ``loc`` and ``scale``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      rv_frozen : rv_frozen instance\n",
      " |          The frozen distribution.\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  entropy(self, *args, **kwds)\n",
      " |      Differential entropy of the RV.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information).\n",
      " |      loc : array_like, optional\n",
      " |          Location parameter (default=0).\n",
      " |      scale : array_like, optional  (continuous distributions only).\n",
      " |          Scale parameter (default=1).\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Entropy is defined base `e`:\n",
      " |      \n",
      " |      >>> drv = rv_discrete(values=((0, 1), (0.5, 0.5)))\n",
      " |      >>> np.allclose(drv.entropy(), np.log(2.0))\n",
      " |      True\n",
      " |  \n",
      " |  freeze(self, *args, **kwds)\n",
      " |      Freeze the distribution for the given arguments.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution.  Should include all\n",
      " |          the non-optional arguments, may include ``loc`` and ``scale``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      rv_frozen : rv_frozen instance\n",
      " |          The frozen distribution.\n",
      " |  \n",
      " |  interval(self, alpha, *args, **kwds)\n",
      " |      Confidence interval with equal areas around the median.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      alpha : array_like of float\n",
      " |          Probability that an rv will be drawn from the returned range.\n",
      " |          Each value should be in the range [0, 1].\n",
      " |      arg1, arg2, ... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information).\n",
      " |      loc : array_like, optional\n",
      " |          location parameter, Default is 0.\n",
      " |      scale : array_like, optional\n",
      " |          scale parameter, Default is 1.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      a, b : ndarray of float\n",
      " |          end-points of range that contain ``100 * alpha %`` of the rv's\n",
      " |          possible values.\n",
      " |  \n",
      " |  mean(self, *args, **kwds)\n",
      " |      Mean of the distribution.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information)\n",
      " |      loc : array_like, optional\n",
      " |          location parameter (default=0)\n",
      " |      scale : array_like, optional\n",
      " |          scale parameter (default=1)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      mean : float\n",
      " |          the mean of the distribution\n",
      " |  \n",
      " |  median(self, *args, **kwds)\n",
      " |      Median of the distribution.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information)\n",
      " |      loc : array_like, optional\n",
      " |          Location parameter, Default is 0.\n",
      " |      scale : array_like, optional\n",
      " |          Scale parameter, Default is 1.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      median : float\n",
      " |          The median of the distribution.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      stats.distributions.rv_discrete.ppf\n",
      " |          Inverse of the CDF\n",
      " |  \n",
      " |  moment(self, n, *args, **kwds)\n",
      " |      n-th order non-central moment of distribution.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int, n >= 1\n",
      " |          Order of moment.\n",
      " |      arg1, arg2, arg3,... : float\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information).\n",
      " |      loc : array_like, optional\n",
      " |          location parameter (default=0)\n",
      " |      scale : array_like, optional\n",
      " |          scale parameter (default=1)\n",
      " |  \n",
      " |  rvs(self, *args, **kwds)\n",
      " |      Random variates of given type.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information).\n",
      " |      loc : array_like, optional\n",
      " |          Location parameter (default=0).\n",
      " |      scale : array_like, optional\n",
      " |          Scale parameter (default=1).\n",
      " |      size : int or tuple of ints, optional\n",
      " |          Defining number of random variates (default is 1).\n",
      " |      random_state : None or int or ``np.random.RandomState`` instance, optional\n",
      " |          If int or RandomState, use it for drawing the random variates.\n",
      " |          If None, rely on ``self.random_state``.\n",
      " |          Default is None.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      rvs : ndarray or scalar\n",
      " |          Random variates of given `size`.\n",
      " |  \n",
      " |  stats(self, *args, **kwds)\n",
      " |      Some statistics of the given RV.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information)\n",
      " |      loc : array_like, optional\n",
      " |          location parameter (default=0)\n",
      " |      scale : array_like, optional (continuous RVs only)\n",
      " |          scale parameter (default=1)\n",
      " |      moments : str, optional\n",
      " |          composed of letters ['mvsk'] defining which moments to compute:\n",
      " |          'm' = mean,\n",
      " |          'v' = variance,\n",
      " |          's' = (Fisher's) skew,\n",
      " |          'k' = (Fisher's) kurtosis.\n",
      " |          (default is 'mv')\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      stats : sequence\n",
      " |          of requested moments.\n",
      " |  \n",
      " |  std(self, *args, **kwds)\n",
      " |      Standard deviation of the distribution.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information)\n",
      " |      loc : array_like, optional\n",
      " |          location parameter (default=0)\n",
      " |      scale : array_like, optional\n",
      " |          scale parameter (default=1)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      std : float\n",
      " |          standard deviation of the distribution\n",
      " |  \n",
      " |  var(self, *args, **kwds)\n",
      " |      Variance of the distribution.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information)\n",
      " |      loc : array_like, optional\n",
      " |          location parameter (default=0)\n",
      " |      scale : array_like, optional\n",
      " |          scale parameter (default=1)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      var : float\n",
      " |          the variance of the distribution\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from scipy.stats._distn_infrastructure.rv_generic:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  random_state\n",
      " |      Get or set the RandomState object for generating random variates.\n",
      " |      \n",
      " |      This can be either None or an existing RandomState object.\n",
      " |      \n",
      " |      If None (or np.random), use the RandomState singleton used by np.random.\n",
      " |      If already a RandomState instance, use it.\n",
      " |      If an int, use a new RandomState instance seeded with seed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(uniform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
