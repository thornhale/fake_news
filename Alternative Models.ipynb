{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlens\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "from matplotlib.pyplot import show\n",
    "\n",
    "from mlens.preprocessing import EnsembleTransformer\n",
    "from mlens.model_selection import Evaluator\n",
    "from mlens.metrics import make_scorer\n",
    "from mlens.ensemble import SuperLearner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fake_real_df_clean = fake_real_df[['title','text','label']]\n",
    "fake_real_df = pd.read_csv('./fake_or_real_news.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(fake_real_df_clean, fake_real_df_clean[\"label\"]):\n",
    "    strat_train_set = fake_real_df_clean.loc[train_index]\n",
    "    strat_test_set = fake_real_df_clean.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "strat_fake_or_real_train = strat_train_set.copy()\n",
    "strat_fake_or_real_test  = strat_test_set.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = strat_fake_or_real_train.copy().drop('label', 1)\n",
    "y_train = strat_fake_or_real_train.copy()['label']\n",
    "X_test  = strat_fake_or_real_test.copy().drop('label', 1)\n",
    "y_test  = strat_fake_or_real_test.copy()['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "\n",
    "def preprocessing(text):\n",
    "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    stop = stopwords.words('english')\n",
    "    tokens = [token for token in tokens if token not in stop]\n",
    "    tokens = [word for word in tokens if len(word) >= 3]\n",
    "    tokens = [word.lower() for word in tokens]\n",
    "    lcStem = LancasterStemmer()\n",
    "    tokens = [lcStem.stem(word) for word in tokens]\n",
    "    preprocessed_text = ' '.join(tokens)\n",
    "    return preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_text_list  = list(X_train['text'])\n",
    "X_train_title_list = list(X_train['title'])\n",
    "X_test_text_list   = list(X_test['text'])\n",
    "X_test_title_list  = list(X_test['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_text_clean = [preprocessing(text) for text in X_train_text_list]\n",
    "X_train_title_clean = [preprocessing(text) for text in X_train_title_list]\n",
    "X_test_text_clean = [preprocessing(text) for text in X_test_text_list]\n",
    "X_test_title_clean = [preprocessing(text) for text in X_test_title_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_binary = [x=='REAL' for x in list(y_train)]\n",
    "y_test_binary = [x=='REAL' for x in list(y_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyTfidfVectorizer(TfidfVectorizer):\n",
    "    def fit_transform(self, X, y):\n",
    "        result = super(MyTfidfVectorizer, self).fit_transform(X, y)\n",
    "        result.sort_indices()\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "The code above is all cleaning.\n",
    "I separated the two features Text and title. \n",
    "You can join them into a df\n",
    "if you want to use multiple features analysis.\n",
    "Below is the actual machine learning that I have done\n",
    "so far.\n",
    "'''\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = MyTfidfVectorizer(min_df=2, ngram_range=(1,2), stop_words='english', strip_accents='unicode',norm=u'l2')\n",
    "\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train_text_clean, y_train_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "rfc = RandomForestClassifier() #.fit(X_train_tfidf, y_train_binary)\n",
    "mnb = MultinomialNB()\n",
    "abc = AdaBoostClassifier()\n",
    "lac = LarsCV()\n",
    "\n",
    "base_learners = [('rfc', rfc),\n",
    "                 ('mnb', mnb),\n",
    "                 ('abc', abc),\n",
    "                ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  rfc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/metrics/regression.py:164: DeprecationWarning: numpy boolean subtract, the `-` operator, is deprecated, use the bitwise_xor, the `^` operator, or the logical_xor function instead.\n",
      "  output_errors = np.average(np.abs(y_pred - y_true),\n",
      "/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/metrics/regression.py:164: DeprecationWarning: numpy boolean subtract, the `-` operator, is deprecated, use the bitwise_xor, the `^` operator, or the logical_xor function instead.\n",
      "  output_errors = np.average(np.abs(y_pred - y_true),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rfc mean absolute error: 0.005130228887134964\n",
      "Processing:  mnb\n",
      "mnb mean absolute error: 0.06610102604577743\n",
      "Processing:  abc\n",
      "abc mean absolute error: 0.09609313338595106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/metrics/regression.py:164: DeprecationWarning: numpy boolean subtract, the `-` operator, is deprecated, use the bitwise_xor, the `^` operator, or the logical_xor function instead.\n",
      "  output_errors = np.average(np.abs(y_pred - y_true),\n"
     ]
    }
   ],
   "source": [
    "#type(X_train_tfidf.shape[0])\n",
    "#len(base_learners)\n",
    "P = np.zeros((X_train_tfidf.shape[0], len(base_learners)))\n",
    "P = pd.DataFrame(P, columns=[e for e, _ in base_learners])\n",
    "\n",
    "for est_name, est in base_learners:\n",
    "    print('Processing: ', est_name)\n",
    "    est.fit(X_train_tfidf, y_train_binary)\n",
    "    p = est.predict(X_train_tfidf)\n",
    "    P.loc[:, est_name] = p\n",
    "    print(\"{0} mean absolute error: {1}\".format(est_name, mean_absolute_error(y_train_binary, P[est_name])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.4869771113\n",
      "93.3898973954\n",
      "90.3906866614\n"
     ]
    }
   ],
   "source": [
    "P['Truth'] = y_train_binary\n",
    "for est_name, est in base_learners:\n",
    "    print(P[P[est_name] == P['Truth']][est_name].count()/len(P)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlcAAAIZCAYAAACLaRqYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl4FHWex/FPJQRzEEkISTAC4RgCcoRwH3KYiCgiCirD\nElBnZMZlRUFACceowCwLCDoDKA4qKJjlUJTBAzllQRAYGBTkknBEbhIkQE5J6No/HHvNchVJdxXp\nvF/Pk0e6u1L1rfQT+fL5HW2YpmkKAAAAHuHndAEAAAC+hOYKAADAg2iuAAAAPIjmCgAAwINorgAA\nADyI5goAAMCDaK4AH/fYY49p8uTJJfreJ598Uq+++qqHK3LGvffeqwULFjhdBoBygOYK8JL09HSN\nGDFCHTp0UHx8vBITE/Xyyy8rMzPT6dKu6sKFC1q0aJH78Zw5czR8+HCvXCspKUkJCQnKzc297LVl\ny5apfv36mjFjhqVzuVwuzZ49+5rHrFixQn379i1RrQBwI2iuAC/Yt2+fHn30UYWHh+vjjz/Wt99+\nq1mzZun48ePq3bu3zp8/73SJV7Rp06ZizZW3BQcHa+XKlZc9/+mnnyoiIsLyefbs2aO33nrLk6UB\nQInRXAFeMGHCBLVp00ajRo1SVFSU/Pz8FBcXp5kzZ+rOO+/UqVOnJP2cFI0aNUodO3ZUQkKCnnji\nCaWlpbnPU79+fb377rvq2LGjZsyYoS1btqhJkyZKTU1VixYttHnzZknS/Pnzdf/996tp06a69957\ntWzZsivWZZqm/vKXvygxMVHNmjXTAw88oLVr10qSPvvsMw0dOlR79uxRkyZNdPjw4cuGFD/88EPd\nf//9io+P1z333KOFCxe6Xxs5cqTGjx+vSZMmqXXr1mrXrp3ee++9a/6cOnfurKVLlxZ77ty5c9q6\ndatat25d7Pl58+apa9euatasme655x4tXrxYkrR9+3b16dNH586dU5MmTbRx40bNmDFDAwYM0PDh\nw5WQkKBLly4pKSlJqampOnPmjFq3bq3Vq1e7z/2nP/1Jv/vd765ZKwBYZgLwqB9//NGMi4szv/76\n6+se++yzz5r9+/c3MzIyzNzcXHPUqFFmUlKSWVRUZJqmacbFxZl9+vQxMzIyTJfLZW7evNls2LCh\n+eKLL5p5eXmmy+UyV61aZbZu3drcsWOHWVRUZH755Zdmo0aNzAMHDpimaZr9+/c3J02aZJqmaS5Z\nssRs06aNeeTIEfPSpUtmamqqmZCQYJ4/f940TdOcPn262atXL3d9v/7etWvXmgkJCeamTZvMwsJC\n93V+uc+UlBSzTZs25kcffWRevHjRTE1NNRs1amSePXv2iveemJhorlq1ymzatKl56tQp9/Pz5883\nBw8ebKakpJjTp083TdM0t27dajZs2NDctWuX6XK5zDVr1pgNGjQwDx48aJqmaX700Udm69at3eeY\nPn262apVK/P99993/ywTExPN999/3318UlKSWVBQYO7cudNMSEgwjxw5ct33CwCsILkCPOzo0aOS\npNq1a1/zuPPnz2vlypUaMmSIIiMjFRwcrOHDh+vYsWPauXOn+7hu3bopMjJShmFIkoqKipScnKyg\noCAZhqEPPvhADz/8sOLj4+Xv76/ExER16NBBf//73y+7Zo8ePbRq1SrVqFFDfn5+6t69u/Ly8nTw\n4MHr3tcvqVXbtm1VoUIFJSYmql27dvriiy/cx1SrVk0PP/ywAgICdN9996mwsFBHjhy56jlDQ0OV\nmJioTz75xP3cp59+qoceeqjYcS1atNCmTZvUqFEjGYahpKQkBQUFac+ePVc9t2EYSk5Olr+//2Wv\nPfzww4qNjdVbb72l//zP/9TgwYNVo0aN6/4MAMCKCk4XAPiqS5cuXfP148ePyzRN/eY3v3E/FxER\noZCQEB0/flzNmjWTJN1+++2XfW9MTIz7z0eOHNHGjRuVmprqfs40TYWGhl72ffn5+Zo4caLWr19f\nbN7XxYsXr3s/R48eVcuWLYs9Fxsbq8OHD7sfV69e3f3nwMBASVJBQcE1z9uzZ09NnTpVf/zjH3Xs\n2DGlp6erU6dOxeZiFRUVaebMmVq+fLl+/PFHd83XqrtatWry87v6vx/Hjx+vHj16qHbt2nr88cev\nWSMA3AiaK8DDatWqJcMwdODAgSs2Rr+4VmPwS0ol6YrJy6+fCwwM1JAhQ/TUU09dt7Zx48Zpz549\nmjdvnmrXrq2cnJzLGqaS1PuLazUzV9OhQweNGTNGe/fu1bp163T//ferQoXi/2t644039Nlnn2nm\nzJlq3Lix/Pz81KpVq2ue90o/t1/LyMiQn5+fMjIylJubq1tvvfWGaweAK2FYEPCwypUrq127dpoz\nZ85lrxUWFqpv375at26dexjq10Nyp0+fVm5urmrWrGn5ejVr1tT3339f7LkTJ07I5XJdduzOnTv1\n4IMPqk6dOjIMQ7t27bqh6/z/4cNDhw4pNjbW8jmuxN/fXw888ICWLVumZcuW6cEHH7zsmO+++05J\nSUmKj4+Xn5+fjh49qgsXLpT4mhcvXtSf/vQnjRo1Ss2bN9crr7xSmlsAgGJorgAvGD16tHbv3q3B\ngwfr+PHjcrlc2r9/vwYOHKi8vDy1bNlSERER6ty5s6ZNm6azZ88qJydHU6ZMUVxcnBo3bmz5Wn37\n9tWKFSu0evVqFRUVafv27erZs6e2bNly2bE1atTQrl27dPHiRe3evVvz589XxYoVdfr0aUnSLbfc\nojNnzigrK+uypKpXr176/PPPtW3bNhUVFWnVqlXavHmzevbsWbofln4eGvz8889VWFio+Pj4y16v\nXr269u3bp7y8PB0+fFiTJk1SdHS0u+7AwEDl5ubq9OnTys/Pv+71/va3v6ly5cp65JFHNGbMGC1b\ntsy98hIASothQcAL6tWrp8WLF2vGjBnq3bu3cnNzFRUVpXvvvVcDBw5USEiIJGnSpEkaN26cevTo\nIZfLpVatWumdd94pNix4Pe3atdPo0aM1ceJEDRs2TDExMXrhhRfUrl27y459/vnn9cILL6hVq1Zq\n2LChJk6cqLCwML344ouqXLmyunTpovnz5ysxMVHvvPNOse/t1q2bTp48qTFjxigjI0O1atXSzJkz\nr9gM3agGDRro1ltv1X333XfF1wcOHKihQ4eqffv2qlWrlsaNG6cNGzbozTffVHh4uLp27arY2Fh1\n6dJF//Vf/3XNa6WlpWnOnDlauHChDMNQdHS0nn32Wb300kv65JNP3HPFAKCkDNM0TaeLAAAA8BUM\nCwIAAHgQzRUAACiX9u/fry5duri3sjl58qQee+wxJScna8iQIe65p5988okeeeQR9e7dWx9++OF1\nz0tzBQAAyp28vDz9+c9/LjY/dfr06UpOTtb8+fMVGxurxYsXKy8vT2+88Ybee+89vf/++5o7d67O\nnTt3zXPTXAEAgHKnYsWKevvttxUVFeV+bsuWLbr77rslSYmJidq0aZN27NihJk2aKDQ0VIGBgWre\nvLm2b99+zXOzWhAAAJQ7FSpUuGzD4vz8fFWsWFHSz5+YkZmZqTNnzqhKlSruY6pUqaLMzMxrn9vz\n5V4uMzPbjsvAQZGRobzP5UBk5M8fqcN77dt4n8uPX95rJ6R1uNfr16i3YUWJv/dqmylY2WSBYUEA\nAABJwcHB7s9DPX36tKKiohQVFaUzZ864j8nIyCg2lHglNFcAAMB+hp/3v25Q+/bttWLFz2nXypUr\n1bFjRzVt2lTfffedLly4oNzcXG3fvv26n8nKnCsAAFDu7Nq1S5MnT9bx48dVoUIFrVixQlOnTtXI\nkSO1aNEixcTEqGfPngoICNDw4cM1YMAAGYahQYMGKTT02sOptuzQzri972POVfnAXJzygfe5/HB0\nzlWn+71+jXrrl3n9GlfCsCAAAIAHMSwIAABsZ/hZ/4D6sobkCgAAwINIrgAAgP1KsJqvrPDdOwMA\nAHAAyRUAALCfwZwrAAAAWEByBQAA7OfDqwVprgAAgO0MhgUBAABgBckVAACwn5/v5ju+e2cAAAAO\nILkCAAD2Y84VAAAArCC5AgAA9iO5AgAAgBUkVwAAwHYGqwUBAABgBckVAACwH8kVAAAArCC5AgAA\n9mO1IAAAAKwguQIAALYzSK4AAABgBckVAACwnx/JFQAAACwguQIAAPYzfDff8d07AwAAcADJFQAA\nsJ8Pz7miuQIAALZjKwYAAABYQnIFAADsx4R2AAAAWEFyBQAA7OfDE9pJrgAAADyI5AoAANjO8PPd\nfMd37wwAAMABJFcAAMB+7HMFAAAAK0iuAACA/UiuAAAAYAXJFQAAsB+rBQEAAGAFyRUAALCdwZwr\nAAAAWEFyBQAA7MdnCwIAAMAKkisAAGA/w3fzHd+9MwAAAAeQXAEAAPv58GpBmisAAGA7gwntAAAA\nsILkCgAA2M+HhwVJrgAAADzIUnN14MABTZ8+3f34z3/+s9LS0rxWFAAA8HF+ft7/curWrBz08ssv\nq3379u7HjzzyiMaNG+e1ogAAAMoqS3OuioqK1LJlS/fjhg0byjRNrxUFAAB8m+FgsuRtlpqr+Ph4\nDR48WM2bN5fL5dKWLVsUHx/v7doAAADKnGs2V7m5uQoJCdGQIUP03Xffaffu3fL399cf//jHYkkW\nAADADfHh1YLXbK4ee+wxzZs3TwMHDtQ777yjhIQE92v5+fkKCgryeoEAAABlyTWbq4SEBPXs2VOn\nTp1S9+7dZZqmDMNw/3fNmjV21QkAAHxJeU2uXnrpJUlS06ZNaaQAAAAssDShPSkpSf/2b/+mJk2a\nKCAgwP38iBEjvFYYAADwYeV9tWCnTp28XQcAAIBPsNRc9erVy9t1AACAcsTw4TlXvpvJAQAAOMBS\ncgUAAOBRJFcAAACwguQKAADYz4/kCgAAABaQXAEAAPsZvpvv+O6dAQAAOIDkCgAA2M7w4TlXNFcA\nAMB+PvzxN757ZwAAAA4guQIAAPZjE1EAAABYQXIFAABsxwc3AwAAwBKSKwAAYD9WCwIAAMAKkisA\nAGA/5lwBAADACpIrAABgP5IrAAAAWEFyBQAAbGewWhAAAABWkFwBAAD7MecKAAAAVpBcAQAA+/mR\nXAEAAMACkisAAGA/h+dcuVwuvfzyy0pLS1NAQIDGjh2rt99+W7t371ZYWJgkacCAAbrrrrtu+Nw0\nVwAAoNxZs2aNsrOztXDhQh05ckQTJkxQeHi4hg0bpsTExFKdm+YKAADYzul9rtLT0xUfHy9Jqlmz\npk6cOKFbb73VI+dmzhUAALCf4ef9r2uIi4vThg0bdOnSJR06dEhHjx5VVlaWUlNT9fjjj2vo0KE6\ne/ZsiW6N5goAAJQ7nTt3VpMmTdSvXz/NnTtXderU0YMPPqjnn39e8+bN0x133KHXX3+9ROdmWBAA\nANjvJtiKYejQoe4/d+nSRQ888ID8/jVcmZSUpLFjx5bovCRXAACg3Nm3b59GjRolSVq/fr0aNmyo\nIUOG6OjRo5KkLVu2qF69eiU6N8kVAACwneHwVgxxcXEyTVOPPvqobrnlFk2dOlU//PCDnnvuOQUF\nBSk4OFgTJ04s0blprgAAQLnj5+enSZMmFXvutttu00cffVTqc9NcAQAA+11nNV9Z5rt3BgAA4ACS\nKwAAYL+bYLWgt5BcAQAAeBDJFQAAsJ/DqwW9ieQKAADAg0iuAACA7QzmXAEAAMAKkisAAGA/9rkC\nAACAFSRXAADAfqwWBAAAgBUkVwAAwH6sFgQAAIAVJFcAAMB2hp/v5js0VwAAwH4+vBWDLc1VZGSo\nHZeBw3ifyw/e6/KB9xkoGZIrAABgPx+e0G5Lc3XyfI4dl4GDbqtcSZmZ2U6XAS/7JcngvfZtvM/l\nB+mkd5BcAQAA2xlsIgoAAAArSK4AAID9SK4AAABgBckVAACwnw9vIuq7dwYAAOAAkisAAGA/5lwB\nAADACpIrAABgO/a5AgAAgCUkVwAAwH6sFgQAAIAVJFcAAMB+zLkCAACAFSRXAADAfsy5AgAAgBUk\nVwAAwHaGn+/OuaK5AgAA9mNCOwAAAKwguQIAAPYzfDff8d07AwAAcADJFQAAsJ0vT2gnuQIAAPAg\nkisAAGA/VgsCAADACpIrAABgP1YLAgAAwAqSKwAAYD9WCwIAAMAKkisAAGA7g9WCAAAAsILkCgAA\n2I85VwAAALCC5AoAANjPz3fzHd+9MwAAAAeQXAEAAPuxQzsAAACsILkCAAC2Y58rAAAAWEJyBQAA\n7OfD+1zRXAEAAPsxLAgAAAArSK4AAID92IoBAAAAVpBcAQAA2xk+PKGd5AoAAMCDSK4AAID9WC0I\nAAAAK0iuAACA/fx8N9/x3TsDAABwAMkVAACwHR/cDAAAAEtIrgAAgP2YcwUAAAArSK5K6YtPP9HC\n1HkyTVORUdF67oUUzX3nLX2/b6/7mNycHDWOb6rxk6c4WCkAADcRH55zRXNVCj+kH9ab0/+q2f+9\nUJFRUVr60WJN/s9xev3tOcWOS3lusO57oIdDVQIAADsxLFgKPxw+rOo1aioyKkqS1LxlKx0+eLDY\nMVu+3qjCixfVvmMnJ0oEAODm5Gd4/8upW3Psyj6gYeMmOnH8mA4dPCDTNLV+7Rq1bN2m2DHvvjVL\nj//hjw5VCAAA7GZpWHDv3r168803dfjwYRmGobp16+rpp59WvXr1vF3fTa1qZKT+8B+D9If+yQoO\nDlZgUJCm/e0t9+vfbNsq0zSV0LyFg1UCAHDzMQzfzXcsNVejRo3Sc889p/j4eEnSN998oxEjRmjJ\nkiVeLe5ml/b9PqW+O0cLlixVdLXbtPKLZRozfJjeXfiBDMPQ6hXLdXfXe50uEwAA2MhS2xgeHq67\n7rpLVapUUZUqVXT33XcrOjra27Xd9P659R9qHB+v6Gq3SZKS7rlH6YcP6fy5c5KkzRs3qM2ddzpZ\nIgAANyfD8P6XQ66ZXK1bt06SVKNGDY0dO1Zt2rSRYRjatm2bqlevbkuBN7OasbX09w8/1Plz51Q5\nLEybN25UlYgIVQ4LU9bZs8rKylKNmrFOlwkAwM3HwQnn3nbN5mr58uXFHq9fv96rxZQ17Tt20vd7\n92rQgN/LMAwFh4Ro7MTJMgxDmRmnFRYWJj8f3oEWAABczjBN07RyYE5OjrKzs/Xrw2NiYixd5OT5\nnJJVhzLjtsqVlJmZ7XQZ8LLIyFBJ4r32cbzP5ccv77UTcjdv8/o1Qtq29Po1rsTShPYXX3xR69at\nU9S/9nMyTVOGYWjx4sVeLQ4AAKCssdRc7d69W+vWrZPhw1vVAwAA+xg+POfK0oSg+vXrKysry9u1\nAAAAlHmWkqtjx46pS5cuio2Nlb+/v/t5hgUBAECJ+PBomKXm6oUXXtCsWbOUnZ2t22+/3ds1AQAA\nlFmWm6unnnpKERER3q4HAACUB+U9uapTp44efvhhJrQDAABch6Xm6oEHHlDPnj1Vv379YnOuJk6c\n6LXCAACA7zJ8eJNtS83VX//6Vz311FOKjIz0dj0AAABe53K59PLLLystLU0BAQEaO3asgoODNWLE\nCF26dEmRkZGaMmWKKlaseMPnttRc1a1bV717977hkwMAAFyRw8nVmjVrlJ2drYULF+rIkSOaMGGC\nqlSpouTkZHXr1k2vvfaaFi9erOTk5Bs+t6XmKjw8XP369VPjxo2LDQuOGDHihi8IAADgtPT0dMXH\nx0uSatasqRMnTigtLU3jxo2TJCUmJmrOnDnea65at26t1q1b3/DJAQAArsjhRXJxcXGaO3eunnji\nCf3www86evSo8vPz3cOAERERyszMLNG5LTVXvXr1KtHJAQAAbkadO3fW9u3b1a9fP9WvX1916tTR\n/v373a+bplnic1tqrgAAADzqJvhswaFDh7r/3KVLF0VHR6ugoECBgYE6ffq0oqKiSnRe310HCQAA\ncBX79u3TqFGjJEnr169Xw4YN1b59e61YsUKStHLlSnXs2LFE5ya5AgAAtjMMZ/OduLg4maapRx99\nVLfccoumTp0qf39/paSkaNGiRYqJiVHPnj1LdG7DLM2gokUnz+d4+xJw2G2VKykzM9vpMuBlkZGh\nksR77eN4n8uPX95rJxTs2uv1awQ2vsPr17gSkisAAGA/H/5IPZorAABgv5tgQru3MKEdAADAg0iu\nAACA/Xx4WJDkCgAAwINIrgAAgO2c3orBm3z3zgAAABxAcgUAAOzHakEAAABYQXIFAADs5+e7+Y7v\n3hkAAIADSK4AAIDtDPa5AgAAgBUkVwAAwH7MuQIAAIAVJFcAAMB+zLkCAACAFSRXAADAfiRXAAAA\nsILkCgAA2M7gswUBAABgBckVAACwn+G7+Q7NFQAAsB8T2gEAAGAFyRUAALAfE9oBAABgBckVAACw\nneHDE9p9984AAAAcQHIFAADsx5wrAAAAWEFyBQAAbJcfeIvXrxHq9StcGckVAACAB9FcAQAAeBDN\nFQAAgAfRXAEAAHgQzRUAAIAH0VwBAAB4EM0VAACABxmmaZpOFwEAAMqX7Oxsr18jNNSZna5IrgAA\nADzIlh3aX/l0rR2XgYNG9EjUXWNfd7oMeNn/jH1GkpSZ6f1/ccI5kZE//2uf99n3/fJew7NIrgAA\nADyI5goAAMCDaK4AAAA8iOYKAADAg2iuAAAAPIjmCgAAwINorgAAADyI5goAAMCDbNlEFAAA4NcK\n/QOcLsFrSK4AAAA8iOQKAADYzjSdrsB7SK4AAAA8iOQKAADYzuXD0RXJFQAAgAeRXAEAANuZJFcA\nAACwguQKAADYjuQKAAAAlpBcAQAA27FaEAAAAJaQXAEAANv5cHBFcgUAAOBJJFcAAMB2rBYEAACA\nJSRXAADAdi75bnJFcwUAAGzHsCAAAAAsIbkCAAC2YxNRAAAAWEJyBQAAbOdykVwBAADAApIrAABg\nOx+eckVyBQAA4EkkVwAAwHbscwUAAABLSK4AAIDtfPnjb0iuAAAAPIjkCgAA2I45VwAAALCE5AoA\nANiO5AoAAACWkFwBAADb+fBHC5JcAQAAeBLJFQAAsB1zrgAAAGAJyRUAALCdLydXNFcAAMB2Lh9u\nrhgWBAAA8CCSKwAAYDtfTq5orgAAQLmTm5urlJQUnT9/XoWFhRo0aJA+//xz7d69W2FhYZKkAQMG\n6K677rrhc9NcAQAA2zk9oX3JkiWqXbu2hg8frtOnT+uJJ55QQkKChg0bpsTExFKdmzlXAACg3AkP\nD9e5c+ckSRcuXFB4eLjHzk1zBQAAbOcyTa9/XUv37t114sQJ3XPPPerfv79SUlIkSampqXr88cc1\ndOhQnT17tkT3RnMFAADKnaVLlyomJkarVq3S3LlzNX78eD300EN6/vnnNW/ePN1xxx16/fXXS3Ru\n5lyVUuMa1dS6bk0ZkrILftKq7/YrKzdfnRrUUdxtkTJlKu3kGa3fd8jpUlEKnRvW1YCktsWeq1k1\nXIu+/kb3JTTQ+bwC9/Nvrd6kDbzfAHBNTi8W3L59uzp06CBJatCggTIyMtS6dWv5+/tLkpKSkjR2\n7NgSnZvmqhSqVArWXQ3r6r11W5VTcFEJsTHqltBA2w8fV82qYXp33T9kmlLf9s0Ud1uk9p/MdLpk\nlNC6PQe1bs9B9+O7Gv1GiY3qKf9ioZb84zu99z//cLA6AMCNio2N1Y4dO3Tvvffq+PHjCgkJ0XPP\nPacRI0aoRo0a2rJli+rVq1eic9NclUJEpWBl5eQrp+CiJOmHM1nqdEcd1Y+J1K6jp3TJ9XNbvvvY\nKTWgufIZFSv4a0BSW6WkfqKuTRs4XQ4AlElOrxbs06ePRo8erf79+6uoqEhjx46VYRh67rnnFBQU\npODgYE2cOLFE56a5KoWTWRcUFhKkqqEhOpOdq7jbIpWemaWISsH6Nv2E+7hzeQVKiA1xsFJ40v3N\nGmrXkZM6kXVBktSiTnW1rFtDtwYFatP+dL2zZpMKL7kcrhIAcC0hISGaNm3aZc9/9NFHpT63pQnt\nGRkZWrhwofvxW2+9pYyMjFJfvKzL+emivtp3SL/r1FKD7+2g5rVu1/q9B1XB31+XXP/3l2vRpUsK\nqMDaAV9gGNJv2ydo0dffSJL2n8zQV3sPaeh7SzRo9mLdcXu0+nZo4XCVAHDzc3q1oDdZ+hs/JSVF\nt956q/txvXr1NHLkSK8VVVZE3VpJbevFataXmzV9xQat23tID7eOV9GlS/L3+78fbYC/vy4WXXKw\nUnhKo+rVlH+xUOmZPy/P/fr7dH2w6VsVXnIpO/8nfbj5W7WLq+VskQAAR1lqrgoKCnT//fe7Hycm\nJqqwsNBrRZUVsVXDdeLseWXn/yRJ2nciQ1VDQ5R/sVDhIUHu48JDgvRjdp5TZcKD2sXV1pa0H9yP\nb69SWcG3BLgf+/v5qYghQQC4LtM0vf7lFEtzrmJiYjR58mQ1b95cLpdLmzZtUkxMjLdru+mdzc1T\ns9q3KzCgggoKi1QnKkI5BT/pm/TjalsvVruPnZJkqGlsDFsx+Ii61SK0dtcB9+PfJ7bRhbwCTf9i\nvSpW8FePFo20OS3duQIBAI6z1FxNnjxZS5Ys0aZNm+Tn56dmzZoVS7LKq4Onf1S1yqHq/685Nj8V\nFWnpP3fr+Nnziq4cqt91aiVT0t7jp3Xw9I/OFguPiLy1ks7m/F8K+fryr/R8j0SlPttfLtPU5rQf\n9MG/5mMBAK7O6X2uvMlSc1VQUKCffvpJhmFIkvLy8nTx4kUFBARc5zt938b96dq4P/2y59fvO0Ra\n5YMGvLmw2ONzufn608JlDlUDALgZWZpzNWjQIJ04cUItW7ZUixYt9MMPP+jZZ5/1dm0AAMBH+fJq\nQUvJVVFRkUaMGOF+3K1bN/3+97/3WlEAAABl1TWbq/z8fElSy5YttWzZMrVt+/Nnq/3zn/9Uq1at\nvF8dAADwSU7v0O5N12yuunfvLsMwZJqmPvvss2Kvmaapp59+2qvFAQAA3+TksJ23XbO5+vLLLyVJ\nO3fu1DvvvKOsrCxJUmFhoX78kdVvAAAA/5+lCe0TJkxQcnKyCgoKlJKSojZt2mj06NHerg0AAPgo\nX57QbqkffrIaAAARQ0lEQVS5CgwMVNu2bRUQEKDGjRtr6NChSk1N9XZtAAAAZY6l1YJBQUFas2aN\nqlevrtdee001atTQyZMnvV0bAADwUb48od1ScjV16lTVrVtXL730kipWrKjvv/9ekydP9nZtAAAA\nZY6l5KpSpUqqVKmSJOmZZ57xakEAAMD3lfvkCgAAANZYSq4AAAA8yeW7wRXJFQAAgCeRXAEAANsx\n5woAAACWkFwBAADbkVwBAADAEpIrAABgO5dIrgAAAGAByRUAALAdc64AAABgCckVAACwHTu0AwAA\nwBKSKwAAYDuXD0dXNFcAAMB2TGgHAACAJSRXAADAdiRXAAAAsITkCgAA2I6PvwEAAIAlJFcAAMB2\nzLkCAACAJSRXAADAdj4cXJFcAQAAeBLJFQAAsJ3Lh6MrkisAAAAPIrkCAAC2Y7UgAAAALCG5AgAA\ntiO5AgAAgCUkVwAAwHasFgQAAIAlJFcAAMB2JFcAAACwhOQKAADYjtWCAAAAsITkCgAA2M7lu8EV\nzRUAALAfw4IAAACwhOQKAADYjuQKAAAAlpBcAQAA27GJKAAAACwhuQIAALbz4eCK5AoAAMCTSK4A\nAIDtfHm1oGH68t0BAICb0jtfbvH6Nf6Q1Mbr17gSW5Krg90eteMycFDdLxYrOzvb6TLgZaGhoZKk\nv3y+zuFK4E1Du3eWJGVm8jvt6yIjQx27NqsFAQAAYAlzrgAAgO18eVYSyRUAAIAHkVwBAADbMecK\nAAAAlpBcAQAA25FcAQAAwBKSKwAAYDtWCwIAAMASkisAAGA7Hw6uaK4AAID9mNAOAAAAS0iuAACA\n7ZjQDgAAAEtIrgAAgO1IrgAAAGAJyRUAALAdqwUBAABgCckVAACwne/mViRXAAAAHkVyBQAAbMec\nKwAAAFhCcgUAAGzHPlcAAACwhOQKAADYzuUiuQIAAIAFJFcAAMB2vjzniuYKAACUO7m5uUpJSdH5\n8+dVWFioQYMG6Te/+Y1GjBihS5cuKTIyUlOmTFHFihVv+Nw0VwAAwHZO73O1ZMkS1a5dW8OHD9fp\n06f1xBNPqFmzZkpOTla3bt302muvafHixUpOTr7hczPnCgAAlDvh4eE6d+6cJOnChQsKDw/Xli1b\ndPfdd0uSEhMTtWnTphKdm+YKAADYzrTh61q6d++uEydO6J577lH//v2VkpKi/Px89zBgRESEMjMz\nS3RvDAsCAADbOT2hfenSpYqJidHs2bO1b98+jR49utjrpamP5AoAAJQ727dvV4cOHSRJDRo0UEZG\nhoKCglRQUCBJOn36tKKiokp0bporAABgO5dpev3rWmJjY7Vjxw5J0vHjxxUSEqI777xTK1askCSt\nXLlSHTt2LNG9MSwIAADKnT59+mj06NHq37+/ioqKNHbsWNWtW1cpKSlatGiRYmJi1LNnzxKdm+YK\nAADYzuk5VyEhIZo2bdplz7/77rulPjfDggAAAB5EcgUAAGzn9Cai3kRyBQAA4EEkVwAAwHY+HFyR\nXAEAAHgSyRUAALCd06sFvYnkCgAAwINIrgAAgO1YLQgAAABLSK4AAIDtSK4AAABgCckVAACwHasF\nAQAAYAnJFQAAsB3JFQAAACwhuQIAALZz+W5wRXMFAADsx7AgAAAALCG5KqVKd3dWeO+eMoICVfDd\nHmVMe1OGfwVV/Y8nFdiwvgz/Cjr7/kLlrP3K6VJRSp988onef/99maapqKgopaSk6O2339bevXvd\nx+Tk5Cg+Pl5TpkxxsFKUxr5/bNSOtStlmqZCwsLV8eFkhUVF6/yZDK2aO0u3BIeox38Mc7pMoMzz\n5eSK5qoUKsbWUNU/PqGjz7ygS2d+VNSIIQp/9OdGyy8wUEefek7+EeGq/tdJKtjzvYpOZzhdMkoo\nPT1d06ZN04IFCxQVFaXFixdr/Pjxmj17drHjBg8erB49ejhUJUor6/RJbf50sR4d/pIqhYVr99fr\n9D+L3tNdfZ7Q8jkzdVuderrwY6bTZQK4yTEsWApBTZsof8cuXTrzoyTp/N8/V8idbRTcLF7Zq9dK\npqlLZ84qd9M/FNKulcPVojQOHTqkmjVrKioqSpLUqlUrHTx4sNgxGzduVGFhoTp16uREifCArNMn\nVblqtCqFhUuSbv9NA509eUL+FQLU4+lhiq5V1+EKAd/hMk2vfzmF5qoUTJmS3//9CF0FBQqIqSaZ\n/+/5/AIF3FbNiRLhIU2aNNGxY8d04MABmaapL7/8Um3atCl2zKxZs/SHP/zBoQrhCdGxdXT+x0yd\nPXlcpmnq0M7tql7/DoVWiVDIrWFOlwegjGBYsBTyv/1OEU/0VcXYGrp49LgqP3CfjIoVlffNTlV+\n4D7lb98p/7DKCmnfRgXf7Xa6XJRCZGSkBg0apH79+ik4OFhBQUF666233K9v27ZNktSiRQunSoQH\nhFQOU5v7e+rDV/+sgFsCFVCxoh4c9LzTZQE+qVzPudqwYYMWLFignJycYj+IefPmebWwsqDwyDGd\neXO2okcOlVlYqAsr18qVk6us+YtV9T+eVPWZr6rw5CnlbftGKipyulyUwr59+zRnzhwtXbpU1apV\n07JlyzRs2DAtWrRIhmFo+fLl6tq1q9NlopTOHDui7auXKXnMBIWGR2j/ts1aPvsN/XbEWBmG4XR5\nAMqI6zZXEyZM0JgxYxQdHW1HPWVO9up1yl69TpIU2PgOXUw/IvOnn5T51zfdx0QOfZrkqozbunWr\n4uPjVa3az8O7Xbt21UsvvaRz584pPDxcGzZsUP/+/R2uEqV1LG2fomvVVWh4hCSpbrOW+nL+HBXk\n5iioUqjD1QG+xZc3Eb3unKvY2Fh16NBB9erVK/YFqcJt1VT99SnyCwmW/P0V3udhZa9eq7DePRXx\nh8clSQE1qysooYlyN211uFqURmxsrHbu3Klz585J+jnRjYiIUFhYmM6ePausrCzVrFnT4SpRWmFR\n0TqdflAFuTmSpCN7dyk49FYFhlRyuDIAZclVk6v//u//liRFR0dryJAhatGihfz9/d2v9+vXz/vV\n3eSKTp5S7uatqv7Gq5JM5fzPBmWvXif/sMqKHjlUNee8IfPiRWVMfV2u3Dyny0UpdOrUSXv37tWT\nTz4pSapUqZImT54swzCUkZGhsLAw+fmxPqSsq9WoqTKP/qAl0ydJMlQxMFD3PPHv2rNpvb5bv1oX\n8/N18acCLZz0oqJq1lZS8pNOlwyUWS7T5XQJXmOYV5lR9vrrr1/zG5955hnLFznY7dEbqwplTt0v\nFis7O9vpMuBloaE/D4395fN1DlcCbxravbMkKTOT32lfFxnp3HD307MXe/0aMwc4039cNbn6pXn6\n8MMP1bt372Kvvfvuu96tCgAA+DQfXix49eZq48aN2rBhg5YvX67Dhw+7ny8qKtIXX3yh3//+97YU\nCAAAUJZctblq2rSpKlSooK+++kpxcXHubRgMw7gsyQIAALgR5XKfq0qVKqlNmzZ66aWXLtvf5ZcV\nUwAAACjuuvtcpaamuv9cVFSkvXv3qnHjxmrVis/KAwAAJePkZ/9523Wbq+nTpxd7nJ+frzFjxnit\nIAAAgLLshj9b0M/PTwcOHPBGLQAAoJwol3OuftG2bVv3nCvTNOXn56e+fft6vTAAAICy6LrN1ezZ\ns9WoUSM7agEAAOWELydX1/28jsmTJ6uoqMiOWgAAAMq86yZXwcHB6tq1qxo0aKCAgAD389OmTfNq\nYQAAwHe5fDe4unpzNXjwYE2fPt39QbUAAACe4svDgldtrn7ZKLR169a2FQMAAFDWXbW5OnLkiF55\n5ZWrfuOIESO8UhAAAPB9LpXD5CooKEj16tWzsxYAAIAy76rNVdWqVdWrVy87awEAAOWEL8+5uupW\nDI0bN7azDgAAAJ9w1eQqJSXFzjoAAEA54vLhvRiuu4koAAAArLvhD24GAAAorXI55woAAAA3juQK\nAADYzoenXJFcAQAAeBLJFQAAsB1zrgAAAGAJyRUAALCd6cOfLUhyBQAA4EEkVwAAwHYu5lwBAADA\nCpIrAABgO1YLAgAAwBKSKwAAYDtf3qGd5goAANiOYUEAAABYQnIFAABsR3IFAAAAS0iuAACA7dhE\nFAAAAJaQXAEAANuRXAEAAMASkisAAGA7VgsCAADAEpIrAABgOx8OrkiuAAAAPInkCgAA2I7VggAA\nALCE5AoAANiO1YIAAACwhOQKAADYjjlXAAAAsITkCgAA2I45VwAAALCE5AoAANjOh4MrmisAAGA/\nJrQDAADAEpIrAABgO1+e0G5Lc1X3i8V2XAYOCw0NdboE2GRo985OlwAbREbyOw2UhGH6cusIAABg\nM+ZcAQAAeBDNFQAAgAfRXAEAAHgQzRUAAIAH0VwBAAB4EM0VAACAB9FcedD48ePVq1cv5eTkOF0K\nHDJy5EitXbvW6TLgAUlJScrNzXW6DJTSpEmT9Nhjj+m+++5T586d9dhjj+mZZ5657vfl5ORow4YN\nkqQZM2YoNTXV26XCh7BDuwetW7dOS5YsUaVKlZwuBQCgn//BI0kff/yx0tLSlJKSYun7du/erY0b\nN6pDhw7eLA8+iuaqlD7++GOtX79eX375pS5duqSBAwdq1qxZmjZtmnbu3Cl/f3+NGzdOcXFxTpeK\nG/Txxx9r69atysrKUlpamoYOHarPPvtMBw8e1NSpUzVlyhTVqFFD33//ve644w5NmDBBkrR27VrN\nnTtXZ8+e1cSJE9WoUSOH7wTXk5OTo+HDhysvL08FBQV68cUXJUmzZs3Stm3b5O/vrzfeeENBQUEa\nOXKkjh8/rltuuUWvvPKKoqOjHa4eN2rLli2aM2eO8vLylJKSogEDBmjLli2SpMGDB6tfv34aP368\ncnJyVKtWLUnS/v379e///u9KT0/XmDFj1KlTJwfvADc7misPOHnypHbs2KG7775bb7/9tnbs2KFT\np07pgw8+0NatW7Vs2TKaqzIqPT1d8+fP14cffqhZs2bp73//uz7++GPNmjVLu3fv1l/+8hdFRESo\nU6dOunDhgvv73nvvPa1du1Z/+9vfNGPGDAfvAFZkZmaqd+/e6tKlizZt2qS3335bklS/fn0NGzZM\nkydP1tKlSxUYGKiqVavq1Vdf1eeff641a9YoOTnZ4epREvv379eKFStUsWLFK74+YMAApaWlqU+f\nPpoxY4bOnTunWbNm6auvvtKCBQtornBNNFce0KRJExmG4X68e/duNW/eXJLUqlUrtWrVyqnSUEqN\nGzeWYRiKjIxU/fr15e/vr6pVqyo7O1s1a9ZUZGSkJCkqKkrZ2dmSpLZt20qS4uPj9eqrrzpWO6yr\nWrWqZs6cqdmzZ+vixYsKDg6WJLVp00bSz7/j27Ztk8vlUrt27SRJ3bt3d6xelF79+vWv2lhdyS//\nT4+Ojnb/rgNXw4R2DwgICCj22N/fXy6Xy6Fq4EkVKlS44p9vv/12+fv7Fzv2Sh/T+eumGzevuXPn\nKjo6WgsWLNDYsWPdz//6/TMMg99tH3K1xqqwsPCKz//69x+4HporL2jSpIl7/H7Pnj0aN26cwxXB\nTv/85z8lSd9++63q1KnjcDWwIisrSzVr1pQkrV692v0X7LZt2yRJO3bsUJ06ddSkSRNt3rxZktzD\nvij7DMNQfn6+8vPztXfvXkmSn5+fioqKHK4MZRWtuBe0atWq2FyMl19+2eGKYLeBAwfq5MmTeuWV\nV5wuBRY89NBDSklJ0fLly9WvXz999tlnMk1TaWlpWrBggSTp2WefVcWKFfX111+rf//+qlChgiZP\nnuxw5fCEvn376re//a3q1q3rXoDSsGFDTZ06VdWqVXO4OpRFhnmlsQwAAACUCMOCAAAAHkRzBQAA\n4EE0VwAAAB5EcwUAAOBBNFcAAAAeRHMFAADgQTRXAAAAHkRzBQAA4EH/C4zNlyI+lr2gAAAAAElF\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f755e56d198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mlens.visualization import corrmat\n",
    "ax = corrmat(P.corr())\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dicts = {\n",
    "    'rfc': \n",
    "        {'n_estimators': randint(5, 40),\n",
    "         'max_features': ['sqrt', 'log2', None],\n",
    "         'n_jobs': [-1]\n",
    "        },\n",
    "    'abc':\n",
    "        {'n_estimators': randint(25, 50, 100),\n",
    "         'learning_rate': uniform(0.1, 10),\n",
    "        },\n",
    "    'mnb':\n",
    "        {'alpha': [0.026895783878784774],\n",
    "         'class_prior': [None],\n",
    "         'fit_prior': [False]\n",
    "        }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "\n",
    "evl = Evaluator(scorer, \n",
    "                cv=2,\n",
    "                random_state=42,\n",
    "                verbose=5\n",
    "               )\n",
    "\n",
    "\n",
    "meta_learners = [('rfc', rfc)]\n",
    "\n",
    "in_layer = EnsembleTransformer()\n",
    "in_layer.add('stack', base_learners)\n",
    "preprocess = [in_layer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SuperLearner(array_check=2, backend='threading', folds=2,\n",
       "       layers=LayerContainer(backend='threading',\n",
       "        layers=OrderedDict([('layer-1', Layer(cls='stack', cls_kwargs=None,\n",
       "   estimators=[('rfc', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            ...n_exception=True, scorer=None, verbose=5))]),\n",
       "        n_jobs=-1, raise_on_exception=True, verbose=5),\n",
       "       n_jobs=-1, raise_on_exception=True, random_state=None, scorer=None,\n",
       "       shuffle=False, verbose=5)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ens = SuperLearner(verbose=5,\n",
    "                   backend=\"threading\")\n",
    "ens.add(base_learners)\n",
    "ens.add_meta(meta_learners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing layers (2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting layer-1\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    0.2s remaining:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   9 | elapsed:    1.2s remaining:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    2.0s remaining:    1.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit complete | 00:00:17\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   17.5s finished\n",
      "layer-1 Done | 00:00:17\n",
      "\n",
      "Fitting layer-2\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "layer-2 Done | 00:00:00\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SuperLearner(array_check=2, backend='threading', folds=2,\n",
       "       layers=LayerContainer(backend='threading',\n",
       "        layers=OrderedDict([('layer-1', Layer(cls='stack', cls_kwargs=None,\n",
       "   estimators=[('rfc', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            ...n_exception=True, scorer=None, verbose=5))]),\n",
       "        n_jobs=-1, raise_on_exception=True, verbose=5),\n",
       "       n_jobs=-1, raise_on_exception=True, random_state=None, scorer=None,\n",
       "       shuffle=False, verbose=5)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ens.fit(X_train_tfidf, y_train_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_tfidf = vectorizer.fit_transform(X_test_text_clean, y_test_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1267, 62200)\n",
      "1267\n",
      "(5068, 286760)\n",
      "5068\n"
     ]
    }
   ],
   "source": [
    "print(X_test_tfidf.shape)\n",
    "print(len(y_test_binary))\n",
    "print(X_train_tfidf.shape)\n",
    "print(len(y_train_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing layers (2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting layer-1\n"
     ]
    },
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x7f75a5c8c0c0, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/anthonyle/anaconda3/envs/deep_learning/lib...ges/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/anthon.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7f75a5c8c0c0, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/anthonyle/anaconda3/envs/deep_learning/lib...ges/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/anthon.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n     17 \n     18 \n     19 \n     20 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'ens_pred = ens.predict(X_test_tfidf)\\nprint(\"Ense...at(mean_absolute_error(y_test_binary, ens_pred)))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 6, 25, 15, 45, 31, 527030, tzinfo=datetime.timezone.utc), 'msg_id': '7CEDC65BE2AF4064BADF387A91B23A59', 'msg_type': 'execute_request', 'session': '55AD9960AF514B44A33856CD0CDB88E6', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '7CEDC65BE2AF4064BADF387A91B23A59', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'55AD9960AF514B44A33856CD0CDB88E6']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'ens_pred = ens.predict(X_test_tfidf)\\nprint(\"Ense...at(mean_absolute_error(y_test_binary, ens_pred)))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 6, 25, 15, 45, 31, 527030, tzinfo=datetime.timezone.utc), 'msg_id': '7CEDC65BE2AF4064BADF387A91B23A59', 'msg_type': 'execute_request', 'session': '55AD9960AF514B44A33856CD0CDB88E6', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '7CEDC65BE2AF4064BADF387A91B23A59', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'55AD9960AF514B44A33856CD0CDB88E6'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'ens_pred = ens.predict(X_test_tfidf)\\nprint(\"Ense...at(mean_absolute_error(y_test_binary, ens_pred)))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 6, 25, 15, 45, 31, 527030, tzinfo=datetime.timezone.utc), 'msg_id': '7CEDC65BE2AF4064BADF387A91B23A59', 'msg_type': 'execute_request', 'session': '55AD9960AF514B44A33856CD0CDB88E6', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '7CEDC65BE2AF4064BADF387A91B23A59', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='ens_pred = ens.predict(X_test_tfidf)\\nprint(\"Ense...at(mean_absolute_error(y_test_binary, ens_pred)))', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'ens_pred = ens.predict(X_test_tfidf)\\nprint(\"Ense...at(mean_absolute_error(y_test_binary, ens_pred)))'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('ens_pred = ens.predict(X_test_tfidf)\\nprint(\"Ense...at(mean_absolute_error(y_test_binary, ens_pred)))',), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('ens_pred = ens.predict(X_test_tfidf)\\nprint(\"Ense...at(mean_absolute_error(y_test_binary, ens_pred)))',)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='ens_pred = ens.predict(X_test_tfidf)\\nprint(\"Ense...at(mean_absolute_error(y_test_binary, ens_pred)))', store_history=True, silent=False, shell_futures=True)\n   2693                 self.displayhook.exec_result = result\n   2694 \n   2695                 # Execute the user code\n   2696                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2697                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2698                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2699                 \n   2700                 self.last_execution_succeeded = not has_raised\n   2701 \n   2702                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-124-4d700f445c49>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7f755f937c88, executi..._before_exec=None error_in_exec=None result=None>)\n   2797 \n   2798         try:\n   2799             for i, node in enumerate(to_run_exec):\n   2800                 mod = ast.Module([node])\n   2801                 code = compiler(mod, cell_name, \"exec\")\n-> 2802                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f7567666d20, file \"<ipython-input-124-4d700f445c49>\", line 1>\n        result = <ExecutionResult object at 7f755f937c88, executi..._before_exec=None error_in_exec=None result=None>\n   2803                     return True\n   2804 \n   2805             for i, node in enumerate(to_run_interactive):\n   2806                 mod = ast.Interactive([node])\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f7567666d20, file \"<ipython-input-124-4d700f445c49>\", line 1>, result=<ExecutionResult object at 7f755f937c88, executi..._before_exec=None error_in_exec=None result=None>)\n   2857         outflag = True  # happens in more places, so it's easier as default\n   2858         try:\n   2859             try:\n   2860                 self.hooks.pre_run_code_hook()\n   2861                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2862                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f7567666d20, file \"<ipython-input-124-4d700f445c49>\", line 1>\n        self.user_global_ns = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'EnsembleTransformer': <class 'mlens.preprocessing.ensemble_transformer.EnsembleTransformer'>, 'Evaluator': <class 'mlens.model_selection.model_selection.Evaluator'>, 'In': ['', \"import pandas as pd\\nfake_real_df = pd.read_csv('./fake_or_real_news.csv')\", \"fake_real_df_clean = fake_real_df[['title','text','label']]\", 'from sklearn.model_selection import StratifiedSh...rat_test_set = fake_real_df_clean.loc[test_index]', 'strat_fake_or_real_train = strat_train_set.copy()\\nstrat_fake_or_real_test  = strat_test_set.copy()', \"X_train = strat_fake_or_real_train.copy().drop('...y_test  = strat_fake_or_real_test.copy()['label']\", \"import nltk\\nfrom nltk.corpus import stopwords\\nfr...t = ' '.join(tokens)\\n    return preprocessed_text\", \"X_train_text_list  = list(X_train['text'])\\nX_tra...ext'])\\nX_test_title_list  = list(X_test['title'])\", 'X_train_text_clean = [preprocessing(text) for te...reprocessing(text) for text in X_test_title_list]', 'nltk.download()', \"import pandas as pd\\nfake_real_df = pd.read_csv('./fake_or_real_news.csv')\", \"fake_real_df_clean = fake_real_df[['title','text','label']]\", 'from sklearn.model_selection import StratifiedSh...rat_test_set = fake_real_df_clean.loc[test_index]', 'strat_fake_or_real_train = strat_train_set.copy()\\nstrat_fake_or_real_test  = strat_test_set.copy()', \"X_train = strat_fake_or_real_train.copy().drop('...y_test  = strat_fake_or_real_test.copy()['label']\", \"import nltk\\nfrom nltk.corpus import stopwords\\nfr...t = ' '.join(tokens)\\n    return preprocessed_text\", \"X_train_text_list  = list(X_train['text'])\\nX_tra...ext'])\\nX_test_title_list  = list(X_test['title'])\", 'X_train_text_clean = [preprocessing(text) for te...reprocessing(text) for text in X_test_title_list]', \"y_train_binary = [x=='REAL' for x in list(y_trai...y_test_binary = [x=='REAL' for x in list(y_test)]\", \"'''\\nThe code above is all cleaning.\\nI separated ...fit_transform(X_train_text_clean, y_train_binary)\", ...], 'LancasterStemmer': <class 'nltk.stem.lancaster.LancasterStemmer'>, 'LarsCV': <class 'sklearn.linear_model.least_angle.LarsCV'>, 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'MyTfidfVectorizer': <class '__main__.MyTfidfVectorizer'>, 'Out': {9: True, 21: array([ 0.82955665,  0.82741617,  0.82329714,  0.81342547,  0.83119447]), 22: '\\nIt is now up to you to use the data as you wish...ll going to work on improving the current model.\\n', 29: <5068x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, 30: <1x286760 sparse matrix of type '<class 'numpy.f... stored elements in Compressed Sparse Row format>, 31: (5068, 286760), 32: 5068, 36: <class 'int'>, 37: 4, 38: <class 'int'>, ...}, 'P':         rfc    mnb    abc  Truth\n0      True   T...lse  False  False  False\n\n[5068 rows x 4 columns], ...}\n        self.user_ns = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'EnsembleTransformer': <class 'mlens.preprocessing.ensemble_transformer.EnsembleTransformer'>, 'Evaluator': <class 'mlens.model_selection.model_selection.Evaluator'>, 'In': ['', \"import pandas as pd\\nfake_real_df = pd.read_csv('./fake_or_real_news.csv')\", \"fake_real_df_clean = fake_real_df[['title','text','label']]\", 'from sklearn.model_selection import StratifiedSh...rat_test_set = fake_real_df_clean.loc[test_index]', 'strat_fake_or_real_train = strat_train_set.copy()\\nstrat_fake_or_real_test  = strat_test_set.copy()', \"X_train = strat_fake_or_real_train.copy().drop('...y_test  = strat_fake_or_real_test.copy()['label']\", \"import nltk\\nfrom nltk.corpus import stopwords\\nfr...t = ' '.join(tokens)\\n    return preprocessed_text\", \"X_train_text_list  = list(X_train['text'])\\nX_tra...ext'])\\nX_test_title_list  = list(X_test['title'])\", 'X_train_text_clean = [preprocessing(text) for te...reprocessing(text) for text in X_test_title_list]', 'nltk.download()', \"import pandas as pd\\nfake_real_df = pd.read_csv('./fake_or_real_news.csv')\", \"fake_real_df_clean = fake_real_df[['title','text','label']]\", 'from sklearn.model_selection import StratifiedSh...rat_test_set = fake_real_df_clean.loc[test_index]', 'strat_fake_or_real_train = strat_train_set.copy()\\nstrat_fake_or_real_test  = strat_test_set.copy()', \"X_train = strat_fake_or_real_train.copy().drop('...y_test  = strat_fake_or_real_test.copy()['label']\", \"import nltk\\nfrom nltk.corpus import stopwords\\nfr...t = ' '.join(tokens)\\n    return preprocessed_text\", \"X_train_text_list  = list(X_train['text'])\\nX_tra...ext'])\\nX_test_title_list  = list(X_test['title'])\", 'X_train_text_clean = [preprocessing(text) for te...reprocessing(text) for text in X_test_title_list]', \"y_train_binary = [x=='REAL' for x in list(y_trai...y_test_binary = [x=='REAL' for x in list(y_test)]\", \"'''\\nThe code above is all cleaning.\\nI separated ...fit_transform(X_train_text_clean, y_train_binary)\", ...], 'LancasterStemmer': <class 'nltk.stem.lancaster.LancasterStemmer'>, 'LarsCV': <class 'sklearn.linear_model.least_angle.LarsCV'>, 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'MyTfidfVectorizer': <class '__main__.MyTfidfVectorizer'>, 'Out': {9: True, 21: array([ 0.82955665,  0.82741617,  0.82329714,  0.81342547,  0.83119447]), 22: '\\nIt is now up to you to use the data as you wish...ll going to work on improving the current model.\\n', 29: <5068x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, 30: <1x286760 sparse matrix of type '<class 'numpy.f... stored elements in Compressed Sparse Row format>, 31: (5068, 286760), 32: 5068, 36: <class 'int'>, 37: 4, 38: <class 'int'>, ...}, 'P':         rfc    mnb    abc  Truth\n0      True   T...lse  False  False  False\n\n[5068 rows x 4 columns], ...}\n   2863             finally:\n   2864                 # Reset our crash handler in place\n   2865                 sys.excepthook = old_excepthook\n   2866         except SystemExit as e:\n\n...........................................................................\n/mnt/Linux-Extra/home-extra/Anthony.Le/Projects/fake_news/<ipython-input-124-4d700f445c49> in <module>()\n----> 1 \n      2 \n      3 \n      4 \n      5 \n      6 ens_pred = ens.predict(X_test_tfidf)\n      7 print(\"Ensemble mean absolute error: {0}\".format(mean_absolute_error(y_test_binary, ens_pred)))\n      8 \n      9 \n     10 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/ensemble/base.py in predict(self=SuperLearner(array_check=2, backend='threading',...ne, scorer=None,\n       shuffle=False, verbose=5), X=<1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>)\n    739         if self.shuffle:\n    740             r = check_random_state(self.random_state)\n    741             idx = r.permutation(X.shape[0])\n    742             X = X[idx]\n    743 \n--> 744         y = self.layers.predict(X)\n        y = undefined\n        self.layers.predict = <bound method LayerContainer.predict of LayerCon...  n_jobs=-1, raise_on_exception=True, verbose=5)>\n        X = <1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>\n    745 \n    746         if y.shape[1] == 1:\n    747             # The meta estimator is treated as a layer and thus a prediction\n    748             # matrix with shape [n_samples, 1] is created. Ravel before return\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/ensemble/base.py in predict(self=LayerContainer(backend='threading',\n        laye...   n_jobs=-1, raise_on_exception=True, verbose=5), X=<1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>, *args=(), **kwargs={})\n    262         Returns\n    263         -------\n    264         X_pred : array-like of shape = [n_samples, n_fitted_estimators]\n    265             predictions from final layer.\n    266         \"\"\"\n--> 267         return self._predict(X, 'predict', *args, **kwargs)\n        self._predict = <bound method LayerContainer._predict of LayerCo...  n_jobs=-1, raise_on_exception=True, verbose=5)>\n        X = <1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>\n        args = ()\n        kwargs = {}\n    268 \n    269     def transform(self, X=None, *args, **kwargs):\n    270         \"\"\"Generic method for reproducing predictions of the ``fit`` call.\n    271 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/ensemble/base.py in _predict(self=LayerContainer(backend='threading',\n        laye...   n_jobs=-1, raise_on_exception=True, verbose=5), X=<1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>, job='predict', *args=(), **kwargs={})\n    315         processor = ParallelProcessing(self)\n    316         processor.initialize(job, X, *args, **kwargs)\n    317 \n    318         # Predict with ensemble\n    319         try:\n--> 320             processor.process()\n        processor.process = <bound method ParallelProcessing.process of <mlens.parallel.manager.ParallelProcessing object>>\n    321 \n    322             preds = processor.get_preds()\n    323 \n    324             if self.verbose:\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/parallel/manager.py in process(self=<mlens.parallel.manager.ParallelProcessing object>)\n    213                       mmap_mode='w+',\n    214                       verbose=self.layers.verbose,\n    215                       backend=self.layers.backend) as parallel:\n    216 \n    217             for n, lyr in enumerate(self.layers.layers.values()):\n--> 218                 self._partial_process(n, lyr, parallel)\n        self._partial_process = <bound method ParallelProcessing._partial_proces...lens.parallel.manager.ParallelProcessing object>>\n        n = 0\n        lyr = Layer(cls='stack', cls_kwargs=None,\n   estimator... raise_on_exception=True, scorer=None, verbose=5)\n        parallel = Parallel(n_jobs=-1)\n    219 \n    220         self.__fitted__ = 1\n    221 \n    222     def get_preds(self, n=-1, dtype=np.float, order='C'):\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/parallel/manager.py in _partial_process(self=<mlens.parallel.manager.ParallelProcessing object>, n=0, lyr=Layer(cls='stack', cls_kwargs=None,\n   estimator... raise_on_exception=True, scorer=None, verbose=5), parallel=Parallel(n_jobs=-1))\n    303         if 'X' in fargs:\n    304             kwargs['X'] = self.job.P[n]\n    305         if 'P' in fargs:\n    306             kwargs['P'] = self.job.P[n + 1]\n    307 \n--> 308         f(**kwargs)\n        f = <bound method BaseEstimator.predict of <mlens.parallel.stack.Stacker object>>\n        kwargs = {'P': memmap([[ 0.,  0.,  0.],\n       [ 0.,  0.,  0.],...\n       [ 0.,  0.,  0.],\n       [ 0.,  0.,  0.]]), 'X': <1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>, 'parallel': Parallel(n_jobs=-1)}\n    309 \n    310 \n    311 ###############################################################################\n    312 class ParallelEvaluation(object):\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/parallel/estimation.py in predict(self=<mlens.parallel.stack.Stacker object>, X=<1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>, P=memmap([[ 0.,  0.,  0.],\n       [ 0.,  0.,  0.],...\n       [ 0.,  0.,  0.],\n       [ 0.,  0.,  0.]]), parallel=Parallel(n_jobs=-1))\n    224                                       xtest=X,\n    225                                       pred=P,\n    226                                       col=col,\n    227                                       name=self.name,\n    228                                       attr=pred_method)\n--> 229                  for case, (inst_name, est, (_, col)) in ests)\n        ests = [(None, ('rfc', RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), (None, 0))), (None, ('mnb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), (None, 1))), (None, ('abc', AdaBoostClassifier(algorithm='SAMME.R', base_est...ing_rate=1.0, n_estimators=50, random_state=None), (None, 2)))]\n    230 \n    231         if self.verbose:\n    232             print_time(t0, '%s Done' % self.name, file=printout)\n    233 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseEstimator.predict.<locals>.<genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Sun Jun 25 08:45:31 2017\nPID: 16426Python 3.6.1: /home/anthonyle/anaconda3/envs/deep_learning/bin/python\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/externals/joblib/parallel.py in __call__(self=<mlens.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function predict_est>, (), {'attr': 'predict', 'case': None, 'col': 0, 'est': RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), 'inst_name': 'rfc', 'name': 'layer-1', 'pred': memmap([[ 0.,  0.,  0.],\n       [ 0.,  0.,  0.],...\n       [ 0.,  0.,  0.],\n       [ 0.,  0.,  0.]]), 'tr_list': [], 'xtest': <1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function predict_est>\n        args = ()\n        kwargs = {'attr': 'predict', 'case': None, 'col': 0, 'est': RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), 'inst_name': 'rfc', 'name': 'layer-1', 'pred': memmap([[ 0.,  0.,  0.],\n       [ 0.,  0.,  0.],...\n       [ 0.,  0.,  0.],\n       [ 0.,  0.,  0.]]), 'tr_list': [], 'xtest': <1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/parallel/estimation.py in predict_est(case=None, tr_list=[], inst_name='rfc', est=RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), xtest=<1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>, pred=memmap([[ 0.,  0.,  0.],\n       [ 0.,  0.,  0.],...\n       [ 0.,  0.,  0.],\n       [ 0.,  0.,  0.]]), col=0, name='layer-1', attr='predict')\n    402 \n    403     # Predict into memmap\n    404     # Here, we coerce errors on failed predictions - all predictors that\n    405     # survive into the estimators_ attribute of a layer should be able to\n    406     # predict, otherwise the subsequent layer will get corrupt input.\n--> 407     p = getattr(est, attr)(xtest)\n        p = undefined\n        est = RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False)\n        attr = 'predict'\n        xtest = <1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>\n    408 \n    409     if len(p.shape) == 1:\n    410         pred[:, col] = p\n    411     else:\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/ensemble/forest.py in predict(self=RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), X=<1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>)\n    529         Returns\n    530         -------\n    531         y : array of shape = [n_samples] or [n_samples, n_outputs]\n    532             The predicted classes.\n    533         \"\"\"\n--> 534         proba = self.predict_proba(X)\n        proba = undefined\n        self.predict_proba = <bound method ForestClassifier.predict_proba of ...e=None,\n            verbose=0, warm_start=False)>\n        X = <1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>\n    535 \n    536         if self.n_outputs_ == 1:\n    537             return self.classes_.take(np.argmax(proba, axis=1), axis=0)\n    538 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/ensemble/forest.py in predict_proba(self=RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), X=<1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>)\n    568             such arrays if n_outputs > 1.\n    569             The class probabilities of the input samples. The order of the\n    570             classes corresponds to that in the attribute `classes_`.\n    571         \"\"\"\n    572         # Check data\n--> 573         X = self._validate_X_predict(X)\n        X = <1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>\n        self._validate_X_predict = <bound method BaseForest._validate_X_predict of ...e=None,\n            verbose=0, warm_start=False)>\n    574 \n    575         # Assign chunk of trees to jobs\n    576         n_jobs, _, _ = _partition_estimators(self.n_estimators, self.n_jobs)\n    577 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/ensemble/forest.py in _validate_X_predict(self=RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), X=<1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>)\n    350         \"\"\"Validate X whenever one tries to predict, apply, predict_proba\"\"\"\n    351         if self.estimators_ is None or len(self.estimators_) == 0:\n    352             raise NotFittedError(\"Estimator not fitted, \"\n    353                                  \"call `fit` before exploiting the model.\")\n    354 \n--> 355         return self.estimators_[0]._validate_X_predict(X, check_input=True)\n        self.estimators_._validate_X_predict = undefined\n        X = <1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>\n    356 \n    357     @property\n    358     def feature_importances_(self):\n    359         \"\"\"Return the feature importances (the higher, the more important the\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/tree/tree.py in _validate_X_predict(self=DecisionTreeClassifier(class_weight=None, criter...rt=False, random_state=30958129, splitter='best'), X=<1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>, check_input=True)\n    371         n_features = X.shape[1]\n    372         if self.n_features_ != n_features:\n    373             raise ValueError(\"Number of features of the model must \"\n    374                              \"match the input. Model n_features is %s and \"\n    375                              \"input n_features is %s \"\n--> 376                              % (self.n_features_, n_features))\n        self.n_features_ = 286760\n        n_features = 62200\n    377 \n    378         return X\n    379 \n    380     def predict(self, X, check_input=True):\n\nValueError: Number of features of the model must match the input. Model n_features is 286760 and input n_features is 62200 \n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/parallel/estimation.py\u001b[0m in \u001b[0;36mpredict_est\u001b[0;34m(case, tr_list, inst_name, est, xtest, pred, col, name, attr)\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;31m# predict, otherwise the subsequent layer will get corrupt input.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    533\u001b[0m         \"\"\"\n\u001b[0;32m--> 534\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    375\u001b[0m                              \u001b[0;34m\"input n_features is %s \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                              % (self.n_features_, n_features))\n\u001b[0m\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features is 286760 and input n_features is 62200 ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    681\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m'timeout'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgetfullargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mworker\u001b[0;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat_exc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_tb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTransportableException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nValueError                                         Sun Jun 25 08:45:31 2017\nPID: 16426Python 3.6.1: /home/anthonyle/anaconda3/envs/deep_learning/bin/python\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/externals/joblib/parallel.py in __call__(self=<mlens.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function predict_est>, (), {'attr': 'predict', 'case': None, 'col': 0, 'est': RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), 'inst_name': 'rfc', 'name': 'layer-1', 'pred': memmap([[ 0.,  0.,  0.],\n       [ 0.,  0.,  0.],...\n       [ 0.,  0.,  0.],\n       [ 0.,  0.,  0.]]), 'tr_list': [], 'xtest': <1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function predict_est>\n        args = ()\n        kwargs = {'attr': 'predict', 'case': None, 'col': 0, 'est': RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), 'inst_name': 'rfc', 'name': 'layer-1', 'pred': memmap([[ 0.,  0.,  0.],\n       [ 0.,  0.,  0.],...\n       [ 0.,  0.,  0.],\n       [ 0.,  0.,  0.]]), 'tr_list': [], 'xtest': <1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/parallel/estimation.py in predict_est(case=None, tr_list=[], inst_name='rfc', est=RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), xtest=<1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>, pred=memmap([[ 0.,  0.,  0.],\n       [ 0.,  0.,  0.],...\n       [ 0.,  0.,  0.],\n       [ 0.,  0.,  0.]]), col=0, name='layer-1', attr='predict')\n    402 \n    403     # Predict into memmap\n    404     # Here, we coerce errors on failed predictions - all predictors that\n    405     # survive into the estimators_ attribute of a layer should be able to\n    406     # predict, otherwise the subsequent layer will get corrupt input.\n--> 407     p = getattr(est, attr)(xtest)\n        p = undefined\n        est = RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False)\n        attr = 'predict'\n        xtest = <1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>\n    408 \n    409     if len(p.shape) == 1:\n    410         pred[:, col] = p\n    411     else:\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/ensemble/forest.py in predict(self=RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), X=<1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>)\n    529         Returns\n    530         -------\n    531         y : array of shape = [n_samples] or [n_samples, n_outputs]\n    532             The predicted classes.\n    533         \"\"\"\n--> 534         proba = self.predict_proba(X)\n        proba = undefined\n        self.predict_proba = <bound method ForestClassifier.predict_proba of ...e=None,\n            verbose=0, warm_start=False)>\n        X = <1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>\n    535 \n    536         if self.n_outputs_ == 1:\n    537             return self.classes_.take(np.argmax(proba, axis=1), axis=0)\n    538 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/ensemble/forest.py in predict_proba(self=RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), X=<1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>)\n    568             such arrays if n_outputs > 1.\n    569             The class probabilities of the input samples. The order of the\n    570             classes corresponds to that in the attribute `classes_`.\n    571         \"\"\"\n    572         # Check data\n--> 573         X = self._validate_X_predict(X)\n        X = <1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>\n        self._validate_X_predict = <bound method BaseForest._validate_X_predict of ...e=None,\n            verbose=0, warm_start=False)>\n    574 \n    575         # Assign chunk of trees to jobs\n    576         n_jobs, _, _ = _partition_estimators(self.n_estimators, self.n_jobs)\n    577 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/ensemble/forest.py in _validate_X_predict(self=RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), X=<1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>)\n    350         \"\"\"Validate X whenever one tries to predict, apply, predict_proba\"\"\"\n    351         if self.estimators_ is None or len(self.estimators_) == 0:\n    352             raise NotFittedError(\"Estimator not fitted, \"\n    353                                  \"call `fit` before exploiting the model.\")\n    354 \n--> 355         return self.estimators_[0]._validate_X_predict(X, check_input=True)\n        self.estimators_._validate_X_predict = undefined\n        X = <1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>\n    356 \n    357     @property\n    358     def feature_importances_(self):\n    359         \"\"\"Return the feature importances (the higher, the more important the\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/tree/tree.py in _validate_X_predict(self=DecisionTreeClassifier(class_weight=None, criter...rt=False, random_state=30958129, splitter='best'), X=<1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>, check_input=True)\n    371         n_features = X.shape[1]\n    372         if self.n_features_ != n_features:\n    373             raise ValueError(\"Number of features of the model must \"\n    374                              \"match the input. Model n_features is %s and \"\n    375                              \"input n_features is %s \"\n--> 376                              % (self.n_features_, n_features))\n        self.n_features_ = 286760\n        n_features = 62200\n    377 \n    378         return X\n    379 \n    380     def predict(self, X, check_input=True):\n\nValueError: Number of features of the model must match the input. Model n_features is 286760 and input n_features is 62200 \n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-124-4d700f445c49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mens_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_tfidf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Ensemble mean absolute error: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_binary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mens_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/ensemble/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    742\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/ensemble/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    265\u001b[0m             \u001b[0mpredictions\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfinal\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \"\"\"\n\u001b[0;32m--> 267\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'predict'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/ensemble/base.py\u001b[0m in \u001b[0;36m_predict\u001b[0;34m(self, X, job, *args, **kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;31m# Predict with ensemble\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m             \u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_preds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/parallel/manager.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlyr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_partial_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlyr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparallel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__fitted__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/parallel/manager.py\u001b[0m in \u001b[0;36m_partial_process\u001b[0;34m(self, n, lyr, parallel)\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'P'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m         \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/parallel/estimation.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, P, parallel)\u001b[0m\n\u001b[1;32m    227\u001b[0m                                       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m                                       attr=pred_method)\n\u001b[0;32m--> 229\u001b[0;31m                  for case, (inst_name, est, (_, col)) in ests)\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    766\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x7f75a5c8c0c0, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/anthonyle/anaconda3/envs/deep_learning/lib...ges/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/anthon.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7f75a5c8c0c0, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/anthonyle/anaconda3/envs/deep_learning/lib...ges/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/anthon.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n     17 \n     18 \n     19 \n     20 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'ens_pred = ens.predict(X_test_tfidf)\\nprint(\"Ense...at(mean_absolute_error(y_test_binary, ens_pred)))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 6, 25, 15, 45, 31, 527030, tzinfo=datetime.timezone.utc), 'msg_id': '7CEDC65BE2AF4064BADF387A91B23A59', 'msg_type': 'execute_request', 'session': '55AD9960AF514B44A33856CD0CDB88E6', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '7CEDC65BE2AF4064BADF387A91B23A59', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'55AD9960AF514B44A33856CD0CDB88E6']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'ens_pred = ens.predict(X_test_tfidf)\\nprint(\"Ense...at(mean_absolute_error(y_test_binary, ens_pred)))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 6, 25, 15, 45, 31, 527030, tzinfo=datetime.timezone.utc), 'msg_id': '7CEDC65BE2AF4064BADF387A91B23A59', 'msg_type': 'execute_request', 'session': '55AD9960AF514B44A33856CD0CDB88E6', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '7CEDC65BE2AF4064BADF387A91B23A59', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'55AD9960AF514B44A33856CD0CDB88E6'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'ens_pred = ens.predict(X_test_tfidf)\\nprint(\"Ense...at(mean_absolute_error(y_test_binary, ens_pred)))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 6, 25, 15, 45, 31, 527030, tzinfo=datetime.timezone.utc), 'msg_id': '7CEDC65BE2AF4064BADF387A91B23A59', 'msg_type': 'execute_request', 'session': '55AD9960AF514B44A33856CD0CDB88E6', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '7CEDC65BE2AF4064BADF387A91B23A59', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='ens_pred = ens.predict(X_test_tfidf)\\nprint(\"Ense...at(mean_absolute_error(y_test_binary, ens_pred)))', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'ens_pred = ens.predict(X_test_tfidf)\\nprint(\"Ense...at(mean_absolute_error(y_test_binary, ens_pred)))'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('ens_pred = ens.predict(X_test_tfidf)\\nprint(\"Ense...at(mean_absolute_error(y_test_binary, ens_pred)))',), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('ens_pred = ens.predict(X_test_tfidf)\\nprint(\"Ense...at(mean_absolute_error(y_test_binary, ens_pred)))',)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='ens_pred = ens.predict(X_test_tfidf)\\nprint(\"Ense...at(mean_absolute_error(y_test_binary, ens_pred)))', store_history=True, silent=False, shell_futures=True)\n   2693                 self.displayhook.exec_result = result\n   2694 \n   2695                 # Execute the user code\n   2696                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2697                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2698                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2699                 \n   2700                 self.last_execution_succeeded = not has_raised\n   2701 \n   2702                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-124-4d700f445c49>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7f755f937c88, executi..._before_exec=None error_in_exec=None result=None>)\n   2797 \n   2798         try:\n   2799             for i, node in enumerate(to_run_exec):\n   2800                 mod = ast.Module([node])\n   2801                 code = compiler(mod, cell_name, \"exec\")\n-> 2802                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f7567666d20, file \"<ipython-input-124-4d700f445c49>\", line 1>\n        result = <ExecutionResult object at 7f755f937c88, executi..._before_exec=None error_in_exec=None result=None>\n   2803                     return True\n   2804 \n   2805             for i, node in enumerate(to_run_interactive):\n   2806                 mod = ast.Interactive([node])\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f7567666d20, file \"<ipython-input-124-4d700f445c49>\", line 1>, result=<ExecutionResult object at 7f755f937c88, executi..._before_exec=None error_in_exec=None result=None>)\n   2857         outflag = True  # happens in more places, so it's easier as default\n   2858         try:\n   2859             try:\n   2860                 self.hooks.pre_run_code_hook()\n   2861                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2862                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f7567666d20, file \"<ipython-input-124-4d700f445c49>\", line 1>\n        self.user_global_ns = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'EnsembleTransformer': <class 'mlens.preprocessing.ensemble_transformer.EnsembleTransformer'>, 'Evaluator': <class 'mlens.model_selection.model_selection.Evaluator'>, 'In': ['', \"import pandas as pd\\nfake_real_df = pd.read_csv('./fake_or_real_news.csv')\", \"fake_real_df_clean = fake_real_df[['title','text','label']]\", 'from sklearn.model_selection import StratifiedSh...rat_test_set = fake_real_df_clean.loc[test_index]', 'strat_fake_or_real_train = strat_train_set.copy()\\nstrat_fake_or_real_test  = strat_test_set.copy()', \"X_train = strat_fake_or_real_train.copy().drop('...y_test  = strat_fake_or_real_test.copy()['label']\", \"import nltk\\nfrom nltk.corpus import stopwords\\nfr...t = ' '.join(tokens)\\n    return preprocessed_text\", \"X_train_text_list  = list(X_train['text'])\\nX_tra...ext'])\\nX_test_title_list  = list(X_test['title'])\", 'X_train_text_clean = [preprocessing(text) for te...reprocessing(text) for text in X_test_title_list]', 'nltk.download()', \"import pandas as pd\\nfake_real_df = pd.read_csv('./fake_or_real_news.csv')\", \"fake_real_df_clean = fake_real_df[['title','text','label']]\", 'from sklearn.model_selection import StratifiedSh...rat_test_set = fake_real_df_clean.loc[test_index]', 'strat_fake_or_real_train = strat_train_set.copy()\\nstrat_fake_or_real_test  = strat_test_set.copy()', \"X_train = strat_fake_or_real_train.copy().drop('...y_test  = strat_fake_or_real_test.copy()['label']\", \"import nltk\\nfrom nltk.corpus import stopwords\\nfr...t = ' '.join(tokens)\\n    return preprocessed_text\", \"X_train_text_list  = list(X_train['text'])\\nX_tra...ext'])\\nX_test_title_list  = list(X_test['title'])\", 'X_train_text_clean = [preprocessing(text) for te...reprocessing(text) for text in X_test_title_list]', \"y_train_binary = [x=='REAL' for x in list(y_trai...y_test_binary = [x=='REAL' for x in list(y_test)]\", \"'''\\nThe code above is all cleaning.\\nI separated ...fit_transform(X_train_text_clean, y_train_binary)\", ...], 'LancasterStemmer': <class 'nltk.stem.lancaster.LancasterStemmer'>, 'LarsCV': <class 'sklearn.linear_model.least_angle.LarsCV'>, 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'MyTfidfVectorizer': <class '__main__.MyTfidfVectorizer'>, 'Out': {9: True, 21: array([ 0.82955665,  0.82741617,  0.82329714,  0.81342547,  0.83119447]), 22: '\\nIt is now up to you to use the data as you wish...ll going to work on improving the current model.\\n', 29: <5068x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, 30: <1x286760 sparse matrix of type '<class 'numpy.f... stored elements in Compressed Sparse Row format>, 31: (5068, 286760), 32: 5068, 36: <class 'int'>, 37: 4, 38: <class 'int'>, ...}, 'P':         rfc    mnb    abc  Truth\n0      True   T...lse  False  False  False\n\n[5068 rows x 4 columns], ...}\n        self.user_ns = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'EnsembleTransformer': <class 'mlens.preprocessing.ensemble_transformer.EnsembleTransformer'>, 'Evaluator': <class 'mlens.model_selection.model_selection.Evaluator'>, 'In': ['', \"import pandas as pd\\nfake_real_df = pd.read_csv('./fake_or_real_news.csv')\", \"fake_real_df_clean = fake_real_df[['title','text','label']]\", 'from sklearn.model_selection import StratifiedSh...rat_test_set = fake_real_df_clean.loc[test_index]', 'strat_fake_or_real_train = strat_train_set.copy()\\nstrat_fake_or_real_test  = strat_test_set.copy()', \"X_train = strat_fake_or_real_train.copy().drop('...y_test  = strat_fake_or_real_test.copy()['label']\", \"import nltk\\nfrom nltk.corpus import stopwords\\nfr...t = ' '.join(tokens)\\n    return preprocessed_text\", \"X_train_text_list  = list(X_train['text'])\\nX_tra...ext'])\\nX_test_title_list  = list(X_test['title'])\", 'X_train_text_clean = [preprocessing(text) for te...reprocessing(text) for text in X_test_title_list]', 'nltk.download()', \"import pandas as pd\\nfake_real_df = pd.read_csv('./fake_or_real_news.csv')\", \"fake_real_df_clean = fake_real_df[['title','text','label']]\", 'from sklearn.model_selection import StratifiedSh...rat_test_set = fake_real_df_clean.loc[test_index]', 'strat_fake_or_real_train = strat_train_set.copy()\\nstrat_fake_or_real_test  = strat_test_set.copy()', \"X_train = strat_fake_or_real_train.copy().drop('...y_test  = strat_fake_or_real_test.copy()['label']\", \"import nltk\\nfrom nltk.corpus import stopwords\\nfr...t = ' '.join(tokens)\\n    return preprocessed_text\", \"X_train_text_list  = list(X_train['text'])\\nX_tra...ext'])\\nX_test_title_list  = list(X_test['title'])\", 'X_train_text_clean = [preprocessing(text) for te...reprocessing(text) for text in X_test_title_list]', \"y_train_binary = [x=='REAL' for x in list(y_trai...y_test_binary = [x=='REAL' for x in list(y_test)]\", \"'''\\nThe code above is all cleaning.\\nI separated ...fit_transform(X_train_text_clean, y_train_binary)\", ...], 'LancasterStemmer': <class 'nltk.stem.lancaster.LancasterStemmer'>, 'LarsCV': <class 'sklearn.linear_model.least_angle.LarsCV'>, 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'MyTfidfVectorizer': <class '__main__.MyTfidfVectorizer'>, 'Out': {9: True, 21: array([ 0.82955665,  0.82741617,  0.82329714,  0.81342547,  0.83119447]), 22: '\\nIt is now up to you to use the data as you wish...ll going to work on improving the current model.\\n', 29: <5068x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, 30: <1x286760 sparse matrix of type '<class 'numpy.f... stored elements in Compressed Sparse Row format>, 31: (5068, 286760), 32: 5068, 36: <class 'int'>, 37: 4, 38: <class 'int'>, ...}, 'P':         rfc    mnb    abc  Truth\n0      True   T...lse  False  False  False\n\n[5068 rows x 4 columns], ...}\n   2863             finally:\n   2864                 # Reset our crash handler in place\n   2865                 sys.excepthook = old_excepthook\n   2866         except SystemExit as e:\n\n...........................................................................\n/mnt/Linux-Extra/home-extra/Anthony.Le/Projects/fake_news/<ipython-input-124-4d700f445c49> in <module>()\n----> 1 \n      2 \n      3 \n      4 \n      5 \n      6 ens_pred = ens.predict(X_test_tfidf)\n      7 print(\"Ensemble mean absolute error: {0}\".format(mean_absolute_error(y_test_binary, ens_pred)))\n      8 \n      9 \n     10 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/ensemble/base.py in predict(self=SuperLearner(array_check=2, backend='threading',...ne, scorer=None,\n       shuffle=False, verbose=5), X=<1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>)\n    739         if self.shuffle:\n    740             r = check_random_state(self.random_state)\n    741             idx = r.permutation(X.shape[0])\n    742             X = X[idx]\n    743 \n--> 744         y = self.layers.predict(X)\n        y = undefined\n        self.layers.predict = <bound method LayerContainer.predict of LayerCon...  n_jobs=-1, raise_on_exception=True, verbose=5)>\n        X = <1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>\n    745 \n    746         if y.shape[1] == 1:\n    747             # The meta estimator is treated as a layer and thus a prediction\n    748             # matrix with shape [n_samples, 1] is created. Ravel before return\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/ensemble/base.py in predict(self=LayerContainer(backend='threading',\n        laye...   n_jobs=-1, raise_on_exception=True, verbose=5), X=<1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>, *args=(), **kwargs={})\n    262         Returns\n    263         -------\n    264         X_pred : array-like of shape = [n_samples, n_fitted_estimators]\n    265             predictions from final layer.\n    266         \"\"\"\n--> 267         return self._predict(X, 'predict', *args, **kwargs)\n        self._predict = <bound method LayerContainer._predict of LayerCo...  n_jobs=-1, raise_on_exception=True, verbose=5)>\n        X = <1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>\n        args = ()\n        kwargs = {}\n    268 \n    269     def transform(self, X=None, *args, **kwargs):\n    270         \"\"\"Generic method for reproducing predictions of the ``fit`` call.\n    271 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/ensemble/base.py in _predict(self=LayerContainer(backend='threading',\n        laye...   n_jobs=-1, raise_on_exception=True, verbose=5), X=<1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>, job='predict', *args=(), **kwargs={})\n    315         processor = ParallelProcessing(self)\n    316         processor.initialize(job, X, *args, **kwargs)\n    317 \n    318         # Predict with ensemble\n    319         try:\n--> 320             processor.process()\n        processor.process = <bound method ParallelProcessing.process of <mlens.parallel.manager.ParallelProcessing object>>\n    321 \n    322             preds = processor.get_preds()\n    323 \n    324             if self.verbose:\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/parallel/manager.py in process(self=<mlens.parallel.manager.ParallelProcessing object>)\n    213                       mmap_mode='w+',\n    214                       verbose=self.layers.verbose,\n    215                       backend=self.layers.backend) as parallel:\n    216 \n    217             for n, lyr in enumerate(self.layers.layers.values()):\n--> 218                 self._partial_process(n, lyr, parallel)\n        self._partial_process = <bound method ParallelProcessing._partial_proces...lens.parallel.manager.ParallelProcessing object>>\n        n = 0\n        lyr = Layer(cls='stack', cls_kwargs=None,\n   estimator... raise_on_exception=True, scorer=None, verbose=5)\n        parallel = Parallel(n_jobs=-1)\n    219 \n    220         self.__fitted__ = 1\n    221 \n    222     def get_preds(self, n=-1, dtype=np.float, order='C'):\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/parallel/manager.py in _partial_process(self=<mlens.parallel.manager.ParallelProcessing object>, n=0, lyr=Layer(cls='stack', cls_kwargs=None,\n   estimator... raise_on_exception=True, scorer=None, verbose=5), parallel=Parallel(n_jobs=-1))\n    303         if 'X' in fargs:\n    304             kwargs['X'] = self.job.P[n]\n    305         if 'P' in fargs:\n    306             kwargs['P'] = self.job.P[n + 1]\n    307 \n--> 308         f(**kwargs)\n        f = <bound method BaseEstimator.predict of <mlens.parallel.stack.Stacker object>>\n        kwargs = {'P': memmap([[ 0.,  0.,  0.],\n       [ 0.,  0.,  0.],...\n       [ 0.,  0.,  0.],\n       [ 0.,  0.,  0.]]), 'X': <1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>, 'parallel': Parallel(n_jobs=-1)}\n    309 \n    310 \n    311 ###############################################################################\n    312 class ParallelEvaluation(object):\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/parallel/estimation.py in predict(self=<mlens.parallel.stack.Stacker object>, X=<1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>, P=memmap([[ 0.,  0.,  0.],\n       [ 0.,  0.,  0.],...\n       [ 0.,  0.,  0.],\n       [ 0.,  0.,  0.]]), parallel=Parallel(n_jobs=-1))\n    224                                       xtest=X,\n    225                                       pred=P,\n    226                                       col=col,\n    227                                       name=self.name,\n    228                                       attr=pred_method)\n--> 229                  for case, (inst_name, est, (_, col)) in ests)\n        ests = [(None, ('rfc', RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), (None, 0))), (None, ('mnb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), (None, 1))), (None, ('abc', AdaBoostClassifier(algorithm='SAMME.R', base_est...ing_rate=1.0, n_estimators=50, random_state=None), (None, 2)))]\n    230 \n    231         if self.verbose:\n    232             print_time(t0, '%s Done' % self.name, file=printout)\n    233 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseEstimator.predict.<locals>.<genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Sun Jun 25 08:45:31 2017\nPID: 16426Python 3.6.1: /home/anthonyle/anaconda3/envs/deep_learning/bin/python\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/externals/joblib/parallel.py in __call__(self=<mlens.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function predict_est>, (), {'attr': 'predict', 'case': None, 'col': 0, 'est': RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), 'inst_name': 'rfc', 'name': 'layer-1', 'pred': memmap([[ 0.,  0.,  0.],\n       [ 0.,  0.,  0.],...\n       [ 0.,  0.,  0.],\n       [ 0.,  0.,  0.]]), 'tr_list': [], 'xtest': <1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function predict_est>\n        args = ()\n        kwargs = {'attr': 'predict', 'case': None, 'col': 0, 'est': RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), 'inst_name': 'rfc', 'name': 'layer-1', 'pred': memmap([[ 0.,  0.,  0.],\n       [ 0.,  0.,  0.],...\n       [ 0.,  0.,  0.],\n       [ 0.,  0.,  0.]]), 'tr_list': [], 'xtest': <1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/parallel/estimation.py in predict_est(case=None, tr_list=[], inst_name='rfc', est=RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), xtest=<1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>, pred=memmap([[ 0.,  0.,  0.],\n       [ 0.,  0.,  0.],...\n       [ 0.,  0.,  0.],\n       [ 0.,  0.,  0.]]), col=0, name='layer-1', attr='predict')\n    402 \n    403     # Predict into memmap\n    404     # Here, we coerce errors on failed predictions - all predictors that\n    405     # survive into the estimators_ attribute of a layer should be able to\n    406     # predict, otherwise the subsequent layer will get corrupt input.\n--> 407     p = getattr(est, attr)(xtest)\n        p = undefined\n        est = RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False)\n        attr = 'predict'\n        xtest = <1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>\n    408 \n    409     if len(p.shape) == 1:\n    410         pred[:, col] = p\n    411     else:\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/ensemble/forest.py in predict(self=RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), X=<1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>)\n    529         Returns\n    530         -------\n    531         y : array of shape = [n_samples] or [n_samples, n_outputs]\n    532             The predicted classes.\n    533         \"\"\"\n--> 534         proba = self.predict_proba(X)\n        proba = undefined\n        self.predict_proba = <bound method ForestClassifier.predict_proba of ...e=None,\n            verbose=0, warm_start=False)>\n        X = <1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>\n    535 \n    536         if self.n_outputs_ == 1:\n    537             return self.classes_.take(np.argmax(proba, axis=1), axis=0)\n    538 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/ensemble/forest.py in predict_proba(self=RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), X=<1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>)\n    568             such arrays if n_outputs > 1.\n    569             The class probabilities of the input samples. The order of the\n    570             classes corresponds to that in the attribute `classes_`.\n    571         \"\"\"\n    572         # Check data\n--> 573         X = self._validate_X_predict(X)\n        X = <1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>\n        self._validate_X_predict = <bound method BaseForest._validate_X_predict of ...e=None,\n            verbose=0, warm_start=False)>\n    574 \n    575         # Assign chunk of trees to jobs\n    576         n_jobs, _, _ = _partition_estimators(self.n_estimators, self.n_jobs)\n    577 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/ensemble/forest.py in _validate_X_predict(self=RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), X=<1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>)\n    350         \"\"\"Validate X whenever one tries to predict, apply, predict_proba\"\"\"\n    351         if self.estimators_ is None or len(self.estimators_) == 0:\n    352             raise NotFittedError(\"Estimator not fitted, \"\n    353                                  \"call `fit` before exploiting the model.\")\n    354 \n--> 355         return self.estimators_[0]._validate_X_predict(X, check_input=True)\n        self.estimators_._validate_X_predict = undefined\n        X = <1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>\n    356 \n    357     @property\n    358     def feature_importances_(self):\n    359         \"\"\"Return the feature importances (the higher, the more important the\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/tree/tree.py in _validate_X_predict(self=DecisionTreeClassifier(class_weight=None, criter...rt=False, random_state=30958129, splitter='best'), X=<1267x62200 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>, check_input=True)\n    371         n_features = X.shape[1]\n    372         if self.n_features_ != n_features:\n    373             raise ValueError(\"Number of features of the model must \"\n    374                              \"match the input. Model n_features is %s and \"\n    375                              \"input n_features is %s \"\n--> 376                              % (self.n_features_, n_features))\n        self.n_features_ = 286760\n        n_features = 62200\n    377 \n    378         return X\n    379 \n    380     def predict(self, X, check_input=True):\n\nValueError: Number of features of the model must match the input. Model n_features is 286760 and input n_features is 62200 \n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "ens_pred = ens.predict(X_test_tfidf)\n",
    "print(\"Ensemble mean absolute error: {0}\".format(mean_absolute_error(y_test_binary, ens_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing layers (2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting layer-1\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    0.2s remaining:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   9 | elapsed:    0.9s remaining:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    1.7s remaining:    0.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit complete | 00:00:19\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   19.1s finished\n",
      "layer-1 Done | 00:00:19\n",
      "\n",
      "Fitting layer-2\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "layer-2 Done | 00:00:00\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing layers (2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting layer-1\n"
     ]
    },
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x7f75a5c8c0c0, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/anthonyle/anaconda3/envs/deep_learning/lib...ges/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/anthon.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7f75a5c8c0c0, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/anthonyle/anaconda3/envs/deep_learning/lib...ges/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/anthon.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n     17 \n     18 \n     19 \n     20 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'from sklearn.model_selection import cross_val_sc..._tfidf, y_train_binary, cv=5, scoring=\"accuracy\")', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 6, 25, 9, 30, 44, 209328, tzinfo=datetime.timezone.utc), 'msg_id': '94F9EAB6938145C09C5F4C0A42C6ABC9', 'msg_type': 'execute_request', 'session': '55AD9960AF514B44A33856CD0CDB88E6', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '94F9EAB6938145C09C5F4C0A42C6ABC9', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'55AD9960AF514B44A33856CD0CDB88E6']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'from sklearn.model_selection import cross_val_sc..._tfidf, y_train_binary, cv=5, scoring=\"accuracy\")', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 6, 25, 9, 30, 44, 209328, tzinfo=datetime.timezone.utc), 'msg_id': '94F9EAB6938145C09C5F4C0A42C6ABC9', 'msg_type': 'execute_request', 'session': '55AD9960AF514B44A33856CD0CDB88E6', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '94F9EAB6938145C09C5F4C0A42C6ABC9', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'55AD9960AF514B44A33856CD0CDB88E6'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'from sklearn.model_selection import cross_val_sc..._tfidf, y_train_binary, cv=5, scoring=\"accuracy\")', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 6, 25, 9, 30, 44, 209328, tzinfo=datetime.timezone.utc), 'msg_id': '94F9EAB6938145C09C5F4C0A42C6ABC9', 'msg_type': 'execute_request', 'session': '55AD9960AF514B44A33856CD0CDB88E6', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '94F9EAB6938145C09C5F4C0A42C6ABC9', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='from sklearn.model_selection import cross_val_sc..._tfidf, y_train_binary, cv=5, scoring=\"accuracy\")', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'from sklearn.model_selection import cross_val_sc..._tfidf, y_train_binary, cv=5, scoring=\"accuracy\")'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('from sklearn.model_selection import cross_val_sc..._tfidf, y_train_binary, cv=5, scoring=\"accuracy\")',), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('from sklearn.model_selection import cross_val_sc..._tfidf, y_train_binary, cv=5, scoring=\"accuracy\")',)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='from sklearn.model_selection import cross_val_sc..._tfidf, y_train_binary, cv=5, scoring=\"accuracy\")', store_history=True, silent=False, shell_futures=True)\n   2693                 self.displayhook.exec_result = result\n   2694 \n   2695                 # Execute the user code\n   2696                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2697                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2698                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2699                 \n   2700                 self.last_execution_succeeded = not has_raised\n   2701 \n   2702                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.ImportFrom object>, <_ast.Expr object>], cell_name='<ipython-input-106-3a7f44104b84>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7f755940dcc0, executi..._before_exec=None error_in_exec=None result=None>)\n   2803                     return True\n   2804 \n   2805             for i, node in enumerate(to_run_interactive):\n   2806                 mod = ast.Interactive([node])\n   2807                 code = compiler(mod, cell_name, \"single\")\n-> 2808                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f7566b519c0, file \"<ipython-input-106-3a7f44104b84>\", line 2>\n        result = <ExecutionResult object at 7f755940dcc0, executi..._before_exec=None error_in_exec=None result=None>\n   2809                     return True\n   2810 \n   2811             # Flush softspace\n   2812             if softspace(sys.stdout, 0):\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f7566b519c0, file \"<ipython-input-106-3a7f44104b84>\", line 2>, result=<ExecutionResult object at 7f755940dcc0, executi..._before_exec=None error_in_exec=None result=None>)\n   2857         outflag = True  # happens in more places, so it's easier as default\n   2858         try:\n   2859             try:\n   2860                 self.hooks.pre_run_code_hook()\n   2861                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2862                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f7566b519c0, file \"<ipython-input-106-3a7f44104b84>\", line 2>\n        self.user_global_ns = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'EnsembleTransformer': <class 'mlens.preprocessing.ensemble_transformer.EnsembleTransformer'>, 'Evaluator': <class 'mlens.model_selection.model_selection.Evaluator'>, 'In': ['', \"import pandas as pd\\nfake_real_df = pd.read_csv('./fake_or_real_news.csv')\", \"fake_real_df_clean = fake_real_df[['title','text','label']]\", 'from sklearn.model_selection import StratifiedSh...rat_test_set = fake_real_df_clean.loc[test_index]', 'strat_fake_or_real_train = strat_train_set.copy()\\nstrat_fake_or_real_test  = strat_test_set.copy()', \"X_train = strat_fake_or_real_train.copy().drop('...y_test  = strat_fake_or_real_test.copy()['label']\", \"import nltk\\nfrom nltk.corpus import stopwords\\nfr...t = ' '.join(tokens)\\n    return preprocessed_text\", \"X_train_text_list  = list(X_train['text'])\\nX_tra...ext'])\\nX_test_title_list  = list(X_test['title'])\", 'X_train_text_clean = [preprocessing(text) for te...reprocessing(text) for text in X_test_title_list]', 'nltk.download()', \"import pandas as pd\\nfake_real_df = pd.read_csv('./fake_or_real_news.csv')\", \"fake_real_df_clean = fake_real_df[['title','text','label']]\", 'from sklearn.model_selection import StratifiedSh...rat_test_set = fake_real_df_clean.loc[test_index]', 'strat_fake_or_real_train = strat_train_set.copy()\\nstrat_fake_or_real_test  = strat_test_set.copy()', \"X_train = strat_fake_or_real_train.copy().drop('...y_test  = strat_fake_or_real_test.copy()['label']\", \"import nltk\\nfrom nltk.corpus import stopwords\\nfr...t = ' '.join(tokens)\\n    return preprocessed_text\", \"X_train_text_list  = list(X_train['text'])\\nX_tra...ext'])\\nX_test_title_list  = list(X_test['title'])\", 'X_train_text_clean = [preprocessing(text) for te...reprocessing(text) for text in X_test_title_list]', \"y_train_binary = [x=='REAL' for x in list(y_trai...y_test_binary = [x=='REAL' for x in list(y_test)]\", \"'''\\nThe code above is all cleaning.\\nI separated ...fit_transform(X_train_text_clean, y_train_binary)\", ...], 'LancasterStemmer': <class 'nltk.stem.lancaster.LancasterStemmer'>, 'LarsCV': <class 'sklearn.linear_model.least_angle.LarsCV'>, 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'Out': {9: True, 21: array([ 0.82955665,  0.82741617,  0.82329714,  0.81342547,  0.83119447]), 22: '\\nIt is now up to you to use the data as you wish...ll going to work on improving the current model.\\n', 29: <5068x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, 30: <1x286760 sparse matrix of type '<class 'numpy.f... stored elements in Compressed Sparse Row format>, 31: (5068, 286760), 32: 5068, 36: <class 'int'>, 37: 4, 38: <class 'int'>, ...}, 'P':         rfc    mnb    abc  Truth\n0      True   T...lse  False  False  False\n\n[5068 rows x 4 columns], 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, ...}\n        self.user_ns = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'EnsembleTransformer': <class 'mlens.preprocessing.ensemble_transformer.EnsembleTransformer'>, 'Evaluator': <class 'mlens.model_selection.model_selection.Evaluator'>, 'In': ['', \"import pandas as pd\\nfake_real_df = pd.read_csv('./fake_or_real_news.csv')\", \"fake_real_df_clean = fake_real_df[['title','text','label']]\", 'from sklearn.model_selection import StratifiedSh...rat_test_set = fake_real_df_clean.loc[test_index]', 'strat_fake_or_real_train = strat_train_set.copy()\\nstrat_fake_or_real_test  = strat_test_set.copy()', \"X_train = strat_fake_or_real_train.copy().drop('...y_test  = strat_fake_or_real_test.copy()['label']\", \"import nltk\\nfrom nltk.corpus import stopwords\\nfr...t = ' '.join(tokens)\\n    return preprocessed_text\", \"X_train_text_list  = list(X_train['text'])\\nX_tra...ext'])\\nX_test_title_list  = list(X_test['title'])\", 'X_train_text_clean = [preprocessing(text) for te...reprocessing(text) for text in X_test_title_list]', 'nltk.download()', \"import pandas as pd\\nfake_real_df = pd.read_csv('./fake_or_real_news.csv')\", \"fake_real_df_clean = fake_real_df[['title','text','label']]\", 'from sklearn.model_selection import StratifiedSh...rat_test_set = fake_real_df_clean.loc[test_index]', 'strat_fake_or_real_train = strat_train_set.copy()\\nstrat_fake_or_real_test  = strat_test_set.copy()', \"X_train = strat_fake_or_real_train.copy().drop('...y_test  = strat_fake_or_real_test.copy()['label']\", \"import nltk\\nfrom nltk.corpus import stopwords\\nfr...t = ' '.join(tokens)\\n    return preprocessed_text\", \"X_train_text_list  = list(X_train['text'])\\nX_tra...ext'])\\nX_test_title_list  = list(X_test['title'])\", 'X_train_text_clean = [preprocessing(text) for te...reprocessing(text) for text in X_test_title_list]', \"y_train_binary = [x=='REAL' for x in list(y_trai...y_test_binary = [x=='REAL' for x in list(y_test)]\", \"'''\\nThe code above is all cleaning.\\nI separated ...fit_transform(X_train_text_clean, y_train_binary)\", ...], 'LancasterStemmer': <class 'nltk.stem.lancaster.LancasterStemmer'>, 'LarsCV': <class 'sklearn.linear_model.least_angle.LarsCV'>, 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'Out': {9: True, 21: array([ 0.82955665,  0.82741617,  0.82329714,  0.81342547,  0.83119447]), 22: '\\nIt is now up to you to use the data as you wish...ll going to work on improving the current model.\\n', 29: <5068x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, 30: <1x286760 sparse matrix of type '<class 'numpy.f... stored elements in Compressed Sparse Row format>, 31: (5068, 286760), 32: 5068, 36: <class 'int'>, 37: 4, 38: <class 'int'>, ...}, 'P':         rfc    mnb    abc  Truth\n0      True   T...lse  False  False  False\n\n[5068 rows x 4 columns], 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, ...}\n   2863             finally:\n   2864                 # Reset our crash handler in place\n   2865                 sys.excepthook = old_excepthook\n   2866         except SystemExit as e:\n\n...........................................................................\n/mnt/Linux-Extra/home-extra/Anthony.Le/Projects/fake_news/<ipython-input-106-3a7f44104b84> in <module>()\n      1 \n----> 2 \n      3 \n      4 \n      5 from sklearn.model_selection import cross_val_score\n      6 cross_val_score(ens, X_train_tfidf, y_train_binary, cv=5, scoring=\"accuracy\")\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in cross_val_score(estimator=SuperLearner(array_check=2, backend='threading',...ne, scorer=None,\n       shuffle=False, verbose=5), X=<5068x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, y=[True, False, False, False, False, False, False, False, True, True, True, False, True, False, True, False, True, True, False, False, ...], groups=None, scoring='accuracy', cv=KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs')\n    135     parallel = Parallel(n_jobs=n_jobs, verbose=verbose,\n    136                         pre_dispatch=pre_dispatch)\n    137     scores = parallel(delayed(_fit_and_score)(clone(estimator), X, y, scorer,\n    138                                               train, test, verbose, None,\n    139                                               fit_params)\n--> 140                       for train, test in cv_iter)\n        cv_iter = [(array([1014, 1015, 1016, ..., 5065, 5066, 5067]), array([   0,    1,    2, ..., 1011, 1012, 1013])), (array([   0,    1,    2, ..., 5065, 5066, 5067]), array([1014, 1015, 1016, ..., 2025, 2026, 2027])), (array([   0,    1,    2, ..., 5065, 5066, 5067]), array([2028, 2029, 2030, ..., 3039, 3040, 3041])), (array([   0,    1,    2, ..., 5065, 5066, 5067]), array([3042, 3043, 3044, ..., 4052, 4053, 4054])), (array([   0,    1,    2, ..., 4052, 4053, 4054]), array([4055, 4056, 4057, ..., 5065, 5066, 5067]))]\n    141     return np.array(scores)[:, 0]\n    142 \n    143 \n    144 def _fit_and_score(estimator, X, y, scorer, train, test, verbose,\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object cross_val_score.<locals>.<genexpr>>)\n    753         self.n_completed_tasks = 0\n    754         try:\n    755             # Only set self._iterating to True if at least a batch\n    756             # was dispatched. In particular this covers the edge\n    757             # case of Parallel used with an exhausted iterator.\n--> 758             while self.dispatch_one_batch(iterator):\n        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>\n        iterator = <generator object cross_val_score.<locals>.<genexpr>>\n    759                 self._iterating = True\n    760             else:\n    761                 self._iterating = False\n    762 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object cross_val_score.<locals>.<genexpr>>)\n    603             tasks = BatchedCalls(itertools.islice(iterator, batch_size))\n    604             if len(tasks) == 0:\n    605                 # No more tasks available in the iterator: tell caller to stop.\n    606                 return False\n    607             else:\n--> 608                 self._dispatch(tasks)\n        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>\n        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    609                 return True\n    610 \n    611     def _print(self, msg, msg_args):\n    612         \"\"\"Display the message on stout or stderr depending on verbosity\"\"\"\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    566         self.n_dispatched_tasks += len(batch)\n    567         self.n_dispatched_batches += 1\n    568 \n    569         dispatch_timestamp = time.time()\n    570         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)\n--> 571         job = self._backend.apply_async(batch, callback=cb)\n        job = undefined\n        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>\n    572         self._jobs.append(job)\n    573 \n    574     def dispatch_next(self):\n    575         \"\"\"Dispatch more data for parallel processing\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)\n    104             raise ValueError('n_jobs == 0 in Parallel has no meaning')\n    105         return 1\n    106 \n    107     def apply_async(self, func, callback=None):\n    108         \"\"\"Schedule a func to be run\"\"\"\n--> 109         result = ImmediateResult(func)\n        result = undefined\n        func = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    110         if callback:\n    111             callback(result)\n    112         return result\n    113 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    321 \n    322 class ImmediateResult(object):\n    323     def __init__(self, batch):\n    324         # Don't delay the application, to avoid keeping the input\n    325         # arguments in memory\n--> 326         self.results = batch()\n        self.results = undefined\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    327 \n    328     def get(self):\n    329         return self.results\n    330 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (SuperLearner(array_check=2, backend='threading',...ne, scorer=None,\n       shuffle=False, verbose=5), <5068x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, [True, False, False, False, False, False, False, False, True, True, True, False, True, False, True, False, True, True, False, False, ...], make_scorer(accuracy_score), array([1014, 1015, 1016, ..., 5065, 5066, 5067]), array([   0,    1,    2, ..., 1011, 1012, 1013]), 0, None, None), {})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (SuperLearner(array_check=2, backend='threading',...ne, scorer=None,\n       shuffle=False, verbose=5), <5068x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, [True, False, False, False, False, False, False, False, True, True, True, False, True, False, True, False, True, True, False, False, ...], make_scorer(accuracy_score), array([1014, 1015, 1016, ..., 5065, 5066, 5067]), array([   0,    1,    2, ..., 1011, 1012, 1013]), 0, None, None)\n        kwargs = {}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=SuperLearner(array_check=2, backend='threading',...ne, scorer=None,\n       shuffle=False, verbose=5), X=<5068x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, y=[True, False, False, False, False, False, False, False, True, True, True, False, True, False, True, False, True, True, False, False, ...], scorer=make_scorer(accuracy_score), train=array([1014, 1015, 1016, ..., 5065, 5066, 5067]), test=array([   0,    1,    2, ..., 1011, 1012, 1013]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=False, error_score='raise')\n    255                              \" numeric value. (Hint: if using 'raise', please\"\n    256                              \" make sure that it has been spelled correctly.)\")\n    257 \n    258     else:\n    259         fit_time = time.time() - start_time\n--> 260         test_score = _score(estimator, X_test, y_test, scorer)\n        test_score = undefined\n        estimator = SuperLearner(array_check=2, backend='threading',...ne, scorer=None,\n       shuffle=False, verbose=5)\n        X_test = <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>\n        y_test = [True, False, False, False, False, False, False, False, True, True, True, False, True, False, True, False, True, True, False, False, ...]\n        scorer = make_scorer(accuracy_score)\n    261         score_time = time.time() - start_time - fit_time\n    262         if return_train_score:\n    263             train_score = _score(estimator, X_train, y_train, scorer)\n    264 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _score(estimator=SuperLearner(array_check=2, backend='threading',...ne, scorer=None,\n       shuffle=False, verbose=5), X_test=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, y_test=[True, False, False, False, False, False, False, False, True, True, True, False, True, False, True, False, True, True, False, False, ...], scorer=make_scorer(accuracy_score))\n    283 def _score(estimator, X_test, y_test, scorer):\n    284     \"\"\"Compute the score of an estimator on a given test set.\"\"\"\n    285     if y_test is None:\n    286         score = scorer(estimator, X_test)\n    287     else:\n--> 288         score = scorer(estimator, X_test, y_test)\n        score = undefined\n        scorer = make_scorer(accuracy_score)\n        estimator = SuperLearner(array_check=2, backend='threading',...ne, scorer=None,\n       shuffle=False, verbose=5)\n        X_test = <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>\n        y_test = [True, False, False, False, False, False, False, False, True, True, True, False, True, False, True, False, True, True, False, False, ...]\n    289     if hasattr(score, 'item'):\n    290         try:\n    291             # e.g. unwrap memmapped scalars\n    292             score = score.item()\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/metrics/scorer.py in __call__(self=make_scorer(accuracy_score), estimator=SuperLearner(array_check=2, backend='threading',...ne, scorer=None,\n       shuffle=False, verbose=5), X=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, y_true=[True, False, False, False, False, False, False, False, True, True, True, False, True, False, True, False, True, True, False, False, ...], sample_weight=None)\n     86         score : float\n     87             Score function applied to prediction of estimator on X.\n     88         \"\"\"\n     89         super(_PredictScorer, self).__call__(estimator, X, y_true,\n     90                                              sample_weight=sample_weight)\n---> 91         y_pred = estimator.predict(X)\n        y_pred = undefined\n        estimator.predict = <bound method BaseEnsemble.predict of SuperLearn...e, scorer=None,\n       shuffle=False, verbose=5)>\n        X = <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>\n     92         if sample_weight is not None:\n     93             return self._sign * self._score_func(y_true, y_pred,\n     94                                                  sample_weight=sample_weight,\n     95                                                  **self._kwargs)\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/ensemble/base.py in predict(self=SuperLearner(array_check=2, backend='threading',...ne, scorer=None,\n       shuffle=False, verbose=5), X=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>)\n    739         if self.shuffle:\n    740             r = check_random_state(self.random_state)\n    741             idx = r.permutation(X.shape[0])\n    742             X = X[idx]\n    743 \n--> 744         y = self.layers.predict(X)\n        y = undefined\n        self.layers.predict = <bound method LayerContainer.predict of LayerCon...  n_jobs=-1, raise_on_exception=True, verbose=5)>\n        X = <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>\n    745 \n    746         if y.shape[1] == 1:\n    747             # The meta estimator is treated as a layer and thus a prediction\n    748             # matrix with shape [n_samples, 1] is created. Ravel before return\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/ensemble/base.py in predict(self=LayerContainer(backend='threading',\n        laye...   n_jobs=-1, raise_on_exception=True, verbose=5), X=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, *args=(), **kwargs={})\n    262         Returns\n    263         -------\n    264         X_pred : array-like of shape = [n_samples, n_fitted_estimators]\n    265             predictions from final layer.\n    266         \"\"\"\n--> 267         return self._predict(X, 'predict', *args, **kwargs)\n        self._predict = <bound method LayerContainer._predict of LayerCo...  n_jobs=-1, raise_on_exception=True, verbose=5)>\n        X = <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>\n        args = ()\n        kwargs = {}\n    268 \n    269     def transform(self, X=None, *args, **kwargs):\n    270         \"\"\"Generic method for reproducing predictions of the ``fit`` call.\n    271 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/ensemble/base.py in _predict(self=LayerContainer(backend='threading',\n        laye...   n_jobs=-1, raise_on_exception=True, verbose=5), X=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, job='predict', *args=(), **kwargs={})\n    315         processor = ParallelProcessing(self)\n    316         processor.initialize(job, X, *args, **kwargs)\n    317 \n    318         # Predict with ensemble\n    319         try:\n--> 320             processor.process()\n        processor.process = <bound method ParallelProcessing.process of <mlens.parallel.manager.ParallelProcessing object>>\n    321 \n    322             preds = processor.get_preds()\n    323 \n    324             if self.verbose:\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/parallel/manager.py in process(self=<mlens.parallel.manager.ParallelProcessing object>)\n    213                       mmap_mode='w+',\n    214                       verbose=self.layers.verbose,\n    215                       backend=self.layers.backend) as parallel:\n    216 \n    217             for n, lyr in enumerate(self.layers.layers.values()):\n--> 218                 self._partial_process(n, lyr, parallel)\n        self._partial_process = <bound method ParallelProcessing._partial_proces...lens.parallel.manager.ParallelProcessing object>>\n        n = 0\n        lyr = Layer(cls='stack', cls_kwargs=None,\n   estimator... raise_on_exception=True, scorer=None, verbose=5)\n        parallel = Parallel(n_jobs=-1)\n    219 \n    220         self.__fitted__ = 1\n    221 \n    222     def get_preds(self, n=-1, dtype=np.float, order='C'):\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/parallel/manager.py in _partial_process(self=<mlens.parallel.manager.ParallelProcessing object>, n=0, lyr=Layer(cls='stack', cls_kwargs=None,\n   estimator... raise_on_exception=True, scorer=None, verbose=5), parallel=Parallel(n_jobs=-1))\n    303         if 'X' in fargs:\n    304             kwargs['X'] = self.job.P[n]\n    305         if 'P' in fargs:\n    306             kwargs['P'] = self.job.P[n + 1]\n    307 \n--> 308         f(**kwargs)\n        f = <bound method BaseEstimator.predict of <mlens.parallel.stack.Stacker object>>\n        kwargs = {'P': memmap([[ 0.,  1.,  0.],\n       [ 0.,  0.,  0.],...\n       [ 0.,  1.,  0.],\n       [ 0.,  1.,  0.]]), 'X': <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, 'parallel': Parallel(n_jobs=-1)}\n    309 \n    310 \n    311 ###############################################################################\n    312 class ParallelEvaluation(object):\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/parallel/estimation.py in predict(self=<mlens.parallel.stack.Stacker object>, X=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, P=memmap([[ 0.,  1.,  0.],\n       [ 0.,  0.,  0.],...\n       [ 0.,  1.,  0.],\n       [ 0.,  1.,  0.]]), parallel=Parallel(n_jobs=-1))\n    224                                       xtest=X,\n    225                                       pred=P,\n    226                                       col=col,\n    227                                       name=self.name,\n    228                                       attr=pred_method)\n--> 229                  for case, (inst_name, est, (_, col)) in ests)\n        ests = [(None, ('rfc', RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), (None, 0))), (None, ('mnb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), (None, 1))), (None, ('abc', AdaBoostClassifier(algorithm='SAMME.R', base_est...ing_rate=1.0, n_estimators=50, random_state=None), (None, 2)))]\n    230 \n    231         if self.verbose:\n    232             print_time(t0, '%s Done' % self.name, file=printout)\n    233 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseEstimator.predict.<locals>.<genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Sun Jun 25 02:31:03 2017\nPID: 16426Python 3.6.1: /home/anthonyle/anaconda3/envs/deep_learning/bin/python\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/externals/joblib/parallel.py in __call__(self=<mlens.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function predict_est>, (), {'attr': 'predict', 'case': None, 'col': 0, 'est': RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), 'inst_name': 'rfc', 'name': 'layer-1', 'pred': memmap([[ 0.,  1.,  0.],\n       [ 0.,  0.,  0.],...\n       [ 0.,  1.,  0.],\n       [ 0.,  1.,  0.]]), 'tr_list': [], 'xtest': <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function predict_est>\n        args = ()\n        kwargs = {'attr': 'predict', 'case': None, 'col': 0, 'est': RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), 'inst_name': 'rfc', 'name': 'layer-1', 'pred': memmap([[ 0.,  1.,  0.],\n       [ 0.,  0.,  0.],...\n       [ 0.,  1.,  0.],\n       [ 0.,  1.,  0.]]), 'tr_list': [], 'xtest': <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/parallel/estimation.py in predict_est(case=None, tr_list=[], inst_name='rfc', est=RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), xtest=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, pred=memmap([[ 0.,  1.,  0.],\n       [ 0.,  0.,  0.],...\n       [ 0.,  1.,  0.],\n       [ 0.,  1.,  0.]]), col=0, name='layer-1', attr='predict')\n    402 \n    403     # Predict into memmap\n    404     # Here, we coerce errors on failed predictions - all predictors that\n    405     # survive into the estimators_ attribute of a layer should be able to\n    406     # predict, otherwise the subsequent layer will get corrupt input.\n--> 407     p = getattr(est, attr)(xtest)\n        p = undefined\n        est = RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False)\n        attr = 'predict'\n        xtest = <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>\n    408 \n    409     if len(p.shape) == 1:\n    410         pred[:, col] = p\n    411     else:\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/ensemble/forest.py in predict(self=RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), X=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>)\n    529         Returns\n    530         -------\n    531         y : array of shape = [n_samples] or [n_samples, n_outputs]\n    532             The predicted classes.\n    533         \"\"\"\n--> 534         proba = self.predict_proba(X)\n        proba = undefined\n        self.predict_proba = <bound method ForestClassifier.predict_proba of ...e=None,\n            verbose=0, warm_start=False)>\n        X = <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>\n    535 \n    536         if self.n_outputs_ == 1:\n    537             return self.classes_.take(np.argmax(proba, axis=1), axis=0)\n    538 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/ensemble/forest.py in predict_proba(self=RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), X=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>)\n    568             such arrays if n_outputs > 1.\n    569             The class probabilities of the input samples. The order of the\n    570             classes corresponds to that in the attribute `classes_`.\n    571         \"\"\"\n    572         # Check data\n--> 573         X = self._validate_X_predict(X)\n        X = <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>\n        self._validate_X_predict = <bound method BaseForest._validate_X_predict of ...e=None,\n            verbose=0, warm_start=False)>\n    574 \n    575         # Assign chunk of trees to jobs\n    576         n_jobs, _, _ = _partition_estimators(self.n_estimators, self.n_jobs)\n    577 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/ensemble/forest.py in _validate_X_predict(self=RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), X=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>)\n    350         \"\"\"Validate X whenever one tries to predict, apply, predict_proba\"\"\"\n    351         if self.estimators_ is None or len(self.estimators_) == 0:\n    352             raise NotFittedError(\"Estimator not fitted, \"\n    353                                  \"call `fit` before exploiting the model.\")\n    354 \n--> 355         return self.estimators_[0]._validate_X_predict(X, check_input=True)\n        self.estimators_._validate_X_predict = undefined\n        X = <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>\n    356 \n    357     @property\n    358     def feature_importances_(self):\n    359         \"\"\"Return the feature importances (the higher, the more important the\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/tree/tree.py in _validate_X_predict(self=DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=537424915, splitter='best'), X=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, check_input=True)\n    360         if self.tree_ is None:\n    361             raise NotFittedError(\"Estimator not fitted, \"\n    362                                  \"call `fit` before exploiting the model.\")\n    363 \n    364         if check_input:\n--> 365             X = check_array(X, dtype=DTYPE, accept_sparse=\"csr\")\n        X = <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>\n    366             if issparse(X) and (X.indices.dtype != np.intc or\n    367                                 X.indptr.dtype != np.intc):\n    368                 raise ValueError(\"No support for np.int64 index based \"\n    369                                  \"sparse matrices\")\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, accept_sparse=['csr'], dtype=<class 'numpy.float32'>, order=None, copy=False, force_all_finite=True, ensure_2d=True, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)\n    375         estimator_name = \"Estimator\"\n    376     context = \" by %s\" % estimator_name if estimator is not None else \"\"\n    377 \n    378     if sp.issparse(array):\n    379         array = _ensure_sparse_format(array, accept_sparse, dtype, copy,\n--> 380                                       force_all_finite)\n        force_all_finite = True\n    381     else:\n    382         array = np.array(array, dtype=dtype, order=order, copy=copy)\n    383 \n    384         if ensure_2d:\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/utils/validation.py in _ensure_sparse_format(spmatrix=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, accept_sparse=['csr'], dtype=<class 'numpy.float32'>, copy=False, force_all_finite=True)\n    253         spmatrix = spmatrix.asformat(accept_sparse[0])\n    254         changed_format = True\n    255 \n    256     if dtype != spmatrix.dtype:\n    257         # convert dtype\n--> 258         spmatrix = spmatrix.astype(dtype)\n        spmatrix = <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>\n        spmatrix.astype = <bound method _data_matrix.astype of <1014x28676...stored elements in Compressed Sparse Row format>>\n        dtype = <class 'numpy.float32'>\n    259     elif copy and not changed_format:\n    260         # force copy\n    261         spmatrix = spmatrix.copy()\n    262 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/scipy/sparse/data.py in astype(self=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, t=<class 'numpy.float32'>)\n     63             return self\n     64         else:\n     65             return NotImplemented\n     66 \n     67     def astype(self, t):\n---> 68         return self._with_data(self._deduped_data().astype(t))\n        self._with_data = <bound method _cs_matrix._with_data of <1014x286...stored elements in Compressed Sparse Row format>>\n        self._deduped_data.astype = undefined\n        t = <class 'numpy.float32'>\n     69 \n     70     astype.__doc__ = spmatrix.astype.__doc__\n     71 \n     72     def conj(self):\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/scipy/sparse/data.py in _deduped_data(self=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>)\n     29         self.data.dtype = newtype\n     30     dtype = property(fget=_get_dtype, fset=_set_dtype)\n     31 \n     32     def _deduped_data(self):\n     33         if hasattr(self, 'sum_duplicates'):\n---> 34             self.sum_duplicates()\n        self.sum_duplicates = <bound method _cs_matrix.sum_duplicates of <1014...stored elements in Compressed Sparse Row format>>\n     35         return self.data\n     36 \n     37     def __abs__(self):\n     38         return self._with_data(abs(self._deduped_data()))\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/scipy/sparse/compressed.py in sum_duplicates(self=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>)\n   1011 \n   1012         The is an *in place* operation\n   1013         \"\"\"\n   1014         if self.has_canonical_format:\n   1015             return\n-> 1016         self.sort_indices()\n        self.sort_indices = <bound method _cs_matrix.sort_indices of <1014x2...stored elements in Compressed Sparse Row format>>\n   1017 \n   1018         M, N = self._swap(self.shape)\n   1019         _sparsetools.csr_sum_duplicates(M, N, self.indptr, self.indices,\n   1020                                         self.data)\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/scipy/sparse/compressed.py in sort_indices(self=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>)\n   1057         \"\"\"Sort the indices of this matrix *in place*\n   1058         \"\"\"\n   1059 \n   1060         if not self.has_sorted_indices:\n   1061             _sparsetools.csr_sort_indices(len(self.indptr) - 1, self.indptr,\n-> 1062                                           self.indices, self.data)\n        self.indices = memmap([285386, 285009, 284390, ...,   1862,   1712,   1709], dtype=int32)\n        self.data = memmap([ 0.04089954,  0.01047909,  0.05310395, ...,  0.03177006,\n        0.02322263,  0.01355832])\n   1063             self.has_sorted_indices = True\n   1064 \n   1065     def prune(self):\n   1066         \"\"\"Remove empty space after all non-zero elements.\n\nValueError: UPDATEIFCOPY base is read-only\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/parallel/estimation.py\u001b[0m in \u001b[0;36mpredict_est\u001b[0;34m(case, tr_list, inst_name, est, xtest, pred, col, name, attr)\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;31m# predict, otherwise the subsequent layer will get corrupt input.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    533\u001b[0m         \"\"\"\n\u001b[0;32m--> 534\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m             if issparse(X) and (X.indices.dtype != np.intc or\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    379\u001b[0m         array = _ensure_sparse_format(array, accept_sparse, dtype, copy,\n\u001b[0;32m--> 380\u001b[0;31m                                       force_all_finite)\n\u001b[0m\u001b[1;32m    381\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_ensure_sparse_format\u001b[0;34m(spmatrix, accept_sparse, dtype, copy, force_all_finite)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;31m# convert dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0mspmatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspmatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchanged_format\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/scipy/sparse/data.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deduped_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/scipy/sparse/data.py\u001b[0m in \u001b[0;36m_deduped_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sum_duplicates'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36msum_duplicates\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1015\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36msort_indices\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m             _sparsetools.csr_sort_indices(len(self.indptr) - 1, self.indptr,\n\u001b[0;32m-> 1062\u001b[0;31m                                           self.indices, self.data)\n\u001b[0m\u001b[1;32m   1063\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_sorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: UPDATEIFCOPY base is read-only",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    681\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m'timeout'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgetfullargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mworker\u001b[0;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat_exc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_tb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTransportableException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nValueError                                         Sun Jun 25 02:31:03 2017\nPID: 16426Python 3.6.1: /home/anthonyle/anaconda3/envs/deep_learning/bin/python\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/externals/joblib/parallel.py in __call__(self=<mlens.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function predict_est>, (), {'attr': 'predict', 'case': None, 'col': 0, 'est': RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), 'inst_name': 'rfc', 'name': 'layer-1', 'pred': memmap([[ 0.,  1.,  0.],\n       [ 0.,  0.,  0.],...\n       [ 0.,  1.,  0.],\n       [ 0.,  1.,  0.]]), 'tr_list': [], 'xtest': <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function predict_est>\n        args = ()\n        kwargs = {'attr': 'predict', 'case': None, 'col': 0, 'est': RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), 'inst_name': 'rfc', 'name': 'layer-1', 'pred': memmap([[ 0.,  1.,  0.],\n       [ 0.,  0.,  0.],...\n       [ 0.,  1.,  0.],\n       [ 0.,  1.,  0.]]), 'tr_list': [], 'xtest': <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/parallel/estimation.py in predict_est(case=None, tr_list=[], inst_name='rfc', est=RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), xtest=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, pred=memmap([[ 0.,  1.,  0.],\n       [ 0.,  0.,  0.],...\n       [ 0.,  1.,  0.],\n       [ 0.,  1.,  0.]]), col=0, name='layer-1', attr='predict')\n    402 \n    403     # Predict into memmap\n    404     # Here, we coerce errors on failed predictions - all predictors that\n    405     # survive into the estimators_ attribute of a layer should be able to\n    406     # predict, otherwise the subsequent layer will get corrupt input.\n--> 407     p = getattr(est, attr)(xtest)\n        p = undefined\n        est = RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False)\n        attr = 'predict'\n        xtest = <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>\n    408 \n    409     if len(p.shape) == 1:\n    410         pred[:, col] = p\n    411     else:\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/ensemble/forest.py in predict(self=RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), X=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>)\n    529         Returns\n    530         -------\n    531         y : array of shape = [n_samples] or [n_samples, n_outputs]\n    532             The predicted classes.\n    533         \"\"\"\n--> 534         proba = self.predict_proba(X)\n        proba = undefined\n        self.predict_proba = <bound method ForestClassifier.predict_proba of ...e=None,\n            verbose=0, warm_start=False)>\n        X = <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>\n    535 \n    536         if self.n_outputs_ == 1:\n    537             return self.classes_.take(np.argmax(proba, axis=1), axis=0)\n    538 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/ensemble/forest.py in predict_proba(self=RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), X=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>)\n    568             such arrays if n_outputs > 1.\n    569             The class probabilities of the input samples. The order of the\n    570             classes corresponds to that in the attribute `classes_`.\n    571         \"\"\"\n    572         # Check data\n--> 573         X = self._validate_X_predict(X)\n        X = <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>\n        self._validate_X_predict = <bound method BaseForest._validate_X_predict of ...e=None,\n            verbose=0, warm_start=False)>\n    574 \n    575         # Assign chunk of trees to jobs\n    576         n_jobs, _, _ = _partition_estimators(self.n_estimators, self.n_jobs)\n    577 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/ensemble/forest.py in _validate_X_predict(self=RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), X=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>)\n    350         \"\"\"Validate X whenever one tries to predict, apply, predict_proba\"\"\"\n    351         if self.estimators_ is None or len(self.estimators_) == 0:\n    352             raise NotFittedError(\"Estimator not fitted, \"\n    353                                  \"call `fit` before exploiting the model.\")\n    354 \n--> 355         return self.estimators_[0]._validate_X_predict(X, check_input=True)\n        self.estimators_._validate_X_predict = undefined\n        X = <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>\n    356 \n    357     @property\n    358     def feature_importances_(self):\n    359         \"\"\"Return the feature importances (the higher, the more important the\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/tree/tree.py in _validate_X_predict(self=DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=537424915, splitter='best'), X=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, check_input=True)\n    360         if self.tree_ is None:\n    361             raise NotFittedError(\"Estimator not fitted, \"\n    362                                  \"call `fit` before exploiting the model.\")\n    363 \n    364         if check_input:\n--> 365             X = check_array(X, dtype=DTYPE, accept_sparse=\"csr\")\n        X = <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>\n    366             if issparse(X) and (X.indices.dtype != np.intc or\n    367                                 X.indptr.dtype != np.intc):\n    368                 raise ValueError(\"No support for np.int64 index based \"\n    369                                  \"sparse matrices\")\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, accept_sparse=['csr'], dtype=<class 'numpy.float32'>, order=None, copy=False, force_all_finite=True, ensure_2d=True, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)\n    375         estimator_name = \"Estimator\"\n    376     context = \" by %s\" % estimator_name if estimator is not None else \"\"\n    377 \n    378     if sp.issparse(array):\n    379         array = _ensure_sparse_format(array, accept_sparse, dtype, copy,\n--> 380                                       force_all_finite)\n        force_all_finite = True\n    381     else:\n    382         array = np.array(array, dtype=dtype, order=order, copy=copy)\n    383 \n    384         if ensure_2d:\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/utils/validation.py in _ensure_sparse_format(spmatrix=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, accept_sparse=['csr'], dtype=<class 'numpy.float32'>, copy=False, force_all_finite=True)\n    253         spmatrix = spmatrix.asformat(accept_sparse[0])\n    254         changed_format = True\n    255 \n    256     if dtype != spmatrix.dtype:\n    257         # convert dtype\n--> 258         spmatrix = spmatrix.astype(dtype)\n        spmatrix = <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>\n        spmatrix.astype = <bound method _data_matrix.astype of <1014x28676...stored elements in Compressed Sparse Row format>>\n        dtype = <class 'numpy.float32'>\n    259     elif copy and not changed_format:\n    260         # force copy\n    261         spmatrix = spmatrix.copy()\n    262 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/scipy/sparse/data.py in astype(self=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, t=<class 'numpy.float32'>)\n     63             return self\n     64         else:\n     65             return NotImplemented\n     66 \n     67     def astype(self, t):\n---> 68         return self._with_data(self._deduped_data().astype(t))\n        self._with_data = <bound method _cs_matrix._with_data of <1014x286...stored elements in Compressed Sparse Row format>>\n        self._deduped_data.astype = undefined\n        t = <class 'numpy.float32'>\n     69 \n     70     astype.__doc__ = spmatrix.astype.__doc__\n     71 \n     72     def conj(self):\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/scipy/sparse/data.py in _deduped_data(self=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>)\n     29         self.data.dtype = newtype\n     30     dtype = property(fget=_get_dtype, fset=_set_dtype)\n     31 \n     32     def _deduped_data(self):\n     33         if hasattr(self, 'sum_duplicates'):\n---> 34             self.sum_duplicates()\n        self.sum_duplicates = <bound method _cs_matrix.sum_duplicates of <1014...stored elements in Compressed Sparse Row format>>\n     35         return self.data\n     36 \n     37     def __abs__(self):\n     38         return self._with_data(abs(self._deduped_data()))\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/scipy/sparse/compressed.py in sum_duplicates(self=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>)\n   1011 \n   1012         The is an *in place* operation\n   1013         \"\"\"\n   1014         if self.has_canonical_format:\n   1015             return\n-> 1016         self.sort_indices()\n        self.sort_indices = <bound method _cs_matrix.sort_indices of <1014x2...stored elements in Compressed Sparse Row format>>\n   1017 \n   1018         M, N = self._swap(self.shape)\n   1019         _sparsetools.csr_sum_duplicates(M, N, self.indptr, self.indices,\n   1020                                         self.data)\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/scipy/sparse/compressed.py in sort_indices(self=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>)\n   1057         \"\"\"Sort the indices of this matrix *in place*\n   1058         \"\"\"\n   1059 \n   1060         if not self.has_sorted_indices:\n   1061             _sparsetools.csr_sort_indices(len(self.indptr) - 1, self.indptr,\n-> 1062                                           self.indices, self.data)\n        self.indices = memmap([285386, 285009, 284390, ...,   1862,   1712,   1709], dtype=int32)\n        self.data = memmap([ 0.04089954,  0.01047909,  0.05310395, ...,  0.03177006,\n        0.02322263,  0.01355832])\n   1063             self.has_sorted_indices = True\n   1064 \n   1065     def prune(self):\n   1066         \"\"\"Remove empty space after all non-zero elements.\n\nValueError: UPDATEIFCOPY base is read-only\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-3a7f44104b84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_tfidf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_binary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m    138\u001b[0m                                               \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                                               fit_params)\n\u001b[0;32m--> 140\u001b[0;31m                       for train, test in cv_iter)\n\u001b[0m\u001b[1;32m    141\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    606\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0mfit_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0mtest_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m         \u001b[0mscore_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfit_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_score\u001b[0;34m(estimator, X_test, y_test, scorer)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'item'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/metrics/scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[1;32m     89\u001b[0m         super(_PredictScorer, self).__call__(estimator, X, y_true,\n\u001b[1;32m     90\u001b[0m                                              sample_weight=sample_weight)\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             return self._sign * self._score_func(y_true, y_pred,\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/ensemble/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    742\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/ensemble/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    265\u001b[0m             \u001b[0mpredictions\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfinal\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \"\"\"\n\u001b[0;32m--> 267\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'predict'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/ensemble/base.py\u001b[0m in \u001b[0;36m_predict\u001b[0;34m(self, X, job, *args, **kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;31m# Predict with ensemble\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m             \u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_preds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/parallel/manager.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlyr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_partial_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlyr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparallel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__fitted__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/parallel/manager.py\u001b[0m in \u001b[0;36m_partial_process\u001b[0;34m(self, n, lyr, parallel)\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'P'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m         \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/parallel/estimation.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, P, parallel)\u001b[0m\n\u001b[1;32m    227\u001b[0m                                       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m                                       attr=pred_method)\n\u001b[0;32m--> 229\u001b[0;31m                  for case, (inst_name, est, (_, col)) in ests)\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    766\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x7f75a5c8c0c0, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/anthonyle/anaconda3/envs/deep_learning/lib...ges/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/anthon.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7f75a5c8c0c0, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/anthonyle/anaconda3/envs/deep_learning/lib...ges/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/anthon.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n     17 \n     18 \n     19 \n     20 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'from sklearn.model_selection import cross_val_sc..._tfidf, y_train_binary, cv=5, scoring=\"accuracy\")', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 6, 25, 9, 30, 44, 209328, tzinfo=datetime.timezone.utc), 'msg_id': '94F9EAB6938145C09C5F4C0A42C6ABC9', 'msg_type': 'execute_request', 'session': '55AD9960AF514B44A33856CD0CDB88E6', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '94F9EAB6938145C09C5F4C0A42C6ABC9', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'55AD9960AF514B44A33856CD0CDB88E6']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'from sklearn.model_selection import cross_val_sc..._tfidf, y_train_binary, cv=5, scoring=\"accuracy\")', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 6, 25, 9, 30, 44, 209328, tzinfo=datetime.timezone.utc), 'msg_id': '94F9EAB6938145C09C5F4C0A42C6ABC9', 'msg_type': 'execute_request', 'session': '55AD9960AF514B44A33856CD0CDB88E6', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '94F9EAB6938145C09C5F4C0A42C6ABC9', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'55AD9960AF514B44A33856CD0CDB88E6'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'from sklearn.model_selection import cross_val_sc..._tfidf, y_train_binary, cv=5, scoring=\"accuracy\")', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 6, 25, 9, 30, 44, 209328, tzinfo=datetime.timezone.utc), 'msg_id': '94F9EAB6938145C09C5F4C0A42C6ABC9', 'msg_type': 'execute_request', 'session': '55AD9960AF514B44A33856CD0CDB88E6', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '94F9EAB6938145C09C5F4C0A42C6ABC9', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='from sklearn.model_selection import cross_val_sc..._tfidf, y_train_binary, cv=5, scoring=\"accuracy\")', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'from sklearn.model_selection import cross_val_sc..._tfidf, y_train_binary, cv=5, scoring=\"accuracy\")'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('from sklearn.model_selection import cross_val_sc..._tfidf, y_train_binary, cv=5, scoring=\"accuracy\")',), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('from sklearn.model_selection import cross_val_sc..._tfidf, y_train_binary, cv=5, scoring=\"accuracy\")',)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='from sklearn.model_selection import cross_val_sc..._tfidf, y_train_binary, cv=5, scoring=\"accuracy\")', store_history=True, silent=False, shell_futures=True)\n   2693                 self.displayhook.exec_result = result\n   2694 \n   2695                 # Execute the user code\n   2696                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2697                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2698                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2699                 \n   2700                 self.last_execution_succeeded = not has_raised\n   2701 \n   2702                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.ImportFrom object>, <_ast.Expr object>], cell_name='<ipython-input-106-3a7f44104b84>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7f755940dcc0, executi..._before_exec=None error_in_exec=None result=None>)\n   2803                     return True\n   2804 \n   2805             for i, node in enumerate(to_run_interactive):\n   2806                 mod = ast.Interactive([node])\n   2807                 code = compiler(mod, cell_name, \"single\")\n-> 2808                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f7566b519c0, file \"<ipython-input-106-3a7f44104b84>\", line 2>\n        result = <ExecutionResult object at 7f755940dcc0, executi..._before_exec=None error_in_exec=None result=None>\n   2809                     return True\n   2810 \n   2811             # Flush softspace\n   2812             if softspace(sys.stdout, 0):\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f7566b519c0, file \"<ipython-input-106-3a7f44104b84>\", line 2>, result=<ExecutionResult object at 7f755940dcc0, executi..._before_exec=None error_in_exec=None result=None>)\n   2857         outflag = True  # happens in more places, so it's easier as default\n   2858         try:\n   2859             try:\n   2860                 self.hooks.pre_run_code_hook()\n   2861                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2862                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f7566b519c0, file \"<ipython-input-106-3a7f44104b84>\", line 2>\n        self.user_global_ns = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'EnsembleTransformer': <class 'mlens.preprocessing.ensemble_transformer.EnsembleTransformer'>, 'Evaluator': <class 'mlens.model_selection.model_selection.Evaluator'>, 'In': ['', \"import pandas as pd\\nfake_real_df = pd.read_csv('./fake_or_real_news.csv')\", \"fake_real_df_clean = fake_real_df[['title','text','label']]\", 'from sklearn.model_selection import StratifiedSh...rat_test_set = fake_real_df_clean.loc[test_index]', 'strat_fake_or_real_train = strat_train_set.copy()\\nstrat_fake_or_real_test  = strat_test_set.copy()', \"X_train = strat_fake_or_real_train.copy().drop('...y_test  = strat_fake_or_real_test.copy()['label']\", \"import nltk\\nfrom nltk.corpus import stopwords\\nfr...t = ' '.join(tokens)\\n    return preprocessed_text\", \"X_train_text_list  = list(X_train['text'])\\nX_tra...ext'])\\nX_test_title_list  = list(X_test['title'])\", 'X_train_text_clean = [preprocessing(text) for te...reprocessing(text) for text in X_test_title_list]', 'nltk.download()', \"import pandas as pd\\nfake_real_df = pd.read_csv('./fake_or_real_news.csv')\", \"fake_real_df_clean = fake_real_df[['title','text','label']]\", 'from sklearn.model_selection import StratifiedSh...rat_test_set = fake_real_df_clean.loc[test_index]', 'strat_fake_or_real_train = strat_train_set.copy()\\nstrat_fake_or_real_test  = strat_test_set.copy()', \"X_train = strat_fake_or_real_train.copy().drop('...y_test  = strat_fake_or_real_test.copy()['label']\", \"import nltk\\nfrom nltk.corpus import stopwords\\nfr...t = ' '.join(tokens)\\n    return preprocessed_text\", \"X_train_text_list  = list(X_train['text'])\\nX_tra...ext'])\\nX_test_title_list  = list(X_test['title'])\", 'X_train_text_clean = [preprocessing(text) for te...reprocessing(text) for text in X_test_title_list]', \"y_train_binary = [x=='REAL' for x in list(y_trai...y_test_binary = [x=='REAL' for x in list(y_test)]\", \"'''\\nThe code above is all cleaning.\\nI separated ...fit_transform(X_train_text_clean, y_train_binary)\", ...], 'LancasterStemmer': <class 'nltk.stem.lancaster.LancasterStemmer'>, 'LarsCV': <class 'sklearn.linear_model.least_angle.LarsCV'>, 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'Out': {9: True, 21: array([ 0.82955665,  0.82741617,  0.82329714,  0.81342547,  0.83119447]), 22: '\\nIt is now up to you to use the data as you wish...ll going to work on improving the current model.\\n', 29: <5068x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, 30: <1x286760 sparse matrix of type '<class 'numpy.f... stored elements in Compressed Sparse Row format>, 31: (5068, 286760), 32: 5068, 36: <class 'int'>, 37: 4, 38: <class 'int'>, ...}, 'P':         rfc    mnb    abc  Truth\n0      True   T...lse  False  False  False\n\n[5068 rows x 4 columns], 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, ...}\n        self.user_ns = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'EnsembleTransformer': <class 'mlens.preprocessing.ensemble_transformer.EnsembleTransformer'>, 'Evaluator': <class 'mlens.model_selection.model_selection.Evaluator'>, 'In': ['', \"import pandas as pd\\nfake_real_df = pd.read_csv('./fake_or_real_news.csv')\", \"fake_real_df_clean = fake_real_df[['title','text','label']]\", 'from sklearn.model_selection import StratifiedSh...rat_test_set = fake_real_df_clean.loc[test_index]', 'strat_fake_or_real_train = strat_train_set.copy()\\nstrat_fake_or_real_test  = strat_test_set.copy()', \"X_train = strat_fake_or_real_train.copy().drop('...y_test  = strat_fake_or_real_test.copy()['label']\", \"import nltk\\nfrom nltk.corpus import stopwords\\nfr...t = ' '.join(tokens)\\n    return preprocessed_text\", \"X_train_text_list  = list(X_train['text'])\\nX_tra...ext'])\\nX_test_title_list  = list(X_test['title'])\", 'X_train_text_clean = [preprocessing(text) for te...reprocessing(text) for text in X_test_title_list]', 'nltk.download()', \"import pandas as pd\\nfake_real_df = pd.read_csv('./fake_or_real_news.csv')\", \"fake_real_df_clean = fake_real_df[['title','text','label']]\", 'from sklearn.model_selection import StratifiedSh...rat_test_set = fake_real_df_clean.loc[test_index]', 'strat_fake_or_real_train = strat_train_set.copy()\\nstrat_fake_or_real_test  = strat_test_set.copy()', \"X_train = strat_fake_or_real_train.copy().drop('...y_test  = strat_fake_or_real_test.copy()['label']\", \"import nltk\\nfrom nltk.corpus import stopwords\\nfr...t = ' '.join(tokens)\\n    return preprocessed_text\", \"X_train_text_list  = list(X_train['text'])\\nX_tra...ext'])\\nX_test_title_list  = list(X_test['title'])\", 'X_train_text_clean = [preprocessing(text) for te...reprocessing(text) for text in X_test_title_list]', \"y_train_binary = [x=='REAL' for x in list(y_trai...y_test_binary = [x=='REAL' for x in list(y_test)]\", \"'''\\nThe code above is all cleaning.\\nI separated ...fit_transform(X_train_text_clean, y_train_binary)\", ...], 'LancasterStemmer': <class 'nltk.stem.lancaster.LancasterStemmer'>, 'LarsCV': <class 'sklearn.linear_model.least_angle.LarsCV'>, 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'Out': {9: True, 21: array([ 0.82955665,  0.82741617,  0.82329714,  0.81342547,  0.83119447]), 22: '\\nIt is now up to you to use the data as you wish...ll going to work on improving the current model.\\n', 29: <5068x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, 30: <1x286760 sparse matrix of type '<class 'numpy.f... stored elements in Compressed Sparse Row format>, 31: (5068, 286760), 32: 5068, 36: <class 'int'>, 37: 4, 38: <class 'int'>, ...}, 'P':         rfc    mnb    abc  Truth\n0      True   T...lse  False  False  False\n\n[5068 rows x 4 columns], 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, ...}\n   2863             finally:\n   2864                 # Reset our crash handler in place\n   2865                 sys.excepthook = old_excepthook\n   2866         except SystemExit as e:\n\n...........................................................................\n/mnt/Linux-Extra/home-extra/Anthony.Le/Projects/fake_news/<ipython-input-106-3a7f44104b84> in <module>()\n      1 \n----> 2 \n      3 \n      4 \n      5 from sklearn.model_selection import cross_val_score\n      6 cross_val_score(ens, X_train_tfidf, y_train_binary, cv=5, scoring=\"accuracy\")\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in cross_val_score(estimator=SuperLearner(array_check=2, backend='threading',...ne, scorer=None,\n       shuffle=False, verbose=5), X=<5068x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, y=[True, False, False, False, False, False, False, False, True, True, True, False, True, False, True, False, True, True, False, False, ...], groups=None, scoring='accuracy', cv=KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs')\n    135     parallel = Parallel(n_jobs=n_jobs, verbose=verbose,\n    136                         pre_dispatch=pre_dispatch)\n    137     scores = parallel(delayed(_fit_and_score)(clone(estimator), X, y, scorer,\n    138                                               train, test, verbose, None,\n    139                                               fit_params)\n--> 140                       for train, test in cv_iter)\n        cv_iter = [(array([1014, 1015, 1016, ..., 5065, 5066, 5067]), array([   0,    1,    2, ..., 1011, 1012, 1013])), (array([   0,    1,    2, ..., 5065, 5066, 5067]), array([1014, 1015, 1016, ..., 2025, 2026, 2027])), (array([   0,    1,    2, ..., 5065, 5066, 5067]), array([2028, 2029, 2030, ..., 3039, 3040, 3041])), (array([   0,    1,    2, ..., 5065, 5066, 5067]), array([3042, 3043, 3044, ..., 4052, 4053, 4054])), (array([   0,    1,    2, ..., 4052, 4053, 4054]), array([4055, 4056, 4057, ..., 5065, 5066, 5067]))]\n    141     return np.array(scores)[:, 0]\n    142 \n    143 \n    144 def _fit_and_score(estimator, X, y, scorer, train, test, verbose,\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object cross_val_score.<locals>.<genexpr>>)\n    753         self.n_completed_tasks = 0\n    754         try:\n    755             # Only set self._iterating to True if at least a batch\n    756             # was dispatched. In particular this covers the edge\n    757             # case of Parallel used with an exhausted iterator.\n--> 758             while self.dispatch_one_batch(iterator):\n        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>\n        iterator = <generator object cross_val_score.<locals>.<genexpr>>\n    759                 self._iterating = True\n    760             else:\n    761                 self._iterating = False\n    762 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object cross_val_score.<locals>.<genexpr>>)\n    603             tasks = BatchedCalls(itertools.islice(iterator, batch_size))\n    604             if len(tasks) == 0:\n    605                 # No more tasks available in the iterator: tell caller to stop.\n    606                 return False\n    607             else:\n--> 608                 self._dispatch(tasks)\n        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>\n        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    609                 return True\n    610 \n    611     def _print(self, msg, msg_args):\n    612         \"\"\"Display the message on stout or stderr depending on verbosity\"\"\"\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    566         self.n_dispatched_tasks += len(batch)\n    567         self.n_dispatched_batches += 1\n    568 \n    569         dispatch_timestamp = time.time()\n    570         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)\n--> 571         job = self._backend.apply_async(batch, callback=cb)\n        job = undefined\n        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>\n    572         self._jobs.append(job)\n    573 \n    574     def dispatch_next(self):\n    575         \"\"\"Dispatch more data for parallel processing\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)\n    104             raise ValueError('n_jobs == 0 in Parallel has no meaning')\n    105         return 1\n    106 \n    107     def apply_async(self, func, callback=None):\n    108         \"\"\"Schedule a func to be run\"\"\"\n--> 109         result = ImmediateResult(func)\n        result = undefined\n        func = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    110         if callback:\n    111             callback(result)\n    112         return result\n    113 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    321 \n    322 class ImmediateResult(object):\n    323     def __init__(self, batch):\n    324         # Don't delay the application, to avoid keeping the input\n    325         # arguments in memory\n--> 326         self.results = batch()\n        self.results = undefined\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    327 \n    328     def get(self):\n    329         return self.results\n    330 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (SuperLearner(array_check=2, backend='threading',...ne, scorer=None,\n       shuffle=False, verbose=5), <5068x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, [True, False, False, False, False, False, False, False, True, True, True, False, True, False, True, False, True, True, False, False, ...], make_scorer(accuracy_score), array([1014, 1015, 1016, ..., 5065, 5066, 5067]), array([   0,    1,    2, ..., 1011, 1012, 1013]), 0, None, None), {})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (SuperLearner(array_check=2, backend='threading',...ne, scorer=None,\n       shuffle=False, verbose=5), <5068x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, [True, False, False, False, False, False, False, False, True, True, True, False, True, False, True, False, True, True, False, False, ...], make_scorer(accuracy_score), array([1014, 1015, 1016, ..., 5065, 5066, 5067]), array([   0,    1,    2, ..., 1011, 1012, 1013]), 0, None, None)\n        kwargs = {}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=SuperLearner(array_check=2, backend='threading',...ne, scorer=None,\n       shuffle=False, verbose=5), X=<5068x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, y=[True, False, False, False, False, False, False, False, True, True, True, False, True, False, True, False, True, True, False, False, ...], scorer=make_scorer(accuracy_score), train=array([1014, 1015, 1016, ..., 5065, 5066, 5067]), test=array([   0,    1,    2, ..., 1011, 1012, 1013]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=False, error_score='raise')\n    255                              \" numeric value. (Hint: if using 'raise', please\"\n    256                              \" make sure that it has been spelled correctly.)\")\n    257 \n    258     else:\n    259         fit_time = time.time() - start_time\n--> 260         test_score = _score(estimator, X_test, y_test, scorer)\n        test_score = undefined\n        estimator = SuperLearner(array_check=2, backend='threading',...ne, scorer=None,\n       shuffle=False, verbose=5)\n        X_test = <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>\n        y_test = [True, False, False, False, False, False, False, False, True, True, True, False, True, False, True, False, True, True, False, False, ...]\n        scorer = make_scorer(accuracy_score)\n    261         score_time = time.time() - start_time - fit_time\n    262         if return_train_score:\n    263             train_score = _score(estimator, X_train, y_train, scorer)\n    264 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _score(estimator=SuperLearner(array_check=2, backend='threading',...ne, scorer=None,\n       shuffle=False, verbose=5), X_test=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, y_test=[True, False, False, False, False, False, False, False, True, True, True, False, True, False, True, False, True, True, False, False, ...], scorer=make_scorer(accuracy_score))\n    283 def _score(estimator, X_test, y_test, scorer):\n    284     \"\"\"Compute the score of an estimator on a given test set.\"\"\"\n    285     if y_test is None:\n    286         score = scorer(estimator, X_test)\n    287     else:\n--> 288         score = scorer(estimator, X_test, y_test)\n        score = undefined\n        scorer = make_scorer(accuracy_score)\n        estimator = SuperLearner(array_check=2, backend='threading',...ne, scorer=None,\n       shuffle=False, verbose=5)\n        X_test = <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>\n        y_test = [True, False, False, False, False, False, False, False, True, True, True, False, True, False, True, False, True, True, False, False, ...]\n    289     if hasattr(score, 'item'):\n    290         try:\n    291             # e.g. unwrap memmapped scalars\n    292             score = score.item()\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/metrics/scorer.py in __call__(self=make_scorer(accuracy_score), estimator=SuperLearner(array_check=2, backend='threading',...ne, scorer=None,\n       shuffle=False, verbose=5), X=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, y_true=[True, False, False, False, False, False, False, False, True, True, True, False, True, False, True, False, True, True, False, False, ...], sample_weight=None)\n     86         score : float\n     87             Score function applied to prediction of estimator on X.\n     88         \"\"\"\n     89         super(_PredictScorer, self).__call__(estimator, X, y_true,\n     90                                              sample_weight=sample_weight)\n---> 91         y_pred = estimator.predict(X)\n        y_pred = undefined\n        estimator.predict = <bound method BaseEnsemble.predict of SuperLearn...e, scorer=None,\n       shuffle=False, verbose=5)>\n        X = <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>\n     92         if sample_weight is not None:\n     93             return self._sign * self._score_func(y_true, y_pred,\n     94                                                  sample_weight=sample_weight,\n     95                                                  **self._kwargs)\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/ensemble/base.py in predict(self=SuperLearner(array_check=2, backend='threading',...ne, scorer=None,\n       shuffle=False, verbose=5), X=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>)\n    739         if self.shuffle:\n    740             r = check_random_state(self.random_state)\n    741             idx = r.permutation(X.shape[0])\n    742             X = X[idx]\n    743 \n--> 744         y = self.layers.predict(X)\n        y = undefined\n        self.layers.predict = <bound method LayerContainer.predict of LayerCon...  n_jobs=-1, raise_on_exception=True, verbose=5)>\n        X = <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>\n    745 \n    746         if y.shape[1] == 1:\n    747             # The meta estimator is treated as a layer and thus a prediction\n    748             # matrix with shape [n_samples, 1] is created. Ravel before return\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/ensemble/base.py in predict(self=LayerContainer(backend='threading',\n        laye...   n_jobs=-1, raise_on_exception=True, verbose=5), X=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, *args=(), **kwargs={})\n    262         Returns\n    263         -------\n    264         X_pred : array-like of shape = [n_samples, n_fitted_estimators]\n    265             predictions from final layer.\n    266         \"\"\"\n--> 267         return self._predict(X, 'predict', *args, **kwargs)\n        self._predict = <bound method LayerContainer._predict of LayerCo...  n_jobs=-1, raise_on_exception=True, verbose=5)>\n        X = <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>\n        args = ()\n        kwargs = {}\n    268 \n    269     def transform(self, X=None, *args, **kwargs):\n    270         \"\"\"Generic method for reproducing predictions of the ``fit`` call.\n    271 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/ensemble/base.py in _predict(self=LayerContainer(backend='threading',\n        laye...   n_jobs=-1, raise_on_exception=True, verbose=5), X=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, job='predict', *args=(), **kwargs={})\n    315         processor = ParallelProcessing(self)\n    316         processor.initialize(job, X, *args, **kwargs)\n    317 \n    318         # Predict with ensemble\n    319         try:\n--> 320             processor.process()\n        processor.process = <bound method ParallelProcessing.process of <mlens.parallel.manager.ParallelProcessing object>>\n    321 \n    322             preds = processor.get_preds()\n    323 \n    324             if self.verbose:\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/parallel/manager.py in process(self=<mlens.parallel.manager.ParallelProcessing object>)\n    213                       mmap_mode='w+',\n    214                       verbose=self.layers.verbose,\n    215                       backend=self.layers.backend) as parallel:\n    216 \n    217             for n, lyr in enumerate(self.layers.layers.values()):\n--> 218                 self._partial_process(n, lyr, parallel)\n        self._partial_process = <bound method ParallelProcessing._partial_proces...lens.parallel.manager.ParallelProcessing object>>\n        n = 0\n        lyr = Layer(cls='stack', cls_kwargs=None,\n   estimator... raise_on_exception=True, scorer=None, verbose=5)\n        parallel = Parallel(n_jobs=-1)\n    219 \n    220         self.__fitted__ = 1\n    221 \n    222     def get_preds(self, n=-1, dtype=np.float, order='C'):\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/parallel/manager.py in _partial_process(self=<mlens.parallel.manager.ParallelProcessing object>, n=0, lyr=Layer(cls='stack', cls_kwargs=None,\n   estimator... raise_on_exception=True, scorer=None, verbose=5), parallel=Parallel(n_jobs=-1))\n    303         if 'X' in fargs:\n    304             kwargs['X'] = self.job.P[n]\n    305         if 'P' in fargs:\n    306             kwargs['P'] = self.job.P[n + 1]\n    307 \n--> 308         f(**kwargs)\n        f = <bound method BaseEstimator.predict of <mlens.parallel.stack.Stacker object>>\n        kwargs = {'P': memmap([[ 0.,  1.,  0.],\n       [ 0.,  0.,  0.],...\n       [ 0.,  1.,  0.],\n       [ 0.,  1.,  0.]]), 'X': <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, 'parallel': Parallel(n_jobs=-1)}\n    309 \n    310 \n    311 ###############################################################################\n    312 class ParallelEvaluation(object):\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/parallel/estimation.py in predict(self=<mlens.parallel.stack.Stacker object>, X=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, P=memmap([[ 0.,  1.,  0.],\n       [ 0.,  0.,  0.],...\n       [ 0.,  1.,  0.],\n       [ 0.,  1.,  0.]]), parallel=Parallel(n_jobs=-1))\n    224                                       xtest=X,\n    225                                       pred=P,\n    226                                       col=col,\n    227                                       name=self.name,\n    228                                       attr=pred_method)\n--> 229                  for case, (inst_name, est, (_, col)) in ests)\n        ests = [(None, ('rfc', RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), (None, 0))), (None, ('mnb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), (None, 1))), (None, ('abc', AdaBoostClassifier(algorithm='SAMME.R', base_est...ing_rate=1.0, n_estimators=50, random_state=None), (None, 2)))]\n    230 \n    231         if self.verbose:\n    232             print_time(t0, '%s Done' % self.name, file=printout)\n    233 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseEstimator.predict.<locals>.<genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Sun Jun 25 02:31:03 2017\nPID: 16426Python 3.6.1: /home/anthonyle/anaconda3/envs/deep_learning/bin/python\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/externals/joblib/parallel.py in __call__(self=<mlens.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function predict_est>, (), {'attr': 'predict', 'case': None, 'col': 0, 'est': RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), 'inst_name': 'rfc', 'name': 'layer-1', 'pred': memmap([[ 0.,  1.,  0.],\n       [ 0.,  0.,  0.],...\n       [ 0.,  1.,  0.],\n       [ 0.,  1.,  0.]]), 'tr_list': [], 'xtest': <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function predict_est>\n        args = ()\n        kwargs = {'attr': 'predict', 'case': None, 'col': 0, 'est': RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), 'inst_name': 'rfc', 'name': 'layer-1', 'pred': memmap([[ 0.,  1.,  0.],\n       [ 0.,  0.,  0.],...\n       [ 0.,  1.,  0.],\n       [ 0.,  1.,  0.]]), 'tr_list': [], 'xtest': <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/mlens/parallel/estimation.py in predict_est(case=None, tr_list=[], inst_name='rfc', est=RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), xtest=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, pred=memmap([[ 0.,  1.,  0.],\n       [ 0.,  0.,  0.],...\n       [ 0.,  1.,  0.],\n       [ 0.,  1.,  0.]]), col=0, name='layer-1', attr='predict')\n    402 \n    403     # Predict into memmap\n    404     # Here, we coerce errors on failed predictions - all predictors that\n    405     # survive into the estimators_ attribute of a layer should be able to\n    406     # predict, otherwise the subsequent layer will get corrupt input.\n--> 407     p = getattr(est, attr)(xtest)\n        p = undefined\n        est = RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False)\n        attr = 'predict'\n        xtest = <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>\n    408 \n    409     if len(p.shape) == 1:\n    410         pred[:, col] = p\n    411     else:\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/ensemble/forest.py in predict(self=RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), X=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>)\n    529         Returns\n    530         -------\n    531         y : array of shape = [n_samples] or [n_samples, n_outputs]\n    532             The predicted classes.\n    533         \"\"\"\n--> 534         proba = self.predict_proba(X)\n        proba = undefined\n        self.predict_proba = <bound method ForestClassifier.predict_proba of ...e=None,\n            verbose=0, warm_start=False)>\n        X = <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>\n    535 \n    536         if self.n_outputs_ == 1:\n    537             return self.classes_.take(np.argmax(proba, axis=1), axis=0)\n    538 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/ensemble/forest.py in predict_proba(self=RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), X=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>)\n    568             such arrays if n_outputs > 1.\n    569             The class probabilities of the input samples. The order of the\n    570             classes corresponds to that in the attribute `classes_`.\n    571         \"\"\"\n    572         # Check data\n--> 573         X = self._validate_X_predict(X)\n        X = <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>\n        self._validate_X_predict = <bound method BaseForest._validate_X_predict of ...e=None,\n            verbose=0, warm_start=False)>\n    574 \n    575         # Assign chunk of trees to jobs\n    576         n_jobs, _, _ = _partition_estimators(self.n_estimators, self.n_jobs)\n    577 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/ensemble/forest.py in _validate_X_predict(self=RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), X=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>)\n    350         \"\"\"Validate X whenever one tries to predict, apply, predict_proba\"\"\"\n    351         if self.estimators_ is None or len(self.estimators_) == 0:\n    352             raise NotFittedError(\"Estimator not fitted, \"\n    353                                  \"call `fit` before exploiting the model.\")\n    354 \n--> 355         return self.estimators_[0]._validate_X_predict(X, check_input=True)\n        self.estimators_._validate_X_predict = undefined\n        X = <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>\n    356 \n    357     @property\n    358     def feature_importances_(self):\n    359         \"\"\"Return the feature importances (the higher, the more important the\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/tree/tree.py in _validate_X_predict(self=DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=537424915, splitter='best'), X=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, check_input=True)\n    360         if self.tree_ is None:\n    361             raise NotFittedError(\"Estimator not fitted, \"\n    362                                  \"call `fit` before exploiting the model.\")\n    363 \n    364         if check_input:\n--> 365             X = check_array(X, dtype=DTYPE, accept_sparse=\"csr\")\n        X = <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>\n    366             if issparse(X) and (X.indices.dtype != np.intc or\n    367                                 X.indptr.dtype != np.intc):\n    368                 raise ValueError(\"No support for np.int64 index based \"\n    369                                  \"sparse matrices\")\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, accept_sparse=['csr'], dtype=<class 'numpy.float32'>, order=None, copy=False, force_all_finite=True, ensure_2d=True, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)\n    375         estimator_name = \"Estimator\"\n    376     context = \" by %s\" % estimator_name if estimator is not None else \"\"\n    377 \n    378     if sp.issparse(array):\n    379         array = _ensure_sparse_format(array, accept_sparse, dtype, copy,\n--> 380                                       force_all_finite)\n        force_all_finite = True\n    381     else:\n    382         array = np.array(array, dtype=dtype, order=order, copy=copy)\n    383 \n    384         if ensure_2d:\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/utils/validation.py in _ensure_sparse_format(spmatrix=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, accept_sparse=['csr'], dtype=<class 'numpy.float32'>, copy=False, force_all_finite=True)\n    253         spmatrix = spmatrix.asformat(accept_sparse[0])\n    254         changed_format = True\n    255 \n    256     if dtype != spmatrix.dtype:\n    257         # convert dtype\n--> 258         spmatrix = spmatrix.astype(dtype)\n        spmatrix = <1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>\n        spmatrix.astype = <bound method _data_matrix.astype of <1014x28676...stored elements in Compressed Sparse Row format>>\n        dtype = <class 'numpy.float32'>\n    259     elif copy and not changed_format:\n    260         # force copy\n    261         spmatrix = spmatrix.copy()\n    262 \n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/scipy/sparse/data.py in astype(self=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, t=<class 'numpy.float32'>)\n     63             return self\n     64         else:\n     65             return NotImplemented\n     66 \n     67     def astype(self, t):\n---> 68         return self._with_data(self._deduped_data().astype(t))\n        self._with_data = <bound method _cs_matrix._with_data of <1014x286...stored elements in Compressed Sparse Row format>>\n        self._deduped_data.astype = undefined\n        t = <class 'numpy.float32'>\n     69 \n     70     astype.__doc__ = spmatrix.astype.__doc__\n     71 \n     72     def conj(self):\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/scipy/sparse/data.py in _deduped_data(self=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>)\n     29         self.data.dtype = newtype\n     30     dtype = property(fget=_get_dtype, fset=_set_dtype)\n     31 \n     32     def _deduped_data(self):\n     33         if hasattr(self, 'sum_duplicates'):\n---> 34             self.sum_duplicates()\n        self.sum_duplicates = <bound method _cs_matrix.sum_duplicates of <1014...stored elements in Compressed Sparse Row format>>\n     35         return self.data\n     36 \n     37     def __abs__(self):\n     38         return self._with_data(abs(self._deduped_data()))\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/scipy/sparse/compressed.py in sum_duplicates(self=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>)\n   1011 \n   1012         The is an *in place* operation\n   1013         \"\"\"\n   1014         if self.has_canonical_format:\n   1015             return\n-> 1016         self.sort_indices()\n        self.sort_indices = <bound method _cs_matrix.sort_indices of <1014x2...stored elements in Compressed Sparse Row format>>\n   1017 \n   1018         M, N = self._swap(self.shape)\n   1019         _sparsetools.csr_sum_duplicates(M, N, self.indptr, self.indices,\n   1020                                         self.data)\n\n...........................................................................\n/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/scipy/sparse/compressed.py in sort_indices(self=<1014x286760 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>)\n   1057         \"\"\"Sort the indices of this matrix *in place*\n   1058         \"\"\"\n   1059 \n   1060         if not self.has_sorted_indices:\n   1061             _sparsetools.csr_sort_indices(len(self.indptr) - 1, self.indptr,\n-> 1062                                           self.indices, self.data)\n        self.indices = memmap([285386, 285009, 284390, ...,   1862,   1712,   1709], dtype=int32)\n        self.data = memmap([ 0.04089954,  0.01047909,  0.05310395, ...,  0.03177006,\n        0.02322263,  0.01355832])\n   1063             self.has_sorted_indices = True\n   1064 \n   1065     def prune(self):\n   1066         \"\"\"Remove empty space after all non-zero elements.\n\nValueError: UPDATEIFCOPY base is read-only\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(ens, X_train_tfidf, y_train_binary, cv=5, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is some error in this module. Given that it is rather late, I may just have to predict based on majority vote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anthonyle/anaconda3/envs/deep_learning/lib/python3.6/site-packages/sklearn/metrics/regression.py:164: DeprecationWarning: numpy boolean subtract, the `-` operator, is deprecated, use the bitwise_xor, the `^` operator, or the logical_xor function instead.\n",
      "  output_errors = np.average(np.abs(y_pred - y_true),\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.006314127861089187"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_train_binary, P['rfc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on uniform_gen in module scipy.stats._continuous_distns object:\n",
      "\n",
      "class uniform_gen(scipy.stats._distn_infrastructure.rv_continuous)\n",
      " |  A uniform continuous random variable.\n",
      " |  \n",
      " |  This distribution is constant between `loc` and ``loc + scale``.\n",
      " |  \n",
      " |  %(before_notes)s\n",
      " |  \n",
      " |  %(example)s\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      uniform_gen\n",
      " |      scipy.stats._distn_infrastructure.rv_continuous\n",
      " |      scipy.stats._distn_infrastructure.rv_generic\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods inherited from scipy.stats._distn_infrastructure.rv_continuous:\n",
      " |  \n",
      " |  __init__(self, momtype=1, a=None, b=None, xtol=1e-14, badvalue=None, name=None, longname=None, shapes=None, extradoc=None, seed=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  cdf(self, x, *args, **kwds)\n",
      " |      Cumulative distribution function of the given RV.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      x : array_like\n",
      " |          quantiles\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information)\n",
      " |      loc : array_like, optional\n",
      " |          location parameter (default=0)\n",
      " |      scale : array_like, optional\n",
      " |          scale parameter (default=1)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      cdf : ndarray\n",
      " |          Cumulative distribution function evaluated at `x`\n",
      " |  \n",
      " |  expect(self, func=None, args=(), loc=0, scale=1, lb=None, ub=None, conditional=False, **kwds)\n",
      " |      Calculate expected value of a function with respect to the\n",
      " |      distribution.\n",
      " |      \n",
      " |      The expected value of a function ``f(x)`` with respect to a\n",
      " |      distribution ``dist`` is defined as::\n",
      " |      \n",
      " |                  ubound\n",
      " |          E[x] = Integral(f(x) * dist.pdf(x))\n",
      " |                  lbound\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : callable, optional\n",
      " |          Function for which integral is calculated. Takes only one argument.\n",
      " |          The default is the identity mapping f(x) = x.\n",
      " |      args : tuple, optional\n",
      " |          Shape parameters of the distribution.\n",
      " |      loc : float, optional\n",
      " |          Location parameter (default=0).\n",
      " |      scale : float, optional\n",
      " |          Scale parameter (default=1).\n",
      " |      lb, ub : scalar, optional\n",
      " |          Lower and upper bound for integration. Default is set to the\n",
      " |          support of the distribution.\n",
      " |      conditional : bool, optional\n",
      " |          If True, the integral is corrected by the conditional probability\n",
      " |          of the integration interval.  The return value is the expectation\n",
      " |          of the function, conditional on being in the given interval.\n",
      " |          Default is False.\n",
      " |      \n",
      " |      Additional keyword arguments are passed to the integration routine.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      expect : float\n",
      " |          The calculated expected value.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The integration behavior of this function is inherited from\n",
      " |      `integrate.quad`.\n",
      " |  \n",
      " |  fit(self, data, *args, **kwds)\n",
      " |      Return MLEs for shape (if applicable), location, and scale\n",
      " |      parameters from data.\n",
      " |      \n",
      " |      MLE stands for Maximum Likelihood Estimate.  Starting estimates for\n",
      " |      the fit are given by input arguments; for any arguments not provided\n",
      " |      with starting estimates, ``self._fitstart(data)`` is called to generate\n",
      " |      such.\n",
      " |      \n",
      " |      One can hold some parameters fixed to specific values by passing in\n",
      " |      keyword arguments ``f0``, ``f1``, ..., ``fn`` (for shape parameters)\n",
      " |      and ``floc`` and ``fscale`` (for location and scale parameters,\n",
      " |      respectively).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : array_like\n",
      " |          Data to use in calculating the MLEs.\n",
      " |      args : floats, optional\n",
      " |          Starting value(s) for any shape-characterizing arguments (those not\n",
      " |          provided will be determined by a call to ``_fitstart(data)``).\n",
      " |          No default value.\n",
      " |      kwds : floats, optional\n",
      " |          Starting values for the location and scale parameters; no default.\n",
      " |          Special keyword arguments are recognized as holding certain\n",
      " |          parameters fixed:\n",
      " |      \n",
      " |          - f0...fn : hold respective shape parameters fixed.\n",
      " |            Alternatively, shape parameters to fix can be specified by name.\n",
      " |            For example, if ``self.shapes == \"a, b\"``, ``fa``and ``fix_a``\n",
      " |            are equivalent to ``f0``, and ``fb`` and ``fix_b`` are\n",
      " |            equivalent to ``f1``.\n",
      " |      \n",
      " |          - floc : hold location parameter fixed to specified value.\n",
      " |      \n",
      " |          - fscale : hold scale parameter fixed to specified value.\n",
      " |      \n",
      " |          - optimizer : The optimizer to use.  The optimizer must take ``func``,\n",
      " |            and starting position as the first two arguments,\n",
      " |            plus ``args`` (for extra arguments to pass to the\n",
      " |            function to be optimized) and ``disp=0`` to suppress\n",
      " |            output as keyword arguments.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      mle_tuple : tuple of floats\n",
      " |          MLEs for any shape parameters (if applicable), followed by those\n",
      " |          for location and scale. For most random variables, shape statistics\n",
      " |          will be returned, but there are exceptions (e.g. ``norm``).\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This fit is computed by maximizing a log-likelihood function, with\n",
      " |      penalty applied for samples outside of range of the distribution. The\n",
      " |      returned answer is not guaranteed to be the globally optimal MLE, it\n",
      " |      may only be locally optimal, or the optimization may fail altogether.\n",
      " |      \n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Generate some data to fit: draw random variates from the `beta`\n",
      " |      distribution\n",
      " |      \n",
      " |      >>> from scipy.stats import beta\n",
      " |      >>> a, b = 1., 2.\n",
      " |      >>> x = beta.rvs(a, b, size=1000)\n",
      " |      \n",
      " |      Now we can fit all four parameters (``a``, ``b``, ``loc`` and ``scale``):\n",
      " |      \n",
      " |      >>> a1, b1, loc1, scale1 = beta.fit(x)\n",
      " |      \n",
      " |      We can also use some prior knowledge about the dataset: let's keep\n",
      " |      ``loc`` and ``scale`` fixed:\n",
      " |      \n",
      " |      >>> a1, b1, loc1, scale1 = beta.fit(x, floc=0, fscale=1)\n",
      " |      >>> loc1, scale1\n",
      " |      (0, 1)\n",
      " |      \n",
      " |      We can also keep shape parameters fixed by using ``f``-keywords. To\n",
      " |      keep the zero-th shape parameter ``a`` equal 1, use ``f0=1`` or,\n",
      " |      equivalently, ``fa=1``:\n",
      " |      \n",
      " |      >>> a1, b1, loc1, scale1 = beta.fit(x, fa=1, floc=0, fscale=1)\n",
      " |      >>> a1\n",
      " |      1\n",
      " |      \n",
      " |      Not all distributions return estimates for the shape parameters.\n",
      " |      ``norm`` for example just returns estimates for location and scale:\n",
      " |      \n",
      " |      >>> from scipy.stats import norm\n",
      " |      >>> x = norm.rvs(a, b, size=1000, random_state=123)\n",
      " |      >>> loc1, scale1 = norm.fit(x)\n",
      " |      >>> loc1, scale1\n",
      " |      (0.92087172783841631, 2.0015750750324668)\n",
      " |  \n",
      " |  fit_loc_scale(self, data, *args)\n",
      " |      Estimate loc and scale parameters from data using 1st and 2nd moments.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : array_like\n",
      " |          Data to fit.\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Lhat : float\n",
      " |          Estimated location parameter for the data.\n",
      " |      Shat : float\n",
      " |          Estimated scale parameter for the data.\n",
      " |  \n",
      " |  isf(self, q, *args, **kwds)\n",
      " |      Inverse survival function (inverse of `sf`) at q of the given RV.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      q : array_like\n",
      " |          upper tail probability\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information)\n",
      " |      loc : array_like, optional\n",
      " |          location parameter (default=0)\n",
      " |      scale : array_like, optional\n",
      " |          scale parameter (default=1)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      x : ndarray or scalar\n",
      " |          Quantile corresponding to the upper tail probability q.\n",
      " |  \n",
      " |  logcdf(self, x, *args, **kwds)\n",
      " |      Log of the cumulative distribution function at x of the given RV.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      x : array_like\n",
      " |          quantiles\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information)\n",
      " |      loc : array_like, optional\n",
      " |          location parameter (default=0)\n",
      " |      scale : array_like, optional\n",
      " |          scale parameter (default=1)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      logcdf : array_like\n",
      " |          Log of the cumulative distribution function evaluated at x\n",
      " |  \n",
      " |  logpdf(self, x, *args, **kwds)\n",
      " |      Log of the probability density function at x of the given RV.\n",
      " |      \n",
      " |      This uses a more numerically accurate calculation if available.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      x : array_like\n",
      " |          quantiles\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information)\n",
      " |      loc : array_like, optional\n",
      " |          location parameter (default=0)\n",
      " |      scale : array_like, optional\n",
      " |          scale parameter (default=1)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      logpdf : array_like\n",
      " |          Log of the probability density function evaluated at x\n",
      " |  \n",
      " |  logsf(self, x, *args, **kwds)\n",
      " |      Log of the survival function of the given RV.\n",
      " |      \n",
      " |      Returns the log of the \"survival function,\" defined as (1 - `cdf`),\n",
      " |      evaluated at `x`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      x : array_like\n",
      " |          quantiles\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information)\n",
      " |      loc : array_like, optional\n",
      " |          location parameter (default=0)\n",
      " |      scale : array_like, optional\n",
      " |          scale parameter (default=1)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      logsf : ndarray\n",
      " |          Log of the survival function evaluated at `x`.\n",
      " |  \n",
      " |  nnlf(self, theta, x)\n",
      " |      Return negative loglikelihood function.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This is ``-sum(log pdf(x, theta), axis=0)`` where `theta` are the\n",
      " |      parameters (including loc and scale).\n",
      " |  \n",
      " |  pdf(self, x, *args, **kwds)\n",
      " |      Probability density function at x of the given RV.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      x : array_like\n",
      " |          quantiles\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information)\n",
      " |      loc : array_like, optional\n",
      " |          location parameter (default=0)\n",
      " |      scale : array_like, optional\n",
      " |          scale parameter (default=1)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      pdf : ndarray\n",
      " |          Probability density function evaluated at x\n",
      " |  \n",
      " |  ppf(self, q, *args, **kwds)\n",
      " |      Percent point function (inverse of `cdf`) at q of the given RV.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      q : array_like\n",
      " |          lower tail probability\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information)\n",
      " |      loc : array_like, optional\n",
      " |          location parameter (default=0)\n",
      " |      scale : array_like, optional\n",
      " |          scale parameter (default=1)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      x : array_like\n",
      " |          quantile corresponding to the lower tail probability q.\n",
      " |  \n",
      " |  sf(self, x, *args, **kwds)\n",
      " |      Survival function (1 - `cdf`) at x of the given RV.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      x : array_like\n",
      " |          quantiles\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information)\n",
      " |      loc : array_like, optional\n",
      " |          location parameter (default=0)\n",
      " |      scale : array_like, optional\n",
      " |          scale parameter (default=1)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      sf : array_like\n",
      " |          Survival function evaluated at x\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from scipy.stats._distn_infrastructure.rv_generic:\n",
      " |  \n",
      " |  __call__(self, *args, **kwds)\n",
      " |      Freeze the distribution for the given arguments.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution.  Should include all\n",
      " |          the non-optional arguments, may include ``loc`` and ``scale``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      rv_frozen : rv_frozen instance\n",
      " |          The frozen distribution.\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  entropy(self, *args, **kwds)\n",
      " |      Differential entropy of the RV.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information).\n",
      " |      loc : array_like, optional\n",
      " |          Location parameter (default=0).\n",
      " |      scale : array_like, optional  (continuous distributions only).\n",
      " |          Scale parameter (default=1).\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Entropy is defined base `e`:\n",
      " |      \n",
      " |      >>> drv = rv_discrete(values=((0, 1), (0.5, 0.5)))\n",
      " |      >>> np.allclose(drv.entropy(), np.log(2.0))\n",
      " |      True\n",
      " |  \n",
      " |  freeze(self, *args, **kwds)\n",
      " |      Freeze the distribution for the given arguments.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution.  Should include all\n",
      " |          the non-optional arguments, may include ``loc`` and ``scale``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      rv_frozen : rv_frozen instance\n",
      " |          The frozen distribution.\n",
      " |  \n",
      " |  interval(self, alpha, *args, **kwds)\n",
      " |      Confidence interval with equal areas around the median.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      alpha : array_like of float\n",
      " |          Probability that an rv will be drawn from the returned range.\n",
      " |          Each value should be in the range [0, 1].\n",
      " |      arg1, arg2, ... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information).\n",
      " |      loc : array_like, optional\n",
      " |          location parameter, Default is 0.\n",
      " |      scale : array_like, optional\n",
      " |          scale parameter, Default is 1.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      a, b : ndarray of float\n",
      " |          end-points of range that contain ``100 * alpha %`` of the rv's\n",
      " |          possible values.\n",
      " |  \n",
      " |  mean(self, *args, **kwds)\n",
      " |      Mean of the distribution.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information)\n",
      " |      loc : array_like, optional\n",
      " |          location parameter (default=0)\n",
      " |      scale : array_like, optional\n",
      " |          scale parameter (default=1)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      mean : float\n",
      " |          the mean of the distribution\n",
      " |  \n",
      " |  median(self, *args, **kwds)\n",
      " |      Median of the distribution.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information)\n",
      " |      loc : array_like, optional\n",
      " |          Location parameter, Default is 0.\n",
      " |      scale : array_like, optional\n",
      " |          Scale parameter, Default is 1.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      median : float\n",
      " |          The median of the distribution.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      stats.distributions.rv_discrete.ppf\n",
      " |          Inverse of the CDF\n",
      " |  \n",
      " |  moment(self, n, *args, **kwds)\n",
      " |      n-th order non-central moment of distribution.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int, n >= 1\n",
      " |          Order of moment.\n",
      " |      arg1, arg2, arg3,... : float\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information).\n",
      " |      loc : array_like, optional\n",
      " |          location parameter (default=0)\n",
      " |      scale : array_like, optional\n",
      " |          scale parameter (default=1)\n",
      " |  \n",
      " |  rvs(self, *args, **kwds)\n",
      " |      Random variates of given type.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information).\n",
      " |      loc : array_like, optional\n",
      " |          Location parameter (default=0).\n",
      " |      scale : array_like, optional\n",
      " |          Scale parameter (default=1).\n",
      " |      size : int or tuple of ints, optional\n",
      " |          Defining number of random variates (default is 1).\n",
      " |      random_state : None or int or ``np.random.RandomState`` instance, optional\n",
      " |          If int or RandomState, use it for drawing the random variates.\n",
      " |          If None, rely on ``self.random_state``.\n",
      " |          Default is None.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      rvs : ndarray or scalar\n",
      " |          Random variates of given `size`.\n",
      " |  \n",
      " |  stats(self, *args, **kwds)\n",
      " |      Some statistics of the given RV.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information)\n",
      " |      loc : array_like, optional\n",
      " |          location parameter (default=0)\n",
      " |      scale : array_like, optional (continuous RVs only)\n",
      " |          scale parameter (default=1)\n",
      " |      moments : str, optional\n",
      " |          composed of letters ['mvsk'] defining which moments to compute:\n",
      " |          'm' = mean,\n",
      " |          'v' = variance,\n",
      " |          's' = (Fisher's) skew,\n",
      " |          'k' = (Fisher's) kurtosis.\n",
      " |          (default is 'mv')\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      stats : sequence\n",
      " |          of requested moments.\n",
      " |  \n",
      " |  std(self, *args, **kwds)\n",
      " |      Standard deviation of the distribution.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information)\n",
      " |      loc : array_like, optional\n",
      " |          location parameter (default=0)\n",
      " |      scale : array_like, optional\n",
      " |          scale parameter (default=1)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      std : float\n",
      " |          standard deviation of the distribution\n",
      " |  \n",
      " |  var(self, *args, **kwds)\n",
      " |      Variance of the distribution.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information)\n",
      " |      loc : array_like, optional\n",
      " |          location parameter (default=0)\n",
      " |      scale : array_like, optional\n",
      " |          scale parameter (default=1)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      var : float\n",
      " |          the variance of the distribution\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from scipy.stats._distn_infrastructure.rv_generic:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  random_state\n",
      " |      Get or set the RandomState object for generating random variates.\n",
      " |      \n",
      " |      This can be either None or an existing RandomState object.\n",
      " |      \n",
      " |      If None (or np.random), use the RandomState singleton used by np.random.\n",
      " |      If already a RandomState instance, use it.\n",
      " |      If an int, use a new RandomState instance seeded with seed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(uniform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
